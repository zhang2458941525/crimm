{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf7d8da7-b8f5-4737-bbbc-475bc581083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15965f13-2583-4d1a-9169-1488a4e88b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dad93c1e-644a-46f3-b5a4-4e5c6e70c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a92cbb81-3dbf-4c02-bc02-0ff0e9a10289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f404590c-7a9f-49a1-ab8d-e52fa55dbed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of custom_function at [0.95, 0.95, 0.95, 0.95, 0.95, 0.95] is 0.00011397265188861638\n"
     ]
    }
   ],
   "source": [
    "import Hartmannb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ac03b4c-4fb3-456f-bab5-e0448edbcbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.test_functions.base import BaseTestProblem\n",
    "from botorch.test_functions import Hartmann\n",
    "import numpy as np \n",
    "import torch \n",
    "import random \n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms.input import Normalize\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "# from botorch.fit import fit_gpytorch_model \n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.acquisition.objective import ScalarizedPosteriorTransform\n",
    "from botorch.acquisition import qLogNoisyExpectedImprovement\n",
    "from botorch.acquisition import qLogExpectedImprovement\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "789397fc-24da-41b5-9be5-f179c2491078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb4b4f-beb7-487a-abc7-9faf2b2d0fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef0d59ee-1b53-430f-b0e5-174a634170f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            G           F            W          V1          V2         V3  \\\n",
      "0  960.274125   85.293927  6623.437770  214.227575  340.372233  54.603440   \n",
      "1  959.872112   85.745979  6595.996008  213.992957  332.089900  54.645951   \n",
      "2  960.379664   86.963096  6622.916667  214.070897  343.915356  54.703336   \n",
      "3  960.241819   94.040876  6654.799367  214.146170  339.090909  54.797417   \n",
      "4  955.264501  101.057077  6768.130288  214.118549  369.283862  54.841628   \n",
      "\n",
      "          C  \n",
      "0  0.089293  \n",
      "1  0.090599  \n",
      "2  0.097921  \n",
      "3  0.105241  \n",
      "4  0.119251  \n"
     ]
    }
   ],
   "source": [
    "# 读取 Excel 文件\n",
    "df = pd.read_csv('data.csv')  # 替换为你的文件名和工作表名\n",
    "\n",
    "# 显示数据\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f701663-9f38-4416-acbc-84f437e0dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['G','F', 'W','V1','V2','V3'\n",
    "        ]]\n",
    "y = df[['C']]\n",
    "J = (df['G'] * (1 - df['C']) + df['F']) / df['W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7268d3d-fd29-4144-a958-f3bf617ff92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels size: (2610, 1)\n",
      "Test labels size: (290, 1)\n"
     ]
    }
   ],
   "source": [
    "# 将 y 分为训练集和测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# 打印 y_train 和 y_test 的大小\n",
    "print(f\"Training labels size: {y_train.shape}\")\n",
    "print(f\"Test labels size: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b16f8f2-c33b-4e7d-b590-7cde0a1317d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_1704\\600102426.py:5: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R²: 0.9806131963064145\n",
      "Test R²: 0.8921716907603638\n"
     ]
    }
   ],
   "source": [
    "# 创建随机森林模型\n",
    "rf_model = RandomForestRegressor(random_state=42, n_estimators=100)  # 可以根据需要调整参数\n",
    "\n",
    "# 拟合模型\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# 在训练集和测试集上进行预测\n",
    "y_train_pred = rf_model.predict(x_train)\n",
    "y_test_pred = rf_model.predict(x_test)\n",
    "\n",
    "# 输出训练集和测试集的 R² 值\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training R²: {train_r2}\")\n",
    "print(f\"Test R²: {test_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a845a4d0-52f8-4563-8043-bce017f71242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0636], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def predict_function(new_data):\n",
    "    \"\"\"给定新的 6 维输入数据，返回 j 的预测值\"\"\"\n",
    "    \n",
    "    # 将输入数据转换为 NumPy 数组\n",
    "    new_data_numpy = new_data.cpu().numpy().astype(np.float64)  \n",
    "    \n",
    "    # 将 NumPy 数组转换为 pandas DataFrame，并提供列名\n",
    "    feature_names = ['G','F', 'W','V1','V2','V3']  # 确保与输入数据对应\n",
    "    new_data_df = pd.DataFrame(new_data_numpy, columns=feature_names)\n",
    "    \n",
    "    # 使用随机森林模型进行预测，确保特征顺序正确\n",
    "    j = rf_model.predict(new_data_df[['G','F', 'W','V1','V2','V3']])  # 使用六个特征进行预测\n",
    "    \n",
    "    return torch.tensor(j, dtype=torch.float64)  # 返回 PyTorch 张量，确保为 float64\n",
    "\n",
    "# 示例输入，确保为6个特征的数组\n",
    "input_data = np.array([[52, 52, 74, 752, 782, 872]])  # 替换为实际值\n",
    "input_tensor = torch.tensor(input_data, dtype=torch.float64)\n",
    "\n",
    "# 调用函数\n",
    "result = predict_function(input_tensor)\n",
    "\n",
    "print(result)  # 输出预测结果\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f18b68f-a606-4879-bd89-acec5b76c388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample set 1:\n",
      "tensor([[1.0759e+03, 1.0106e+02, 6.7681e+03, 1.2918e+02, 3.0213e+02, 7.2350e+01],\n",
      "        [1.1889e+03, 1.0106e+02, 6.7681e+03, 1.9630e+02, 3.7445e+02, 6.2671e+00],\n",
      "        [1.0791e+03, 1.0106e+02, 6.7681e+03, 1.4851e+02, 2.5804e+02, 5.2469e+01],\n",
      "        [9.6116e+02, 1.0106e+02, 6.7681e+03, 3.4610e+02, 3.0421e+02, 1.1273e+02],\n",
      "        [1.0443e+03, 1.0106e+02, 6.7681e+03, 2.5983e+02, 2.8301e+02, 1.1072e+02]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Sample set 2:\n",
      "tensor([[1.0216e+03, 1.0106e+02, 6.7681e+03, 2.1749e+02, 2.3416e+02, 4.5258e+01],\n",
      "        [1.0242e+03, 1.0106e+02, 6.7681e+03, 1.7655e+02, 2.3518e+02, 7.0730e+01],\n",
      "        [9.2427e+02, 1.0106e+02, 6.7681e+03, 9.2844e+01, 1.8860e+02, 3.5846e-01],\n",
      "        [1.0311e+03, 1.0106e+02, 6.7681e+03, 1.4768e+02, 2.6140e+02, 1.0167e+02],\n",
      "        [1.0219e+03, 1.0106e+02, 6.7681e+03, 4.3508e+01, 2.0602e+02, 4.7682e+00]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Sample set 3:\n",
      "tensor([[ 978.9510,  101.0571, 6768.1304,  281.9436,  333.0673,  116.8611],\n",
      "        [ 950.8885,  101.0571, 6768.1304,  168.9780,  197.9074,  100.3179],\n",
      "        [ 973.3823,  101.0571, 6768.1304,    9.1823,  216.8098,  119.0619],\n",
      "        [1009.0571,  101.0571, 6768.1304,  255.7192,  344.8938,   29.9466],\n",
      "        [1079.9109,  101.0571, 6768.1304,  276.7737,  311.0977,   87.8375]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Sample set 4:\n",
      "tensor([[1177.7209,  101.0571, 6768.1304,    8.8978,  319.1137,   58.6066],\n",
      "        [ 938.8610,  101.0571, 6768.1304,  305.0471,  335.4722,   18.5811],\n",
      "        [ 906.4420,  101.0571, 6768.1304,   44.2917,  260.4398,   74.1636],\n",
      "        [1083.3923,  101.0571, 6768.1304,  212.6816,  282.9826,   61.5769],\n",
      "        [ 985.0483,  101.0571, 6768.1304,  319.9530,  361.8379,  102.0892]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Sample set 5:\n",
      "tensor([[1065.5331,  101.0571, 6768.1304,  271.2763,  273.4585,   29.2982],\n",
      "        [1154.0381,  101.0571, 6768.1304,   77.9565,  274.0237,   93.8373],\n",
      "        [1161.4719,  101.0571, 6768.1304,   22.3201,  210.7451,   85.0050],\n",
      "        [ 981.6711,  101.0571, 6768.1304,   73.8471,  277.0828,  112.8805],\n",
      "        [1146.8143,  101.0571, 6768.1304,   36.3579,  257.5158,   73.5565]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Sample set 6:\n",
      "tensor([[1037.4058,  101.0571, 6768.1304,  120.6983,  242.0618,   37.8806],\n",
      "        [1163.4825,  101.0571, 6768.1304,   67.0651,  276.6459,   29.1891],\n",
      "        [1064.0776,  101.0571, 6768.1304,   50.0644,  219.2999,   73.9574],\n",
      "        [1169.9244,  101.0571, 6768.1304,  189.9265,  338.2250,   57.9863],\n",
      "        [ 918.7260,  101.0571, 6768.1304,   58.9747,  247.5551,   68.3667]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Sample set 7:\n",
      "tensor([[9.4611e+02, 1.0106e+02, 6.7681e+03, 8.4766e+01, 2.1215e+02, 3.3296e+01],\n",
      "        [1.1041e+03, 1.0106e+02, 6.7681e+03, 2.9297e+02, 3.1267e+02, 1.1199e+00],\n",
      "        [1.1241e+03, 1.0106e+02, 6.7681e+03, 8.5339e+01, 2.9172e+02, 1.0140e+02],\n",
      "        [1.1804e+03, 1.0106e+02, 6.7681e+03, 3.4931e+02, 3.7083e+02, 1.6830e+01],\n",
      "        [1.1822e+03, 1.0106e+02, 6.7681e+03, 9.2147e+01, 2.5437e+02, 1.1883e+02]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Sample set 8:\n",
      "tensor([[1192.1663,  101.0571, 6768.1304,   70.9480,  269.2741,  104.0842],\n",
      "        [1061.8242,  101.0571, 6768.1304,  260.3137,  279.1757,  103.3144],\n",
      "        [ 914.7174,  101.0571, 6768.1304,  336.6749,  322.9619,   47.0423],\n",
      "        [1056.8091,  101.0571, 6768.1304,  111.9791,  247.2485,  109.2388],\n",
      "        [1009.3706,  101.0571, 6768.1304,  127.9284,  273.7638,   69.5998]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Sample set 9:\n",
      "tensor([[1094.6608,  101.0571, 6768.1304,  341.1474,  303.5670,   49.5408],\n",
      "        [ 929.2448,  101.0571, 6768.1304,  355.9745,  277.9332,   90.2681],\n",
      "        [1059.2120,  101.0571, 6768.1304,  247.3802,  256.0694,   29.3879],\n",
      "        [1161.3474,  101.0571, 6768.1304,  198.4377,  357.5760,   40.9034],\n",
      "        [1115.7629,  101.0571, 6768.1304,  228.3705,  305.6982,   38.3932]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Sample set 10:\n",
      "tensor([[1082.4423,  101.0571, 6768.1304,  251.7535,  315.2401,  100.7651],\n",
      "        [ 936.3405,  101.0571, 6768.1304,  299.0207,  235.0194,   58.5589],\n",
      "        [1157.8606,  101.0571, 6768.1304,  133.1354,  247.5896,   17.6483],\n",
      "        [1056.2343,  101.0571, 6768.1304,  238.6144,  349.8604,   80.9391],\n",
      "        [ 960.8389,  101.0571, 6768.1304,  159.8520,  274.5679,   11.6288]],\n",
      "       device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_random_6d_tensor(n_samples, fixed_values, bounds, device):\n",
    "    \"\"\"\n",
    "    生成一组随机的 6 维张量数据。\n",
    "    第 2 和第 3 个维度是固定的。\n",
    "    第 1，4，第 5 和第 6 个维度是随机生成的，具有各自的范围。\n",
    "    \"\"\"\n",
    "    # 检查 bounds 是否为 4 维\n",
    "    if len(bounds) != 4:\n",
    "        raise ValueError(\"Bounds should have 4 elements for the remaining dimensions.\")\n",
    "    \n",
    "    # 生成随机数据\n",
    "    random_data = torch.empty((n_samples, 6), device=device)\n",
    "\n",
    "    # 固定第 2 和第 3 维度的值\n",
    "    random_data[:, 1] = fixed_values[0]  # 固定值 for 第 2 维\n",
    "    random_data[:, 2] = fixed_values[1]  # 固定值 for 第 3 维\n",
    "\n",
    "    # 生成随机范围数据\n",
    "    while True:\n",
    "        # 生成随机值\n",
    "        random_data[:, 0] = torch.FloatTensor(n_samples).uniform_(*bounds[0]).to(device)  # 第1维度 (G)\n",
    "        random_data[:, 3] = torch.FloatTensor(n_samples).uniform_(*bounds[1]).to(device)  # 第4维度 (F)\n",
    "        random_data[:, 4] = torch.FloatTensor(n_samples).uniform_(*bounds[2]).to(device)  # 第5维度 (V1)\n",
    "        random_data[:, 5] = torch.FloatTensor(n_samples).uniform_(*bounds[3]).to(device)  # 第6维度\n",
    "\n",
    "        # 计算条件\n",
    "        G_plus_F = random_data[:, 0] + random_data[:, 3]  # G + F\n",
    "        V1 = random_data[:, 4]  # V1\n",
    "\n",
    "        # 计算比例并检查条件\n",
    "        ratio = G_plus_F / (G_plus_F + V1)\n",
    "        if (ratio > 0.78).all() and (ratio < 0.85).all():\n",
    "            break  # 如果所有样本都满足条件，则退出循环\n",
    "\n",
    "    return random_data\n",
    "\n",
    "# 固定值\n",
    "fixed_values = (101.057077, 6768.130288)  # 第2和第3维度的固定值\n",
    "\n",
    "# 随机范围的 bounds\n",
    "bounds = [(900, 1200),  # 第1维度的范围\n",
    "          (0, 372),    # 第4维度的范围\n",
    "          (0, 740),    # 第5维度的范围\n",
    "          (0, 126)]    # 第6维度的范围\n",
    "\n",
    "# 选择设备\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 存储所有生成的样本\n",
    "all_random_tensor_data = []\n",
    "\n",
    "# 生成 10 次随机样本，每次 5 个\n",
    "for _ in range(10):\n",
    "    random_tensor_data = generate_random_6d_tensor(n_samples=5, fixed_values=fixed_values, bounds=bounds, device=device)\n",
    "    all_random_tensor_data.append(random_tensor_data)\n",
    "\n",
    "# 打印所有生成的随机张量数据\n",
    "for i, tensor in enumerate(all_random_tensor_data):\n",
    "    print(f\"Sample set {i + 1}:\\n{tensor}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba0a197a-176b-4b9c-918a-13e4a7a2be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gp_model_and_select_next_point1(train_x, train_obj, device):\n",
    "    # 确保 train_x 和 train_obj 是 float64 类型\n",
    "    train_x = train_x.to(device=device, dtype=torch.float64)\n",
    "    train_obj = train_obj.to(device=device, dtype=torch.float64)\n",
    "\n",
    "    # 创建和拟合高斯过程模型\n",
    "    model = SingleTaskGP(\n",
    "        train_X=train_x,\n",
    "        train_Y=train_obj,\n",
    "        input_transform=Normalize(d=train_x.shape[1]),  # 使用输入的维度\n",
    "        outcome_transform=Standardize(m=1),  # 输出为一维\n",
    "    ).to(device)\n",
    "\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    # 找到当前最优值\n",
    "    best_value = train_obj.max()\n",
    "\n",
    "    # 定义 Log Expected Improvement\n",
    "    qLogEI = qLogExpectedImprovement(model=model, best_f=best_value)\n",
    "\n",
    "    # 固定值\n",
    "    fixed_value_2 =101.057077  # 固定第2维度\n",
    "    fixed_value_3 = 6768.13028  # 固定第3维度\n",
    "\n",
    "    # 修改为你指定的上下界，确保第2和第3维度固定\n",
    "    lower_bounds = [900, fixed_value_2, fixed_value_3, 0, 0, 0]  # 对应 4 维输入\n",
    "    upper_bounds = [1200, fixed_value_2, fixed_value_3, 372, 740, 126]  # 对应 4 维输入\n",
    "\n",
    "    # 转换为 tensor，确保数据类型为 float64\n",
    "    bounds = torch.tensor([lower_bounds, upper_bounds], device=device, dtype=torch.float64)\n",
    "\n",
    "    while True:\n",
    "        # 优化获取函数，找到新的采样点\n",
    "        new_point_analytic, _ = optimize_acqf(\n",
    "            acq_function=qLogEI,\n",
    "            bounds=bounds,\n",
    "            q=1,  # 采样一个点\n",
    "            num_restarts=20,\n",
    "            raw_samples=100,\n",
    "            options={},\n",
    "        )\n",
    "\n",
    "        # 将新点转换为张量并提取值\n",
    "        point = new_point_analytic.squeeze(0)  # 从 (1, 6) 转为 (6,)\n",
    "\n",
    "        G = point[0].item()  # 第1维度\n",
    "        F = point[1].item()  # 第4维度\n",
    "        V1 = point[3].item()  # 第5维度\n",
    "\n",
    "        # 计算比例\n",
    "        ratio = (G + F) / (G + F + V1)\n",
    "\n",
    "        # 检查条件是否满足\n",
    "        if 0.78 < ratio < 0.85:\n",
    "            break  # 满足条件，退出循环\n",
    "\n",
    "    return new_point_analytic.squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86fc7245-4cfa-40c5-8fd8-f6a96b943259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0759e+03, 1.0106e+02, 6.7681e+03, 1.2918e+02, 3.0213e+02, 7.2350e+01],\n",
      "        [1.1889e+03, 1.0106e+02, 6.7681e+03, 1.9630e+02, 3.7445e+02, 6.2671e+00],\n",
      "        [1.0791e+03, 1.0106e+02, 6.7681e+03, 1.4851e+02, 2.5804e+02, 5.2469e+01],\n",
      "        [9.6116e+02, 1.0106e+02, 6.7681e+03, 3.4610e+02, 3.0421e+02, 1.1273e+02],\n",
      "        [1.0443e+03, 1.0106e+02, 6.7681e+03, 2.5983e+02, 2.8301e+02, 1.1072e+02]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:174: InputDataWarning:\n",
      "\n",
      "Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results1 \u001b[38;5;241m=\u001b[39m Hartmannb\u001b[38;5;241m.\u001b[39mbayesian_optimization_experiment(\n\u001b[0;32m      2\u001b[0m     num_experiments\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      3\u001b[0m     n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,\n\u001b[0;32m      4\u001b[0m     obj_fn1\u001b[38;5;241m=\u001b[39mpredict_function,\n\u001b[0;32m      5\u001b[0m     obj_fn2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[0;32m      6\u001b[0m     obj_fn3\u001b[38;5;241m=\u001b[39mpredict_function,\n\u001b[0;32m      7\u001b[0m     initial_points_task1\u001b[38;5;241m=\u001b[39mall_random_tensor_data,\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m     fit_task_fn\u001b[38;5;241m=\u001b[39mfit_gp_model_and_select_next_point1,\n\u001b[0;32m     10\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m     task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# 表示运行单任务模型\u001b[39;00m\n\u001b[0;32m     12\u001b[0m )\n",
      "File \u001b[1;32m~\\哈特曼\\Hartmannb.py:786\u001b[0m, in \u001b[0;36mbayesian_optimization_experiment\u001b[1;34m(num_experiments, n, fit_task_fn, obj_fn1, obj_fn2, obj_fn3, initial_points_task1, initial_points_task2, device, task_type)\u001b[0m\n\u001b[0;32m    783\u001b[0m     new_point_analytic \u001b[38;5;241m=\u001b[39m fit_task_fn(train_x, train_obj, device, task\u001b[38;5;241m=\u001b[39mtask_tensor)\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# 单任务模型不需要任务参数\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m     new_point_analytic \u001b[38;5;241m=\u001b[39m fit_task_fn(train_x, train_obj, device)\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# 确保 new_point_analytic 是二维张量\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_point_analytic\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "Cell \u001b[1;32mIn[14], line 36\u001b[0m, in \u001b[0;36mfit_gp_model_and_select_next_point1\u001b[1;34m(train_x, train_obj, device)\u001b[0m\n\u001b[0;32m     32\u001b[0m bounds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([lower_bounds, upper_bounds], device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# 优化获取函数，找到新的采样点\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     new_point_analytic, _ \u001b[38;5;241m=\u001b[39m optimize_acqf(\n\u001b[0;32m     37\u001b[0m         acq_function\u001b[38;5;241m=\u001b[39mqLogEI,\n\u001b[0;32m     38\u001b[0m         bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m     39\u001b[0m         q\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# 采样一个点\u001b[39;00m\n\u001b[0;32m     40\u001b[0m         num_restarts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     41\u001b[0m         raw_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     42\u001b[0m         options\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m     43\u001b[0m     )\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# 将新点转换为张量并提取值\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     point \u001b[38;5;241m=\u001b[39m new_point_analytic\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# 从 (1, 6) 转为 (6,)\u001b[39;00m\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\botorch\\optim\\optimize.py:567\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[1;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, gen_candidates, sequential, ic_generator, timeout_sec, return_full_tree, retry_on_optimization_warning, **ic_gen_kwargs)\u001b[0m\n\u001b[0;32m    544\u001b[0m     gen_candidates \u001b[38;5;241m=\u001b[39m gen_candidates_scipy\n\u001b[0;32m    545\u001b[0m opt_acqf_inputs \u001b[38;5;241m=\u001b[39m OptimizeAcqfInputs(\n\u001b[0;32m    546\u001b[0m     acq_function\u001b[38;5;241m=\u001b[39macq_function,\n\u001b[0;32m    547\u001b[0m     bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    565\u001b[0m     ic_gen_kwargs\u001b[38;5;241m=\u001b[39mic_gen_kwargs,\n\u001b[0;32m    566\u001b[0m )\n\u001b[1;32m--> 567\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf(opt_acqf_inputs)\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\botorch\\optim\\optimize.py:588\u001b[0m, in \u001b[0;36m_optimize_acqf\u001b[1;34m(opt_inputs)\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf_sequential_q(opt_inputs\u001b[38;5;241m=\u001b[39mopt_inputs)\n\u001b[0;32m    587\u001b[0m \u001b[38;5;66;03m# Batch optimization (including the case q=1)\u001b[39;00m\n\u001b[1;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf_batch(opt_inputs\u001b[38;5;241m=\u001b[39mopt_inputs)\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\botorch\\optim\\optimize.py:352\u001b[0m, in \u001b[0;36m_optimize_acqf_batch\u001b[1;34m(opt_inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m         batch_acq_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(batch_acq_values_list)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch_candidates, batch_acq_values, opt_warnings\n\u001b[1;32m--> 352\u001b[0m batch_candidates, batch_acq_values, ws \u001b[38;5;241m=\u001b[39m _optimize_batch_candidates()\n\u001b[0;32m    354\u001b[0m optimization_warning_raised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    355\u001b[0m     (\u001b[38;5;28missubclass\u001b[39m(w\u001b[38;5;241m.\u001b[39mcategory, OptimizationWarning) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m ws)\n\u001b[0;32m    356\u001b[0m )\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimization_warning_raised \u001b[38;5;129;01mand\u001b[39;00m opt_inputs\u001b[38;5;241m.\u001b[39mretry_on_optimization_warning:\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\botorch\\optim\\optimize.py:336\u001b[0m, in \u001b[0;36m_optimize_acqf_batch.<locals>._optimize_batch_candidates\u001b[1;34m()\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m ws:\n\u001b[0;32m    332\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39mOptimizationWarning)\n\u001b[0;32m    333\u001b[0m     (\n\u001b[0;32m    334\u001b[0m         batch_candidates_curr,\n\u001b[0;32m    335\u001b[0m         batch_acq_values_curr,\n\u001b[1;32m--> 336\u001b[0m     ) \u001b[38;5;241m=\u001b[39m opt_inputs\u001b[38;5;241m.\u001b[39mgen_candidates(\n\u001b[0;32m    337\u001b[0m         batched_ics_, opt_inputs\u001b[38;5;241m.\u001b[39macq_function, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfiltered_gen_kwargs\n\u001b[0;32m    338\u001b[0m     )\n\u001b[0;32m    339\u001b[0m opt_warnings \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ws\n\u001b[0;32m    340\u001b[0m batch_candidates_list\u001b[38;5;241m.\u001b[39mappend(batch_candidates_curr)\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\botorch\\generation\\gen.py:252\u001b[0m, in \u001b[0;36mgen_candidates_scipy\u001b[1;34m(initial_conditions, acquisition_function, lower_bounds, upper_bounds, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, options, fixed_features, timeout_sec)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(x):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39macquisition_function(x)\n\u001b[1;32m--> 252\u001b[0m res \u001b[38;5;241m=\u001b[39m minimize_with_timeout(\n\u001b[0;32m    253\u001b[0m     fun\u001b[38;5;241m=\u001b[39mf_np_wrapper,\n\u001b[0;32m    254\u001b[0m     args\u001b[38;5;241m=\u001b[39m(f,),\n\u001b[0;32m    255\u001b[0m     x0\u001b[38;5;241m=\u001b[39mx0,\n\u001b[0;32m    256\u001b[0m     method\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSLSQP\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m constraints \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    257\u001b[0m     jac\u001b[38;5;241m=\u001b[39mwith_grad,\n\u001b[0;32m    258\u001b[0m     bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m    259\u001b[0m     constraints\u001b[38;5;241m=\u001b[39mconstraints,\n\u001b[0;32m    260\u001b[0m     callback\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    261\u001b[0m     options\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    262\u001b[0m         k: v\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m options\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    265\u001b[0m     },\n\u001b[0;32m    266\u001b[0m     timeout_sec\u001b[38;5;241m=\u001b[39mtimeout_sec,\n\u001b[0;32m    267\u001b[0m )\n\u001b[0;32m    268\u001b[0m _process_scipy_result(res\u001b[38;5;241m=\u001b[39mres, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m    270\u001b[0m candidates \u001b[38;5;241m=\u001b[39m fix_features(\n\u001b[0;32m    271\u001b[0m     X\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(res\u001b[38;5;241m.\u001b[39mx)\u001b[38;5;241m.\u001b[39mto(initial_conditions)\u001b[38;5;241m.\u001b[39mreshape(shapeX),\n\u001b[0;32m    272\u001b[0m     fixed_features\u001b[38;5;241m=\u001b[39mfixed_features,\n\u001b[0;32m    273\u001b[0m )\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\botorch\\optim\\utils\\timeout.py:82\u001b[0m, in \u001b[0;36mminimize_with_timeout\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod .* cannot handle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m optimize\u001b[38;5;241m.\u001b[39mminimize(\n\u001b[0;32m     83\u001b[0m         fun\u001b[38;5;241m=\u001b[39mfun,\n\u001b[0;32m     84\u001b[0m         x0\u001b[38;5;241m=\u001b[39mx0,\n\u001b[0;32m     85\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m     86\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m     87\u001b[0m         jac\u001b[38;5;241m=\u001b[39mjac,\n\u001b[0;32m     88\u001b[0m         hess\u001b[38;5;241m=\u001b[39mhess,\n\u001b[0;32m     89\u001b[0m         hessp\u001b[38;5;241m=\u001b[39mhessp,\n\u001b[0;32m     90\u001b[0m         bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m     91\u001b[0m         constraints\u001b[38;5;241m=\u001b[39mconstraints,\n\u001b[0;32m     92\u001b[0m         tol\u001b[38;5;241m=\u001b[39mtol,\n\u001b[0;32m     93\u001b[0m         callback\u001b[38;5;241m=\u001b[39mwrapped_callback,\n\u001b[0;32m     94\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m     95\u001b[0m     )\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OptimizationTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     97\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization timed out after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mruntime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:696\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    693\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    694\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 696\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    697\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    699\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    700\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:359\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    353\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m func_and_grad(x)\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    362\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_if_needed(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 70\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\botorch\\generation\\gen.py:209\u001b[0m, in \u001b[0;36mgen_candidates_scipy.<locals>.f_np_wrapper\u001b[1;34m(x, f)\u001b[0m\n\u001b[0;32m    201\u001b[0m X \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    202\u001b[0m     torch\u001b[38;5;241m.\u001b[39mfrom_numpy(x)\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;241m.\u001b[39mto(initial_conditions)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    207\u001b[0m )\n\u001b[0;32m    208\u001b[0m X_fix \u001b[38;5;241m=\u001b[39m fix_features(X, fixed_features\u001b[38;5;241m=\u001b[39mfixed_features)\n\u001b[1;32m--> 209\u001b[0m loss \u001b[38;5;241m=\u001b[39m f(X_fix)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# compute gradient w.r.t. the inputs (does not accumulate in leaves)\u001b[39;00m\n\u001b[0;32m    211\u001b[0m gradf \u001b[38;5;241m=\u001b[39m _arrayify(torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(loss, X)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\botorch\\generation\\gen.py:250\u001b[0m, in \u001b[0;36mgen_candidates_scipy.<locals>.f\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(x):\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39macquisition_function(x)\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\botorch\\utils\\transforms.py:305\u001b[0m, in \u001b[0;36mconcatenate_pending_points.<locals>.decorated\u001b[1;34m(cls, X, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mX_pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    304\u001b[0m     X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([X, match_batch_shape(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mX_pending, X)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mcls\u001b[39m, X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\botorch\\utils\\transforms.py:259\u001b[0m, in \u001b[0;36mt_batch_mode_transform.<locals>.decorator.<locals>.decorated\u001b[1;34m(acqf, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# add t-batch dim\u001b[39;00m\n\u001b[0;32m    258\u001b[0m X \u001b[38;5;241m=\u001b[39m X \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 259\u001b[0m output \u001b[38;5;241m=\u001b[39m method(acqf, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(acqf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_ensemble(acqf\u001b[38;5;241m.\u001b[39mmodel):\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# IDEA: this could be wrapped into SampleReducingMCAcquisitionFunction\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    263\u001b[0m         output\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m acqf\u001b[38;5;241m.\u001b[39m_log \u001b[38;5;28;01melse\u001b[39;00m logmeanexp(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    264\u001b[0m     )\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\botorch\\acquisition\\monte_carlo.py:275\u001b[0m, in \u001b[0;36mSampleReducingMCAcquisitionFunction.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the acquisition value associated with the input `X`. Weighs the\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124;03macquisition utility values by smoothed constraint indicators if `constraints`\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;124;03mwas passed to the constructor of the class. Applies `self.sample_reduction` and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m    batch shape of model and input `X`.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    274\u001b[0m non_reduced_acqval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_reduced_forward(X\u001b[38;5;241m=\u001b[39mX)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_reduction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_q_reduction(non_reduced_acqval))\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\botorch\\utils\\safe_math.py:352\u001b[0m, in \u001b[0;36mfatmax\u001b[1;34m(x, dim, keepdim, tau, alpha)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax_fun\u001b[39m(\n\u001b[0;32m    348\u001b[0m     x: Tensor, dim: Union[\u001b[38;5;28mint\u001b[39m, Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]], keepdim: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tau \u001b[38;5;241m*\u001b[39m _pareto(\u001b[38;5;241m-\u001b[39mx \u001b[38;5;241m/\u001b[39m tau, alpha\u001b[38;5;241m=\u001b[39malpha)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39mkeepdim)\u001b[38;5;241m.\u001b[39mlog()\n\u001b[1;32m--> 352\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _inf_max_helper(max_fun\u001b[38;5;241m=\u001b[39mmax_fun, x\u001b[38;5;241m=\u001b[39mx, dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39mkeepdim)\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\botorch\\utils\\safe_math.py:181\u001b[0m, in \u001b[0;36m_inf_max_helper\u001b[1;34m(max_fun, x, dim, keepdim)\u001b[0m\n\u001b[0;32m    175\u001b[0m M_no_inf \u001b[38;5;241m=\u001b[39m M\u001b[38;5;241m.\u001b[39mmasked_fill(M\u001b[38;5;241m.\u001b[39misinf(), \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m    176\u001b[0m y_no_inf \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmasked_fill(has_inf_max, \u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;241m-\u001b[39m M_no_inf\n\u001b[0;32m    178\u001b[0m res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[0;32m    179\u001b[0m     has_inf_max,\n\u001b[0;32m    180\u001b[0m     y_inf\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m--> 181\u001b[0m     M_no_inf \u001b[38;5;241m+\u001b[39m max_fun(y_no_inf, dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m    182\u001b[0m )\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# NOTE: Using `sum` instead of `squeeze` because PyTorch < 2.0 does not support\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# tuple `dim` arguments. `sum` and `squeeze` are equivalent here because the\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# `dim` dimensions have length one after the reductions in the previous lines.\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# TODO: Replace `sum` with `squeeze` once PyTorch >= 2.0 is required.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res \u001b[38;5;28;01mif\u001b[39;00m keepdim \u001b[38;5;28;01melse\u001b[39;00m res\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39mdim)\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\botorch\\utils\\safe_math.py:350\u001b[0m, in \u001b[0;36mfatmax.<locals>.max_fun\u001b[1;34m(x, dim, keepdim)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax_fun\u001b[39m(\n\u001b[0;32m    348\u001b[0m     x: Tensor, dim: Union[\u001b[38;5;28mint\u001b[39m, Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]], keepdim: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tau \u001b[38;5;241m*\u001b[39m _pareto(\u001b[38;5;241m-\u001b[39mx \u001b[38;5;241m/\u001b[39m tau, alpha\u001b[38;5;241m=\u001b[39malpha)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39mkeepdim)\u001b[38;5;241m.\u001b[39mlog()\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\botorch\\utils\\safe_math.py:478\u001b[0m, in \u001b[0;36m_pareto\u001b[1;34m(x, alpha, check)\u001b[0m\n\u001b[0;32m    476\u001b[0m beta_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m alpha\n\u001b[0;32m    477\u001b[0m beta_0 \u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m beta_1\n\u001b[1;32m--> 478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (beta_0 \u001b[38;5;241m/\u001b[39m (beta_0 \u001b[38;5;241m+\u001b[39m beta_1 \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m+\u001b[39m x\u001b[38;5;241m.\u001b[39msquare()))\u001b[38;5;241m.\u001b[39mpow(alpha)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results1 = Hartmannb.bayesian_optimization_experiment(\n",
    "    num_experiments=1,\n",
    "    n=25,\n",
    "    obj_fn1=predict_function,\n",
    "    obj_fn2=None, \n",
    "    obj_fn3=predict_function,\n",
    "    initial_points_task1=all_random_tensor_data,\n",
    "\n",
    "    fit_task_fn=fit_gp_model_and_select_next_point1,\n",
    "    device='cuda',\n",
    "    task_type='single'  # 表示运行单任务模型\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae7e272-fcb4-43be-996c-f4c1dfa40581",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = [results1]\n",
    "results_names = ['results1']\n",
    "\n",
    "# 初始化一个空字典来存储展平后的数据\n",
    "flattened_results = {}\n",
    "\n",
    "# 遍历所有结果数组\n",
    "for i, results in enumerate(results_list):\n",
    "    if isinstance(results, torch.Tensor):\n",
    "        results_np = results.cpu().numpy()  # 转为 numpy 数组\n",
    "    else:\n",
    "        results_np = results  # 如果已经是 numpy 数组，直接使用\n",
    "    \n",
    "    # 获取数组的维度\n",
    "    shape_len = len(results_np.shape)\n",
    "    \n",
    "    if shape_len == 3:\n",
    "        # 3D 数组的形状 (num_experiments, num_samples, num_metrics)\n",
    "        num_experiments, num_samples, num_metrics = results_np.shape\n",
    "        # 展平为 2D 数组\n",
    "        flattened_array = results_np.reshape(num_experiments * num_samples, num_metrics)\n",
    "    elif shape_len == 2:\n",
    "        # 2D 数组的形状 (num_experiments, num_metrics)\n",
    "        flattened_array = results_np\n",
    "        num_experiments, num_metrics = flattened_array.shape\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected number of dimensions: {shape_len}\")\n",
    "    \n",
    "    # 将每个数组的列命名为 'results1_Metric_1', 'results1_Metric_2', ...\n",
    "    columns = [f\"{results_names[i]}_Metric_{j+1}\" for j in range(num_metrics)]\n",
    "    \n",
    "    # 将展平后的数组存入字典，方便后面转换为 DataFrame\n",
    "    flattened_results.update({col: flattened_array[:, j] for j, col in enumerate(columns)})\n",
    "\n",
    "# 创建 DataFrame\n",
    "df_results = pd.DataFrame(flattened_results)\n",
    "\n",
    "# 文件名\n",
    "csv_filename = '实验数据二'\n",
    "\n",
    "# 检查 CSV 文件是否已经存在\n",
    "if os.path.exists(csv_filename):\n",
    "    # 如果文件存在，先读取现有文件\n",
    "    df_existing = pd.read_csv(csv_filename)\n",
    "    # 合并新结果到现有的 DataFrame 中\n",
    "    df_results = pd.concat([df_existing, df_results], ignore_index=True)\n",
    "\n",
    "# 保存或追加为 CSV 文件\n",
    "df_results.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"所有结果已保存到 {csv_filename} 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6170b497-c504-4c4e-be5b-e835808d89cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_plot_individual_results(csv_files, confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    - csv_files: CSV 文件名的列表。\n",
    "    - confidence_level: 置信水平，默认值为 0.95。\n",
    "    \"\"\"\n",
    "    # 计算置信区间的 Z 值\n",
    "    z_value = stats.norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "    \n",
    "    # 准备线条颜色和标签\n",
    "    line_colors = ['blue']\n",
    "    line_styles = ['-']  # 为每一条线添加样式\n",
    "    labels = ['mokuangshuju']\n",
    "\n",
    "    # 创建一个包含 2x2 网格的图形\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    for idx, csv_filename in enumerate(csv_files):\n",
    "        # 检查 CSV 文件是否存在\n",
    "        if not os.path.exists(csv_filename):\n",
    "            raise FileNotFoundError(f\"File {csv_filename} does not exist.\")\n",
    "\n",
    "        # 从 CSV 文件中读取数据\n",
    "        df_results = pd.read_csv(csv_filename)\n",
    "\n",
    "\n",
    "\n",
    "        means_bayes1 = df_results.filter(like='results1_Metric_').mean(axis=0)\n",
    "        standard_errors1 = df_results.filter(like='results1_Metric_').sem(axis=0)\n",
    "        ci_bayes1 = z_value * standard_errors1\n",
    "\n",
    "        \n",
    "        # x轴的索引\n",
    "        x = np.arange(len(means_bayes1))\n",
    "\n",
    "        # 找到对应的子图位置\n",
    "        ax = axs[idx // 2, idx % 2]\n",
    "\n",
    "        # 使用不同颜色绘制带有误差条的均值图\n",
    "        ax.errorbar(x, means_bayes1, yerr=ci_bayes1, fmt='o', label='STGP+qlogEI', \n",
    "                    color=line_colors[0], linestyle=line_styles[0], ecolor=line_colors[0], capsize=5)\n",
    "        \n",
    "        # 设置子图的标题和标签\n",
    "        ax.set_title(f'Optimal values and confidence intervals ({labels[idx]})')\n",
    "        ax.set_xlabel('Number of Iterations')\n",
    "        ax.set_ylabel('The optimal value')\n",
    "\n",
    "        # 添加图例\n",
    "        ax.legend()\n",
    "\n",
    "    # 调整布局\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # 保存图像\n",
    "    plt.savefig('Ackley_Cos_Hartmann_Individual_Plots_Colored_Lines.png', dpi=300)\n",
    "    # 显示图形\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4903b70-d736-45ad-870b-89be373b89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义文件名列表\n",
    "csv_files = [ '实验数据二']\n",
    "\n",
    "# 调用函数并绘图\n",
    "load_and_plot_individual_results(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31238434-f0bd-46c8-9b7e-f4ccd4c7a8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edca024-f920-413a-8b1b-219eac50f245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
