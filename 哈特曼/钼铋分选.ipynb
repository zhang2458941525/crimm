{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72ffc2cc-a19f-42ea-a49d-36a51d5ec9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90bd435d-981d-4055-8dc1-6d39af86c893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of custom_function at [0.95, 0.95, 0.95, 0.95, 0.95, 0.95] is 0.00011397265188861638\n"
     ]
    }
   ],
   "source": [
    "import Hartmannb\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf37d52-bf26-4669-a934-ad4d1ce1f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e22846-4661-4e55-926c-bf1e17396235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f67f49-167f-49a5-b503-8d62e6c45686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e6312f-1ab6-439a-9ccc-fb9a8df5311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import FeatureAgglomeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19c1e97d-6447-45ad-a954-4728ec08adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8dfca49-022e-4570-922c-aa81bcd77e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition import qLogExpectedImprovement\n",
    "from botorch.acquisition import qLogNoisyExpectedImprovement\n",
    "import random \n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms.input import Normalize\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "# from botorch.fit import fit_gpytorch_model \n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95e0be4f-d6b7-4c23-94ae-df539259ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc6cc848-7ee2-45cb-ac40-9ce91ee006c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    粗精产率  粗精品味Mo  粗精品味Bi  粗精品味S  粗精回收率Mo  粗精回收率Bi  粗精回收率S  粗尾品味Mo  粗尾品味Bi  \\\n",
      "0  12.49   0.225   0.633   8.71    84.71    76.35   92.56  0.0058   0.028   \n",
      "1  12.12   0.228   0.674   9.08    87.00    78.81   92.61  0.0047   0.025   \n",
      "2  10.88   0.244   0.719  10.06    88.16    77.82   92.47  0.0040   0.025   \n",
      "3   9.74   0.293   0.831  10.76    86.58    78.89   88.56  0.0049   0.024   \n",
      "4   9.48   0.280   0.845  10.86    84.69    80.08   88.34  0.0053   0.022   \n",
      "\n",
      "   粗尾品味S  ...   乙硫氮   丁黄药  BK205   水玻璃     ph  硝酸铅  矿浆浓度  CYB-05  CYB-06  \\\n",
      "0   0.10  ...  80.0  40.0   30.0     0  10.05  NaN    42     NaN     NaN   \n",
      "1   0.10  ...  80.0  40.0   30.0   300  10.22  NaN    42     NaN     NaN   \n",
      "2   0.10  ...  80.0  40.0   30.0   600  10.30  NaN    42     NaN     NaN   \n",
      "3   0.15  ...  80.0  40.0   30.0   900  10.37  NaN    42     NaN     NaN   \n",
      "4   0.15  ...  80.0  40.0   30.0  1200  10.43  NaN    42     NaN     NaN   \n",
      "\n",
      "   CYQ-03  \n",
      "0     NaN  \n",
      "1     NaN  \n",
      "2     NaN  \n",
      "3     NaN  \n",
      "4     NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# 读取 Excel 文件\n",
    "df = pd.read_excel('钼铋分选.xlsx', sheet_name='Sheet1')  # 替换为你的文件名和工作表名\n",
    "\n",
    "# 显示数据\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f07e6396-6cc9-4cc3-9305-aa2e5d87b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df[['碳酸钠', '乙硫氮', '丁黄药', 'BK205', '水玻璃',  '硝酸铅', '矿浆浓度', 'CYB-05', 'CYB-06', 'CYQ-03','给矿品味S','给矿品味Mo','给矿品味Bi']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b96678a1-9781-48c4-93f2-e5b215d46c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['碳酸钠', '乙硫氮', '丁黄药', 'BK205', '水玻璃',  '硝酸铅', '矿浆浓度', 'CYB-05', 'CYB-06', 'CYQ-03']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39e1cc39-faa8-4c5b-870a-ba8cfe33fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['粗精品味Mo','粗精品味Bi','粗精回收率Mo','粗精回收率Bi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39fd5cae-8693-498e-9999-7e7e188b245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df['粗精品味Bi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a8a3a12-5366-4778-bc0a-ef2308dd9f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 设置支持中文的字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 使用黑体字体（SimHei）\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n",
    "\n",
    "# 统计每个特征中的缺失值数量\n",
    "missing_values = x.isnull().sum()\n",
    "\n",
    "# 设置图像大小\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 绘制缺失值统计的条形图\n",
    "sns.barplot(x=missing_values.index, y=missing_values.values, palette=\"viridis\")\n",
    "\n",
    "# 添加标题和标签\n",
    "plt.title('Missing Values Count per Feature', fontsize=16)\n",
    "plt.xlabel('Features', fontsize=14)\n",
    "plt.ylabel('Missing Values Count', fontsize=14)\n",
    "\n",
    "# 旋转x轴标签，避免重叠\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 展示图像\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45d8b00e-7e00-46cb-b5f9-7b58fb921e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "碳酸钠       0\n",
      "乙硫氮       0\n",
      "丁黄药       0\n",
      "BK205     0\n",
      "水玻璃       0\n",
      "硝酸铅       0\n",
      "矿浆浓度      0\n",
      "CYB-05    0\n",
      "CYB-06    0\n",
      "CYQ-03    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 填充缺失值为0\n",
    "x_filled = x.fillna(0)\n",
    "\n",
    "# 查看是否有缺失值\n",
    "print(x_filled.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68b6187f-ffed-4f6b-9407-14fff3ba5947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>碳酸钠</th>\n",
       "      <th>乙硫氮</th>\n",
       "      <th>丁黄药</th>\n",
       "      <th>BK205</th>\n",
       "      <th>水玻璃</th>\n",
       "      <th>硝酸铅</th>\n",
       "      <th>矿浆浓度</th>\n",
       "      <th>CYB-05</th>\n",
       "      <th>CYB-06</th>\n",
       "      <th>CYQ-03</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>400</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>800</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1200</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>400.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>600.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>800.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>500</td>\n",
       "      <td>200.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>500</td>\n",
       "      <td>400.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>500</td>\n",
       "      <td>600.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>500</td>\n",
       "      <td>800.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1000</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1000</td>\n",
       "      <td>78.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1000</td>\n",
       "      <td>104.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     碳酸钠    乙硫氮    丁黄药  BK205   水玻璃    硝酸铅  矿浆浓度  CYB-05  CYB-06  CYQ-03\n",
       "0   1000   80.0   40.0   30.0     0    0.0    42     0.0     0.0     0.0\n",
       "1   1000   80.0   40.0   30.0   300    0.0    42     0.0     0.0     0.0\n",
       "2   1000   80.0   40.0   30.0   600    0.0    42     0.0     0.0     0.0\n",
       "3   1000   80.0   40.0   30.0   900    0.0    42     0.0     0.0     0.0\n",
       "4   1000   80.0   40.0   30.0  1200    0.0    42     0.0     0.0     0.0\n",
       "5   1000   80.0   40.0   30.0  1500    0.0    42     0.0     0.0     0.0\n",
       "6      0   80.0   40.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "7    400   80.0   40.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "8    800   80.0   40.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "9   1000   80.0   40.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "10  1200   80.0   40.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "11  1000   80.0   40.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "12  1000   80.0   40.0   30.0  1000  200.0    42     0.0     0.0     0.0\n",
       "13  1000   80.0   40.0   30.0  1000  400.0    42     0.0     0.0     0.0\n",
       "14  1000   80.0   40.0   30.0  1000  600.0    42     0.0     0.0     0.0\n",
       "15  1000   80.0   40.0   30.0  1000  800.0    42     0.0     0.0     0.0\n",
       "16  1000   80.0   40.0   30.0   500    0.0    42     0.0     0.0     0.0\n",
       "17  1000   80.0   40.0   30.0   500  200.0    42     0.0     0.0     0.0\n",
       "18  1000   80.0   40.0   30.0   500  400.0    42     0.0     0.0     0.0\n",
       "19  1000   80.0   40.0   30.0   500  600.0    42     0.0     0.0     0.0\n",
       "20  1000   80.0   40.0   30.0   500  800.0    42     0.0     0.0     0.0\n",
       "21  1000   80.0   40.0   30.0  1000    0.0    30     0.0     0.0     0.0\n",
       "22  1000   80.0   40.0   30.0  1000    0.0    35     0.0     0.0     0.0\n",
       "23  1000   80.0   40.0   30.0  1000    0.0    40     0.0     0.0     0.0\n",
       "24  1000   80.0   40.0   30.0  1000    0.0    45     0.0     0.0     0.0\n",
       "25  1000   80.0   40.0   30.0  1000    0.0    50     0.0     0.0     0.0\n",
       "26  1000   80.0   40.0   30.0  1000    0.0    55     0.0     0.0     0.0\n",
       "27  1000   80.0   40.0   30.0  1000    0.0    60     0.0     0.0     0.0\n",
       "28  1000    0.0  120.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "29  1000   20.0  100.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "30  1000   40.0   80.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "31  1000   60.0   60.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "32  1000   80.0   40.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "33  1000  100.0   20.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "34  1000  120.0    0.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "35  1000   26.0   13.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "36  1000   52.0   26.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "37  1000   78.0   39.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "38  1000  104.0   52.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "39  1000    0.0    0.0   30.0  1000    0.0    42    40.0     0.0     0.0\n",
       "40  1000    0.0    0.0   30.0  1000    0.0    42    80.0     0.0     0.0\n",
       "41  1000    0.0    0.0   30.0  1000    0.0    42   120.0     0.0     0.0\n",
       "42  1000    0.0    0.0   30.0  1000    0.0    42   160.0     0.0     0.0\n",
       "43  1000    0.0    0.0   30.0  1000    0.0    42     0.0    40.0     0.0\n",
       "44  1000    0.0    0.0   30.0  1000    0.0    42     0.0    80.0     0.0\n",
       "45  1000    0.0    0.0   30.0  1000    0.0    42     0.0   120.0     0.0\n",
       "46  1000    0.0    0.0   30.0  1000    0.0    42     0.0   160.0     0.0\n",
       "47  1000   80.0   40.0    0.0  1000    0.0    42     0.0     0.0    20.0\n",
       "48  1000   80.0   40.0    0.0  1000    0.0    42     0.0     0.0    40.0\n",
       "49  1000   80.0   40.0    0.0  1000    0.0    42     0.0     0.0    60.0\n",
       "50  1000   80.0   40.0    0.0  1000    0.0    42     0.0     0.0    80.0\n",
       "51  1000   80.0   40.0   20.0  1000    0.0    42     0.0     0.0     0.0\n",
       "52  1000   80.0   40.0   30.0  1000    0.0    42     0.0     0.0     0.0\n",
       "53  1000   80.0   40.0   40.0  1000    0.0    42     0.0     0.0     0.0\n",
       "54  1000   80.0   40.0   50.0  1000    0.0    42     0.0     0.0     0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80ecd993-6cf3-4ce6-a7d1-977f562494c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均 R^2 分数: 0.7136209433380425\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 初始化随机森林回归器\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# 设置留一交叉验证\n",
    "loo = LeaveOneOut()\n",
    "# 保存每次分割的预测值和真实值\n",
    "y_true = []\n",
    "y_pred = []\n",
    "# 执行留一交叉验证\n",
    "for train_index, test_index in loo.split(x_filled):\n",
    "    x_train, x_test = x_filled.iloc[train_index], x_filled.iloc[test_index]\n",
    "    y_train, y_test = y1.iloc[train_index], y1.iloc[test_index]\n",
    "    \n",
    "    # 训练模型并预测\n",
    "    rf.fit(x_train, y_train)\n",
    "    y_pred.append(rf.predict(x_test)[0])\n",
    "    y_true.append(y_test.values[0])\n",
    "\n",
    "# 计算总体的 R^2 分数\n",
    "overall_r2 = r2_score(y_true, y_pred)\n",
    "print(\"平均 R^2 分数:\", overall_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1d811-5f6d-46a2-b8a7-44a36a11569c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64883e55-06bc-4fcd-8049-aeb4c8628c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dbda66-6dda-4da8-b629-165f3db33342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb757c-33e2-4897-9611-43677097af6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4fc754-2d72-4abd-a940-ceed04a36fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4974870-dd52-497e-b664-dafd59341036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 初始化留一交叉验证\n",
    "# loo = LeaveOneOut()\n",
    "\n",
    "# # 存储每个目标的 R^2 分数\n",
    "# mean_r2_scores = {}\n",
    "\n",
    "# # 对每个目标变量进行预测和计算 R^2\n",
    "# for target in y.columns:\n",
    "#     y_true, y_pred = [], []\n",
    "#     rf = RandomForestRegressor(random_state=42)  # 每个目标单独的随机森林模型\n",
    "    \n",
    "#     for train_index, test_index in loo.split(x_filled):\n",
    "#         # 划分训练集和测试集\n",
    "#         x_train, x_test = x_filled.iloc[train_index], x_filled.iloc[test_index]\n",
    "#         y_train, y_test = y[target].iloc[train_index], y[target].iloc[test_index]\n",
    "        \n",
    "#         # 训练模型\n",
    "#         rf.fit(x_train, y_train)\n",
    "        \n",
    "#         # 预测并保存结果\n",
    "#         y_pred_single = rf.predict(x_test)[0]\n",
    "#         y_pred.append(y_pred_single)\n",
    "#         y_true.append(y_test.values[0])\n",
    "\n",
    "#     # 使用整体的真实值和预测值计算 R^2\n",
    "#     mean_r2_scores[target] = r2_score(y_true, y_pred)\n",
    "#     print(f\"{target} 的平均 R^2 值: {mean_r2_scores[target]}\")\n",
    "\n",
    "# # 输出每个目标的平均 R^2 值\n",
    "# print(\"所有目标的平均 R^2 值:\", mean_r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a4cf53a-fb52-4ce8-b207-3b6e23364765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 rf_model 已经训练好用于预测 y1\n",
    "def predict_bi_function_rf(new_data):\n",
    "    \n",
    "    # 将输入数据转换为 NumPy 数组\n",
    "    new_data_numpy = new_data.cpu().numpy().astype(np.float64)\n",
    "    \n",
    "    # 将 NumPy 数组转换为 pandas DataFrame，并提供列名\n",
    "    feature_names = ['碳酸钠', '乙硫氮', '丁黄药', 'BK205', '水玻璃', '硝酸铅', '矿浆浓度', 'CYB-05', 'CYB-06', 'CYQ-03']  # 根据特征名设定列名\n",
    "    new_data_df = pd.DataFrame(new_data_numpy, columns=feature_names)\n",
    "    \n",
    "    # 使用随机森林模型进行预测，确保特征顺序正确\n",
    "    Bi_pred = rf.predict(new_data_df[feature_names])\n",
    "    \n",
    "    # 将预测值转换为 PyTorch 张量，并返回 float64 类型\n",
    "    return torch.tensor(Bi_pred, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b32e072-088f-4b57-b03a-eb75c5465f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义每个维度的范围\n",
    "dim_ranges = [\n",
    "    (0, 1200),       # 第1维度范围\n",
    "    (0, 120),     # 第2维度范围\n",
    "    (0, 120),      # 第3维度范围\n",
    "    (0, 50),   # 第4维度范围\n",
    "    (0, 1500),    # 第5维度范围\n",
    "    (0, 800),     # 第6维度范围\n",
    "    (40, 60),       # 第7维度范围\n",
    "    (0, 160),    # 第8维度范围\n",
    "    (0, 160),    # 第9维度范围\n",
    "    (0, 80)   # 第10维度范围\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccde1c27-58c7-4d54-a244-fa99360f7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机生成1000个点\n",
    "n_samples = 1000\n",
    "random_data = np.array([np.random.uniform(low, high, n_samples) for low, high in dim_ranges]).T\n",
    "random_data_tensor = torch.tensor(random_data, dtype=torch.float64)\n",
    "\n",
    "# 预测函数值\n",
    "bi_predictions_rf = predict_bi_function_rf(random_data_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6749f510-005a-4ccc-b0b9-1c2831dbf354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 将预测结果转换为 NumPy 数组，绘制直方图\n",
    "bi_predictions_np = bi_predictions_rf.numpy()\n",
    "plt.hist(bi_predictions_np, bins=30, color='blue', edgecolor='black')\n",
    "plt.xlabel('Bi Prediction')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Bi Predictions rf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5426c0da-8497-4bea-98f0-f65154c3666b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均 R^2 分数: 0.8205324316712244\n"
     ]
    }
   ],
   "source": [
    "# 初始化 XGBoost 回归器\n",
    "xgboost_model = XGBRegressor()\n",
    "\n",
    "# 设置留一交叉验证\n",
    "loo = LeaveOneOut()\n",
    "# 保存每次分割的预测值和真实值\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# 执行留一交叉验证\n",
    "for train_index, test_index in loo.split(x_filled):\n",
    "    x_train, x_test = x_filled.iloc[train_index], x_filled.iloc[test_index]\n",
    "    y_train, y_test = y1.iloc[train_index], y1.iloc[test_index]\n",
    "    \n",
    "    # 训练 XGBoost 模型并预测\n",
    "    xgboost_model.fit(x_train, y_train)\n",
    "    y_pred.append(xgboost_model.predict(x_test)[0])\n",
    "    y_true.append(y_test.values[0])\n",
    "\n",
    "# 计算总体的 R^2 分数\n",
    "overall_r2 = r2_score(y_true, y_pred)\n",
    "print(\"平均 R^2 分数:\", overall_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de353da4-da34-43c5-95e9-97f093a669a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 rf_model 已经训练好用于预测 y1\n",
    "def predict_bi_function_xg(new_data):\n",
    "    \n",
    "    # 将输入数据转换为 NumPy 数组\n",
    "    new_data_numpy = new_data.cpu().numpy().astype(np.float64)\n",
    "    \n",
    "    # 将 NumPy 数组转换为 pandas DataFrame，并提供列名\n",
    "    feature_names = ['碳酸钠', '乙硫氮', '丁黄药', 'BK205', '水玻璃', '硝酸铅', '矿浆浓度', 'CYB-05', 'CYB-06', 'CYQ-03']  # 根据特征名设定列名\n",
    "    new_data_df = pd.DataFrame(new_data_numpy, columns=feature_names)\n",
    "    \n",
    "    # 使用随机森林模型进行预测，确保特征顺序正确\n",
    "    Bi_pred = xgboost_model.predict(new_data_df[feature_names])\n",
    "    \n",
    "    # 将预测值转换为 PyTorch 张量，并返回 float64 类型\n",
    "    return torch.tensor(Bi_pred, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6b93a28-72b9-400a-8cc1-f2c7c1107ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 预测函数值\n",
    "bi_predictions_xg = predict_bi_function_xg(random_data_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa6889d3-0455-43eb-81cf-fddbbdfa2c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 将预测结果转换为 NumPy 数组，绘制直方图\n",
    "bi_predictions_np = bi_predictions_xg.numpy()\n",
    "plt.hist(bi_predictions_np, bins=30, color='blue', edgecolor='black')\n",
    "plt.xlabel('Bi Prediction')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Bi Predictions xg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9be72f3-1e30-4a38-b568-970207dcbfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 创建平方特征\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "# x_with_poly = poly.fit_transform(x_filled)  # 包含原始特征和平方特征\n",
    "\n",
    "# # 标准化\n",
    "# scaler = StandardScaler()\n",
    "# x_scaled_poly = scaler.fit_transform(x_with_poly)\n",
    "\n",
    "# # 初始化 Lasso 回归器\n",
    "# lasso_model = Lasso()\n",
    "\n",
    "# # 设置留一交叉验证\n",
    "# loo = LeaveOneOut()\n",
    "# # 保存每次分割的预测值和真实值\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "# # 执行留一交叉验证\n",
    "# for train_index, test_index in loo.split(x_scaled_poly):\n",
    "#     x_train, x_test = x_scaled_poly[train_index], x_scaled_poly[test_index]\n",
    "#     y_train, y_test = y1.iloc[train_index], y1.iloc[test_index]\n",
    "    \n",
    "#     # 训练 Lasso 模型并预测\n",
    "#     lasso_model.fit(x_train, y_train)\n",
    "#     y_pred.append(lasso_model.predict(x_test)[0])\n",
    "#     y_true.append(y_test.values[0])\n",
    "\n",
    "# # 计算总体的 R^2 分数\n",
    "# overall_r2 = r2_score(y_true, y_pred)\n",
    "# print(\"平均 R^2 分数:\", overall_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770aaf53-4570-41a1-89c3-6b012f3efa16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ae4ca82-88ec-470d-8633-1943eacdf9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 假设 rf_model 是之前已经训练好的模型\n",
    "# def predict_mo_function(new_data):\n",
    "\n",
    "    \n",
    "#     # 将输入数据转换为 NumPy 数组\n",
    "#     new_data_numpy = new_data.cpu().numpy().astype(np.float64)\n",
    "    \n",
    "#     # 将 NumPy 数组转换为 pandas DataFrame，并提供列名\n",
    "#     feature_names = ['碳酸钠', '乙硫氮', '丁黄药', 'BK205', '水玻璃',  '硝酸铅', '矿浆浓度', 'CYB-05', 'CYB-06', 'CYQ-03']  # 根据特征名设定列名\n",
    "#     new_data_df = pd.DataFrame(new_data_numpy, columns=feature_names)\n",
    "    \n",
    "#     # 使用随机森林模型进行预测，确保特征顺序正确\n",
    "#     Mo_pred = rf.predict(new_data_df[['碳酸钠', '乙硫氮', '丁黄药', 'BK205', '水玻璃',  '硝酸铅', '矿浆浓度', 'CYB-05', 'CYB-06', 'CYQ-03']])\n",
    "    \n",
    "#     # 将预测值转换为 PyTorch 张量，并返回 float64 类型\n",
    "#     return torch.tensor(Mo_pred, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfb35590-5a3f-4c88-9898-6e8618d3b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_tensor_batch(dim_ranges, num_samples=5):\n",
    "    \"\"\"\n",
    "    随机生成一个二维张量，每行是一个10维数据，每个维度有单独的区间范围。\n",
    "\n",
    "    参数:\n",
    "    dim_ranges (list of tuples): 每个元素是一个包含(min, max)的元组，表示该维度的范围。\n",
    "    num_samples (int): 每次生成的样本数，默认是5。\n",
    "\n",
    "    返回:\n",
    "    torch.Tensor: 生成的二维张量，形状为(num_samples, 10)，dtype=torch.float64, device='cuda:0'。\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        sample = [torch.DoubleTensor(1).uniform_(low, high).item() for low, high in dim_ranges]\n",
    "        data.append(sample)\n",
    "    tensor_batch = torch.tensor(data, device='cuda:0', dtype=torch.float64)\n",
    "    return tensor_batch\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36e030a2-f7ef-4300-afc4-a4258664214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成十次，每次生成一个5x10的二维张量\n",
    "tensors = [generate_random_tensor_batch(dim_ranges) for _ in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10852767-5f2e-40cf-83cf-55fd63da8cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[3.4184e+02, 1.9690e+00, 9.8791e+01, 3.7921e+01, 7.5024e+02, 2.0982e+02,\n",
       "          5.3923e+01, 7.5682e+01, 1.4006e+02, 1.9229e+01],\n",
       "         [3.6221e+02, 1.2058e+00, 5.6277e+01, 4.0617e+01, 1.0702e+03, 7.9879e+02,\n",
       "          5.8215e+01, 1.5645e+01, 1.4941e+02, 5.1372e+01],\n",
       "         [8.5012e+02, 6.2660e+01, 1.4704e+01, 2.6075e+01, 1.1994e+03, 5.8682e+02,\n",
       "          4.3437e+01, 5.0589e+01, 2.1980e+01, 8.3418e+00],\n",
       "         [9.9788e+02, 8.6128e+01, 8.2381e+01, 2.0644e+01, 1.3724e+03, 5.7371e+02,\n",
       "          5.0069e+01, 5.4028e+01, 1.4771e+02, 4.9593e+01],\n",
       "         [6.4233e+02, 1.1346e+02, 3.4487e+01, 2.5174e+00, 8.2257e+02, 3.7235e+01,\n",
       "          4.6280e+01, 6.7757e+01, 8.1175e+01, 9.9483e+00]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[8.7163e+01, 3.5610e+00, 1.7020e+01, 1.1857e+01, 1.1409e+03, 2.9783e+02,\n",
       "          4.7401e+01, 2.8070e+01, 8.0562e+01, 7.9235e+01],\n",
       "         [1.1215e+03, 8.1793e+01, 1.2646e+01, 7.2920e+00, 1.1105e+03, 7.1397e+01,\n",
       "          4.3776e+01, 4.1093e-01, 2.2449e+01, 5.7891e+01],\n",
       "         [7.2925e+02, 4.5991e+01, 4.7922e+01, 4.3188e+01, 1.0140e+03, 1.4440e+02,\n",
       "          4.5051e+01, 7.7157e+01, 9.5538e+01, 6.6766e+01],\n",
       "         [2.4841e+02, 3.9029e+01, 2.3172e+01, 2.7306e+01, 9.4365e+02, 1.5132e+02,\n",
       "          4.6110e+01, 6.1055e+01, 7.5956e+01, 7.6859e+01],\n",
       "         [1.0197e+03, 7.4210e+01, 8.5811e+01, 5.1069e+00, 8.1936e+02, 7.9870e+02,\n",
       "          5.2401e+01, 1.3262e+02, 4.6005e+01, 2.0828e+00]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[1089.2396,   78.0076,  107.9582,   13.6721,  915.9850,  434.3955,\n",
       "            52.9896,  100.5988,  106.1669,   11.1080],\n",
       "         [ 371.2330,   54.2200,   35.3618,   18.7707,  286.2199,  734.8804,\n",
       "            53.1260,   26.9835,   76.6771,   37.6968],\n",
       "         [ 266.2530,  104.6275,   44.1561,   47.7926, 1079.6652,  525.3959,\n",
       "            50.5033,   61.2882,   62.1187,   63.1404],\n",
       "         [ 402.3087,  113.9892,    4.3447,   10.2045,  129.0450,  304.5634,\n",
       "            43.3355,   73.3621,   52.7524,   36.7417],\n",
       "         [ 200.1535,  101.3917,   92.5688,   10.5239,  239.4705,  398.5315,\n",
       "            53.3588,   55.9908,   22.0208,   77.6007]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[ 975.5257,   75.7973,   97.4184,    9.7173,  106.6926,  451.4654,\n",
       "            45.1821,   12.0112,   24.6909,   16.3742],\n",
       "         [ 641.8907,   59.1715,    2.3275,   12.8983,  675.0399,  796.5588,\n",
       "            55.6736,   49.7215,   81.3868,    8.0365],\n",
       "         [ 131.6560,    8.9748,    2.9430,   19.5062,  960.8623,  117.0835,\n",
       "            42.6072,   12.9522,   77.2567,   31.8659],\n",
       "         [ 957.4030,  108.2847,    3.7889,    6.0420, 1169.0379,  507.3486,\n",
       "            41.9790,  114.1495,   56.5446,   46.6285],\n",
       "         [ 543.9748,   78.4735,   94.0992,   27.6257, 1144.5549,  292.3492,\n",
       "            43.3666,  109.5231,   53.6293,   76.3860]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[ 957.2990,  114.5814,  119.7566,   22.1784,  580.8580,  369.7469,\n",
       "            43.1374,  153.0257,   88.2778,   25.1513],\n",
       "         [1005.1571,   78.6979,  107.4027,   31.9806,  731.7871,  363.0733,\n",
       "            43.2728,   19.5839,  127.7233,   21.5319],\n",
       "         [ 204.9743,  114.6409,   69.5192,   14.9780, 1326.8383,   32.1989,\n",
       "            49.7994,  125.6573,  159.3024,   19.6523],\n",
       "         [ 705.0015,   98.5678,   71.2594,    2.5301,   55.8065,  531.0915,\n",
       "            47.0542,   24.5839,  100.1481,   78.0224],\n",
       "         [  44.6417,   98.2833,   33.8330,   46.5741,  886.5213,  364.4133,\n",
       "            40.3616,  120.4623,   53.2566,   32.8309]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[8.3487e+02, 3.7781e+01, 6.7576e+01, 3.4817e+01, 7.3967e+02, 1.1073e+02,\n",
       "          4.6184e+01, 9.7690e+00, 1.8519e+00, 2.6908e+01],\n",
       "         [1.9834e+02, 3.5492e+01, 6.4748e+01, 2.5186e+01, 8.3869e+01, 5.7601e+02,\n",
       "          5.7008e+01, 3.5315e+01, 1.4418e+02, 7.2061e+00],\n",
       "         [1.2088e+02, 3.1864e+01, 6.3096e+01, 4.4615e+01, 1.2117e+03, 4.6117e+02,\n",
       "          5.8921e+01, 1.1346e+02, 2.2059e+01, 7.3192e+01],\n",
       "         [1.0915e+03, 8.4056e+01, 4.3915e+01, 1.2070e+01, 6.9677e+02, 7.9252e+02,\n",
       "          4.2287e+01, 8.3152e+01, 1.1297e+01, 3.6502e+01],\n",
       "         [7.6507e+02, 6.6852e+01, 3.5124e+01, 3.9579e+01, 1.8612e+02, 5.5315e+02,\n",
       "          5.2762e+01, 1.2542e+02, 9.1622e+01, 2.3322e-01]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[2.7407e+02, 1.0158e+02, 2.6207e+01, 2.9812e+01, 1.2403e+03, 4.2020e+02,\n",
       "          4.3232e+01, 4.6422e+01, 1.3633e+02, 1.2846e+01],\n",
       "         [1.1588e+03, 6.7166e+01, 3.6018e+01, 2.0330e+01, 7.3465e+02, 2.7304e+02,\n",
       "          4.3777e+01, 1.0825e+02, 7.3245e+01, 1.7409e+00],\n",
       "         [7.2736e+02, 3.7359e+01, 2.7838e+01, 4.4994e+01, 6.7884e+02, 5.7656e+02,\n",
       "          4.7248e+01, 1.5862e+01, 1.5852e+02, 4.8607e+01],\n",
       "         [7.0483e+02, 3.2612e-01, 4.9636e+01, 3.2278e+01, 6.3977e+02, 2.6749e+02,\n",
       "          5.9483e+01, 1.3580e+02, 8.0070e+01, 5.5668e+01],\n",
       "         [9.3328e+02, 2.0649e+01, 3.8957e+01, 1.3124e+01, 1.2519e+03, 1.2955e+02,\n",
       "          5.9328e+01, 1.3711e+02, 1.3935e+02, 6.2361e+01]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[1.0477e+03, 1.0276e+02, 9.8685e+01, 1.9143e+01, 2.8138e+02, 4.0193e+02,\n",
       "          4.4285e+01, 8.3141e+01, 6.2694e+01, 6.9649e+01],\n",
       "         [3.3544e+02, 8.7918e+00, 1.1059e+02, 3.8653e+01, 4.5654e+02, 5.7986e+02,\n",
       "          4.7938e+01, 5.0211e+01, 1.1085e+02, 2.5496e+01],\n",
       "         [1.1548e+03, 7.4763e+01, 1.1039e+02, 4.8142e+01, 1.5808e+02, 2.0698e+02,\n",
       "          4.6601e+01, 1.0942e+02, 5.9340e+01, 2.3616e+01],\n",
       "         [3.5968e+02, 2.6152e+01, 8.1701e+01, 2.4089e+01, 1.4360e+03, 3.1059e+00,\n",
       "          5.1369e+01, 5.1384e+01, 1.3409e+00, 2.2767e+01],\n",
       "         [9.7731e+02, 3.8286e+01, 3.0578e+01, 1.0762e+01, 1.3673e+03, 1.7356e+02,\n",
       "          4.2212e+01, 1.1171e+02, 1.5604e+02, 4.8352e+01]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[6.5417e+02, 4.5062e+01, 7.2948e+01, 1.2145e+01, 1.3197e+03, 2.3310e+01,\n",
       "          4.3512e+01, 3.3130e+01, 3.8106e+01, 1.4550e+01],\n",
       "         [2.2071e+02, 1.3995e+01, 3.2416e+01, 2.8952e+01, 5.5420e+02, 6.3027e+02,\n",
       "          5.8717e+01, 1.0903e+02, 8.5038e+01, 2.4416e-01],\n",
       "         [3.4589e+02, 4.4364e+01, 8.1701e+01, 2.8330e+01, 1.0728e+03, 7.6572e+02,\n",
       "          5.3650e+01, 1.6991e+01, 1.2770e+02, 2.3919e+01],\n",
       "         [9.5245e+02, 5.5016e+01, 5.0517e-01, 4.9695e+01, 1.1746e+03, 2.5010e+02,\n",
       "          4.1631e+01, 1.9245e+01, 1.4036e+02, 6.4667e+01],\n",
       "         [1.4139e+02, 8.4173e+01, 1.1177e+02, 1.6270e+01, 4.2586e+02, 2.7306e+01,\n",
       "          5.4309e+01, 1.3814e+02, 5.1891e+00, 2.3243e+01]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[ 373.5851,   42.3481,   28.2132,   47.7716,  401.0603,  708.0976,\n",
       "            45.3799,  139.8014,   74.1156,   70.0049],\n",
       "         [ 365.8422,   60.6736,   12.3250,   27.3812,  229.3148,  487.7974,\n",
       "            56.4798,  100.3647,  140.4854,   72.4745],\n",
       "         [ 199.3768,   19.6290,   91.8926,   33.6921,  706.9081,  493.1646,\n",
       "            41.0089,   87.0028,   48.8923,   73.7453],\n",
       "         [ 912.3393,   44.5452,   84.8709,   35.8131,  475.3241,  493.1233,\n",
       "            41.8152,  147.0894,  131.1938,   63.9720],\n",
       "         [ 943.6881,   30.6485,   73.7431,   43.8560, 1003.7825,  326.9272,\n",
       "            42.8058,  100.8544,   36.5746,   53.3754]], device='cuda:0',\n",
       "        dtype=torch.float64)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbdca1f-bae0-4ced-8bb4-fb7324020a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49c257cb-ae3c-4689-8948-b8b8054b98f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_points_task11 = tensors\n",
    "initial_points_task22 = None  # 如果你没有任务2的初始点，可以设置为 None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06ed8191-2161-4f7c-b43a-26fd5c568d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[3.4184e+02, 1.9690e+00, 9.8791e+01, 3.7921e+01, 7.5024e+02, 2.0982e+02,\n",
       "          5.3923e+01, 7.5682e+01, 1.4006e+02, 1.9229e+01],\n",
       "         [3.6221e+02, 1.2058e+00, 5.6277e+01, 4.0617e+01, 1.0702e+03, 7.9879e+02,\n",
       "          5.8215e+01, 1.5645e+01, 1.4941e+02, 5.1372e+01],\n",
       "         [8.5012e+02, 6.2660e+01, 1.4704e+01, 2.6075e+01, 1.1994e+03, 5.8682e+02,\n",
       "          4.3437e+01, 5.0589e+01, 2.1980e+01, 8.3418e+00],\n",
       "         [9.9788e+02, 8.6128e+01, 8.2381e+01, 2.0644e+01, 1.3724e+03, 5.7371e+02,\n",
       "          5.0069e+01, 5.4028e+01, 1.4771e+02, 4.9593e+01],\n",
       "         [6.4233e+02, 1.1346e+02, 3.4487e+01, 2.5174e+00, 8.2257e+02, 3.7235e+01,\n",
       "          4.6280e+01, 6.7757e+01, 8.1175e+01, 9.9483e+00]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[8.7163e+01, 3.5610e+00, 1.7020e+01, 1.1857e+01, 1.1409e+03, 2.9783e+02,\n",
       "          4.7401e+01, 2.8070e+01, 8.0562e+01, 7.9235e+01],\n",
       "         [1.1215e+03, 8.1793e+01, 1.2646e+01, 7.2920e+00, 1.1105e+03, 7.1397e+01,\n",
       "          4.3776e+01, 4.1093e-01, 2.2449e+01, 5.7891e+01],\n",
       "         [7.2925e+02, 4.5991e+01, 4.7922e+01, 4.3188e+01, 1.0140e+03, 1.4440e+02,\n",
       "          4.5051e+01, 7.7157e+01, 9.5538e+01, 6.6766e+01],\n",
       "         [2.4841e+02, 3.9029e+01, 2.3172e+01, 2.7306e+01, 9.4365e+02, 1.5132e+02,\n",
       "          4.6110e+01, 6.1055e+01, 7.5956e+01, 7.6859e+01],\n",
       "         [1.0197e+03, 7.4210e+01, 8.5811e+01, 5.1069e+00, 8.1936e+02, 7.9870e+02,\n",
       "          5.2401e+01, 1.3262e+02, 4.6005e+01, 2.0828e+00]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[1089.2396,   78.0076,  107.9582,   13.6721,  915.9850,  434.3955,\n",
       "            52.9896,  100.5988,  106.1669,   11.1080],\n",
       "         [ 371.2330,   54.2200,   35.3618,   18.7707,  286.2199,  734.8804,\n",
       "            53.1260,   26.9835,   76.6771,   37.6968],\n",
       "         [ 266.2530,  104.6275,   44.1561,   47.7926, 1079.6652,  525.3959,\n",
       "            50.5033,   61.2882,   62.1187,   63.1404],\n",
       "         [ 402.3087,  113.9892,    4.3447,   10.2045,  129.0450,  304.5634,\n",
       "            43.3355,   73.3621,   52.7524,   36.7417],\n",
       "         [ 200.1535,  101.3917,   92.5688,   10.5239,  239.4705,  398.5315,\n",
       "            53.3588,   55.9908,   22.0208,   77.6007]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[ 975.5257,   75.7973,   97.4184,    9.7173,  106.6926,  451.4654,\n",
       "            45.1821,   12.0112,   24.6909,   16.3742],\n",
       "         [ 641.8907,   59.1715,    2.3275,   12.8983,  675.0399,  796.5588,\n",
       "            55.6736,   49.7215,   81.3868,    8.0365],\n",
       "         [ 131.6560,    8.9748,    2.9430,   19.5062,  960.8623,  117.0835,\n",
       "            42.6072,   12.9522,   77.2567,   31.8659],\n",
       "         [ 957.4030,  108.2847,    3.7889,    6.0420, 1169.0379,  507.3486,\n",
       "            41.9790,  114.1495,   56.5446,   46.6285],\n",
       "         [ 543.9748,   78.4735,   94.0992,   27.6257, 1144.5549,  292.3492,\n",
       "            43.3666,  109.5231,   53.6293,   76.3860]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[ 957.2990,  114.5814,  119.7566,   22.1784,  580.8580,  369.7469,\n",
       "            43.1374,  153.0257,   88.2778,   25.1513],\n",
       "         [1005.1571,   78.6979,  107.4027,   31.9806,  731.7871,  363.0733,\n",
       "            43.2728,   19.5839,  127.7233,   21.5319],\n",
       "         [ 204.9743,  114.6409,   69.5192,   14.9780, 1326.8383,   32.1989,\n",
       "            49.7994,  125.6573,  159.3024,   19.6523],\n",
       "         [ 705.0015,   98.5678,   71.2594,    2.5301,   55.8065,  531.0915,\n",
       "            47.0542,   24.5839,  100.1481,   78.0224],\n",
       "         [  44.6417,   98.2833,   33.8330,   46.5741,  886.5213,  364.4133,\n",
       "            40.3616,  120.4623,   53.2566,   32.8309]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[8.3487e+02, 3.7781e+01, 6.7576e+01, 3.4817e+01, 7.3967e+02, 1.1073e+02,\n",
       "          4.6184e+01, 9.7690e+00, 1.8519e+00, 2.6908e+01],\n",
       "         [1.9834e+02, 3.5492e+01, 6.4748e+01, 2.5186e+01, 8.3869e+01, 5.7601e+02,\n",
       "          5.7008e+01, 3.5315e+01, 1.4418e+02, 7.2061e+00],\n",
       "         [1.2088e+02, 3.1864e+01, 6.3096e+01, 4.4615e+01, 1.2117e+03, 4.6117e+02,\n",
       "          5.8921e+01, 1.1346e+02, 2.2059e+01, 7.3192e+01],\n",
       "         [1.0915e+03, 8.4056e+01, 4.3915e+01, 1.2070e+01, 6.9677e+02, 7.9252e+02,\n",
       "          4.2287e+01, 8.3152e+01, 1.1297e+01, 3.6502e+01],\n",
       "         [7.6507e+02, 6.6852e+01, 3.5124e+01, 3.9579e+01, 1.8612e+02, 5.5315e+02,\n",
       "          5.2762e+01, 1.2542e+02, 9.1622e+01, 2.3322e-01]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[2.7407e+02, 1.0158e+02, 2.6207e+01, 2.9812e+01, 1.2403e+03, 4.2020e+02,\n",
       "          4.3232e+01, 4.6422e+01, 1.3633e+02, 1.2846e+01],\n",
       "         [1.1588e+03, 6.7166e+01, 3.6018e+01, 2.0330e+01, 7.3465e+02, 2.7304e+02,\n",
       "          4.3777e+01, 1.0825e+02, 7.3245e+01, 1.7409e+00],\n",
       "         [7.2736e+02, 3.7359e+01, 2.7838e+01, 4.4994e+01, 6.7884e+02, 5.7656e+02,\n",
       "          4.7248e+01, 1.5862e+01, 1.5852e+02, 4.8607e+01],\n",
       "         [7.0483e+02, 3.2612e-01, 4.9636e+01, 3.2278e+01, 6.3977e+02, 2.6749e+02,\n",
       "          5.9483e+01, 1.3580e+02, 8.0070e+01, 5.5668e+01],\n",
       "         [9.3328e+02, 2.0649e+01, 3.8957e+01, 1.3124e+01, 1.2519e+03, 1.2955e+02,\n",
       "          5.9328e+01, 1.3711e+02, 1.3935e+02, 6.2361e+01]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[1.0477e+03, 1.0276e+02, 9.8685e+01, 1.9143e+01, 2.8138e+02, 4.0193e+02,\n",
       "          4.4285e+01, 8.3141e+01, 6.2694e+01, 6.9649e+01],\n",
       "         [3.3544e+02, 8.7918e+00, 1.1059e+02, 3.8653e+01, 4.5654e+02, 5.7986e+02,\n",
       "          4.7938e+01, 5.0211e+01, 1.1085e+02, 2.5496e+01],\n",
       "         [1.1548e+03, 7.4763e+01, 1.1039e+02, 4.8142e+01, 1.5808e+02, 2.0698e+02,\n",
       "          4.6601e+01, 1.0942e+02, 5.9340e+01, 2.3616e+01],\n",
       "         [3.5968e+02, 2.6152e+01, 8.1701e+01, 2.4089e+01, 1.4360e+03, 3.1059e+00,\n",
       "          5.1369e+01, 5.1384e+01, 1.3409e+00, 2.2767e+01],\n",
       "         [9.7731e+02, 3.8286e+01, 3.0578e+01, 1.0762e+01, 1.3673e+03, 1.7356e+02,\n",
       "          4.2212e+01, 1.1171e+02, 1.5604e+02, 4.8352e+01]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[6.5417e+02, 4.5062e+01, 7.2948e+01, 1.2145e+01, 1.3197e+03, 2.3310e+01,\n",
       "          4.3512e+01, 3.3130e+01, 3.8106e+01, 1.4550e+01],\n",
       "         [2.2071e+02, 1.3995e+01, 3.2416e+01, 2.8952e+01, 5.5420e+02, 6.3027e+02,\n",
       "          5.8717e+01, 1.0903e+02, 8.5038e+01, 2.4416e-01],\n",
       "         [3.4589e+02, 4.4364e+01, 8.1701e+01, 2.8330e+01, 1.0728e+03, 7.6572e+02,\n",
       "          5.3650e+01, 1.6991e+01, 1.2770e+02, 2.3919e+01],\n",
       "         [9.5245e+02, 5.5016e+01, 5.0517e-01, 4.9695e+01, 1.1746e+03, 2.5010e+02,\n",
       "          4.1631e+01, 1.9245e+01, 1.4036e+02, 6.4667e+01],\n",
       "         [1.4139e+02, 8.4173e+01, 1.1177e+02, 1.6270e+01, 4.2586e+02, 2.7306e+01,\n",
       "          5.4309e+01, 1.3814e+02, 5.1891e+00, 2.3243e+01]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[ 373.5851,   42.3481,   28.2132,   47.7716,  401.0603,  708.0976,\n",
       "            45.3799,  139.8014,   74.1156,   70.0049],\n",
       "         [ 365.8422,   60.6736,   12.3250,   27.3812,  229.3148,  487.7974,\n",
       "            56.4798,  100.3647,  140.4854,   72.4745],\n",
       "         [ 199.3768,   19.6290,   91.8926,   33.6921,  706.9081,  493.1646,\n",
       "            41.0089,   87.0028,   48.8923,   73.7453],\n",
       "         [ 912.3393,   44.5452,   84.8709,   35.8131,  475.3241,  493.1233,\n",
       "            41.8152,  147.0894,  131.1938,   63.9720],\n",
       "         [ 943.6881,   30.6485,   73.7431,   43.8560, 1003.7825,  326.9272,\n",
       "            42.8058,  100.8544,   36.5746,   53.3754]], device='cuda:0',\n",
       "        dtype=torch.float64)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_points_task11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a5443e1-3d0e-4898-9c82-b3568c5d80e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gp_model_and_select_next_point(train_x, train_obj, device):\n",
    "    # 创建和拟合高斯过程模型\n",
    "    model = SingleTaskGP(\n",
    "        train_X=train_x,\n",
    "        train_Y=train_obj,\n",
    "        input_transform=Normalize(d=train_x.shape[1]),  # 使用输入的维度\n",
    "        outcome_transform=Standardize(m=1),  # 输出为一维\n",
    "    ).to(device)\n",
    "\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    # 找到当前最优值\n",
    "    best_value = train_obj.max()\n",
    "    X_baseline = train_x[train_obj.flatten() == best_value.item()]\n",
    "\n",
    "    qLogNEI = qLogNoisyExpectedImprovement(model=model, best_f=best_value, X_baseline=X_baseline)\n",
    "\n",
    "    # 设置每个维度的上下界\n",
    "    dim_ranges = [\n",
    "        (0, 1200),    # 第1维度范围\n",
    "        (0, 120),     # 第2维度范围\n",
    "        (0, 120),     # 第3维度范围\n",
    "        (0, 50),      # 第4维度范围\n",
    "        (0, 1500),    # 第5维度范围\n",
    "        (0, 800),     # 第6维度范围\n",
    "        (40, 60),     # 第7维度范围\n",
    "        (0, 160),     # 第8维度范围\n",
    "        (0, 160),     # 第9维度范围\n",
    "        (0, 80)       # 第10维度范围\n",
    "    ]\n",
    "    \n",
    "    lower_bounds = [dim[0] for dim in dim_ranges]\n",
    "    upper_bounds = [dim[1] for dim in dim_ranges]\n",
    "    \n",
    "    bounds = torch.tensor([lower_bounds, upper_bounds], device=device, dtype=torch.float64)\n",
    "    \n",
    "    new_point_analytic, _ = optimize_acqf(\n",
    "        acq_function=qLogNEI,\n",
    "        bounds=bounds,\n",
    "        q=1,  # 采样一个点\n",
    "        num_restarts=20,\n",
    "        raw_samples=100,\n",
    "        options={},\n",
    "    )\n",
    "    \n",
    "    return new_point_analytic.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3a5ecd3-2558-42d6-aedb-35f0c4f224cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.4184e+02, 1.9690e+00, 9.8791e+01, 3.7921e+01, 7.5024e+02, 2.0982e+02,\n",
      "         5.3923e+01, 7.5682e+01, 1.4006e+02, 1.9229e+01],\n",
      "        [3.6221e+02, 1.2058e+00, 5.6277e+01, 4.0617e+01, 1.0702e+03, 7.9879e+02,\n",
      "         5.8215e+01, 1.5645e+01, 1.4941e+02, 5.1372e+01],\n",
      "        [8.5012e+02, 6.2660e+01, 1.4704e+01, 2.6075e+01, 1.1994e+03, 5.8682e+02,\n",
      "         4.3437e+01, 5.0589e+01, 2.1980e+01, 8.3418e+00],\n",
      "        [9.9788e+02, 8.6128e+01, 8.2381e+01, 2.0644e+01, 1.3724e+03, 5.7371e+02,\n",
      "         5.0069e+01, 5.4028e+01, 1.4771e+02, 4.9593e+01],\n",
      "        [6.4233e+02, 1.1346e+02, 3.4487e+01, 2.5174e+00, 8.2257e+02, 3.7235e+01,\n",
      "         4.6280e+01, 6.7757e+01, 8.1175e+01, 9.9483e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[692.5402, 102.0307,  30.0148,   7.8911, 911.6174, 164.9416,  45.6230,\n",
      "          63.7569,  67.7788,   9.7425]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 7.16 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[724.0456, 112.5083,  40.5213,   4.7004, 936.6831, 126.6088,  46.6526,\n",
      "          64.8792,  90.1885,  16.7231]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 9.70 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[714.3369, 117.8050,  39.8392,   1.1942, 835.0603, 248.2777,  44.6631,\n",
      "          64.1641,  81.7279,  10.6874]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 14.89 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[796.4725, 110.7052,  28.5326,   4.9774, 816.9153, 116.3683,  44.8562,\n",
      "          69.8969,  79.1329,  16.0040]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 8.33 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[697.3981, 119.9974,  26.9439,   1.1995, 878.0939, 220.5248,  47.6154,\n",
      "          68.0163,  69.0538,  15.2639]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 9.95 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[773.3215, 116.5481,  29.0070,   0.9746, 949.7822, 146.9627,  45.9858,\n",
      "          70.7659,  85.6705,   6.8065]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 13.47 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[675.1490, 119.9562,  38.7088,   2.9320, 943.0621, 141.3806,  44.2620,\n",
      "          73.4400,  65.9400,  15.0076]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 13.50 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[793.3120, 119.7899,  43.3082,   3.1095, 876.4603, 109.0664,  46.8301,\n",
      "          64.4922,  59.9096,  10.2465]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 14.23 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[ 834.9720,   80.0939,   22.3980,   18.9615, 1120.4807,  474.8754,\n",
      "           44.2217,   55.6494,   39.0198,   10.7194]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 7.11 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[ 785.2293,   72.8709,    9.8932,   20.9301, 1092.7474,  452.3696,\n",
      "           43.1816,   53.9533,   18.0575,    3.2874]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 9 took 7.88 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[ 815.9568,   73.0312,   18.6625,   24.1009, 1231.3462,  359.3493,\n",
      "           42.6094,   50.0391,   36.4510,    9.8350]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 12.70 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[ 870.7698,   55.3508,   22.1512,   16.6436, 1192.9827,  432.1672,\n",
      "           44.0140,   55.2245,   20.1924,    9.0483]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 9.51 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[ 881.5806,   76.4156,   20.9392,   23.9051, 1209.3933,  420.1856,\n",
      "           45.3472,   59.7455,   13.0621,    6.9682]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 11.64 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[ 897.7553,   77.1684,   16.9534,   16.4428, 1167.3600,  482.8112,\n",
      "           43.4528,   44.2577,   15.5316,   10.2074]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 9.62 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[ 915.3229,   71.2926,   28.1902,   18.7518, 1149.1859,  509.3438,\n",
      "           41.3885,   51.9298,   29.2971,    3.7190]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 14 took 13.34 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[ 853.5646,   70.9424,    3.3908,   16.0773, 1211.6563,  504.5798,\n",
      "           43.2237,   55.0322,   28.9720,   14.4065]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 7.03 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[ 780.6091,   68.4635,   26.2120,   18.9299, 1144.7295,  484.1357,\n",
      "           43.7316,   48.3988,    9.3013,   16.5766]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 14.55 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[ 809.4039,   67.2669,   18.1469,   16.9523, 1201.4736,  494.2699,\n",
      "           45.9714,   44.0685,   34.4747,    7.0134]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 7.72 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[ 909.6291,   62.2225,   13.0020,   21.2629, 1078.2741,  408.9454,\n",
      "           44.5459,   47.1016,   28.2360,   14.7280]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 7.47 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[ 879.9145,   88.7987,   31.2198,    6.0171, 1093.9356,  301.8179,\n",
      "           45.0546,   52.0871,   42.7196,   19.2987]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 8.69 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[ 966.1811,   90.7778,   52.1462,   14.9408, 1238.5040,  472.4339,\n",
      "           46.5862,   55.1739,   85.0120,   30.9943]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 6.47 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[ 939.9013,   70.2133,   31.7520,   16.6360, 1230.4711,  480.1716,\n",
      "           44.8908,   47.4774,   35.8708,   21.0613]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 6.97 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[ 861.2455,  120.0000,   29.1226,   13.3741, 1054.3856,  380.5423,\n",
      "           45.2589,   48.8782,   64.7147,   20.8933]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 22 took 6.81 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[ 886.5578,  103.5650,   47.1788,    6.6652, 1006.4276,  502.1458,\n",
      "           46.8019,   64.2226,   65.2621,   21.5378]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 7.08 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[ 968.6738,  120.0000,   69.3844,    7.4894, 1206.9537,  401.0774,\n",
      "           47.7502,   58.3274,  131.6299,   39.1453]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 24 took 7.17 seconds\n",
      "最优点: [0.8331813812255859, 0.8331813812255859, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.361149787902832, 1.361149787902832, 1.361149787902832, 1.361149787902832, 1.361149787902832, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638]\n",
      "tensor([[8.7163e+01, 3.5610e+00, 1.7020e+01, 1.1857e+01, 1.1409e+03, 2.9783e+02,\n",
      "         4.7401e+01, 2.8070e+01, 8.0562e+01, 7.9235e+01],\n",
      "        [1.1215e+03, 8.1793e+01, 1.2646e+01, 7.2920e+00, 1.1105e+03, 7.1397e+01,\n",
      "         4.3776e+01, 4.1093e-01, 2.2449e+01, 5.7891e+01],\n",
      "        [7.2925e+02, 4.5991e+01, 4.7922e+01, 4.3188e+01, 1.0140e+03, 1.4440e+02,\n",
      "         4.5051e+01, 7.7157e+01, 9.5538e+01, 6.6766e+01],\n",
      "        [2.4841e+02, 3.9029e+01, 2.3172e+01, 2.7306e+01, 9.4365e+02, 1.5132e+02,\n",
      "         4.6110e+01, 6.1055e+01, 7.5956e+01, 7.6859e+01],\n",
      "        [1.0197e+03, 7.4210e+01, 8.5811e+01, 5.1069e+00, 8.1936e+02, 7.9870e+02,\n",
      "         5.2401e+01, 1.3262e+02, 4.6005e+01, 2.0828e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[1077.4210,   78.5676,   87.4570,    1.2186,  829.9908,  725.9477,\n",
      "           53.7611,  141.6922,   43.3579,    1.9163]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 0 took 9.80 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[1.0690e+03, 8.7968e+01, 8.5385e+01, 3.1184e-01, 8.1121e+02, 7.9374e+02,\n",
      "         5.2581e+01, 1.2108e+02, 3.7736e+01, 0.0000e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 19.12 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[1.0448e+03, 7.0272e+01, 9.4529e+01, 3.8406e-01, 8.1058e+02, 8.0000e+02,\n",
      "         5.2868e+01, 1.3289e+02, 3.2035e+01, 0.0000e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 2 took 18.97 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[1183.0618,   73.5772,   78.3809,    2.9594,  810.2796,  795.6012,\n",
      "           52.7162,  139.8200,   33.8500,    0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 8.31 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[1.1356e+03, 7.9884e+01, 9.1028e+01, 7.9599e-01, 7.6695e+02, 7.9963e+02,\n",
      "         5.2896e+01, 1.4292e+02, 4.4047e+01, 0.0000e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 4 took 15.33 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[9.3014e+02, 7.8806e+01, 7.8710e+01, 5.6977e-01, 7.8138e+02, 7.9166e+02,\n",
      "         5.3129e+01, 1.4416e+02, 3.5703e+01, 0.0000e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 18.61 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[1.0506e+03, 8.2359e+01, 8.8828e+01, 1.1658e-02, 8.3618e+02, 7.7226e+02,\n",
      "         5.1717e+01, 1.5255e+02, 3.7430e+01, 0.0000e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 18.52 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[1059.2529,   85.0034,   91.5578,    7.3032,  801.4286,  778.7267,\n",
      "           53.0494,  144.7746,   32.5757,    3.0968]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 7 took 18.56 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[1060.0111,   76.3246,   86.9161,    3.1268,  779.0623,  682.7432,\n",
      "           52.0132,  133.2521,   36.2382,    0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 18.23 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[1061.6450,   78.0694,   86.0984,    0.0000,  795.5094,  779.0775,\n",
      "           52.4449,  137.8245,   36.2332,   11.9675]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 9 took 18.66 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[1062.3409,   78.6867,   86.9030,    2.5365,  805.3204,  778.7683,\n",
      "           52.7108,  139.3638,   37.2435,    0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 18.64 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[1200.0000,   80.6898,  108.5155,    4.5113,  852.5439,  720.1919,\n",
      "           51.7137,  122.9089,   42.0549,    8.2845]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 16.39 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[8.4189e+02, 8.9461e+01, 1.1587e+02, 6.2663e-01, 7.9867e+02, 7.1250e+02,\n",
      "         5.2414e+01, 1.3156e+02, 4.6126e+01, 7.1191e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 8.44 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[1062.0801,  104.4350,   93.6762,    5.1539,  799.9326,  666.3148,\n",
      "           51.8009,  142.8084,   53.3469,   10.8736]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 13.20 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[1200.0000,   92.6699,   10.7007,    0.0000, 1097.1908,   94.2210,\n",
      "           44.0261,    0.0000,    6.0152,   51.5712]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 14 took 10.12 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[1200.0000,   88.6915,    0.0000,    1.2379, 1158.0103,    0.0000,\n",
      "           42.4898,    0.0000,    8.3615,   62.9196]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 9.01 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[1139.0822,   86.7270,   19.6863,    4.7652, 1065.3526,  142.1301,\n",
      "           44.9146,    0.0000,   17.3994,   48.4949]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 18.78 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[1133.9387,   95.3529,   13.8258,    7.2860, 1079.4688,  116.9309,\n",
      "           44.5561,    0.0000,    8.5812,   56.8031]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 19.27 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[1159.8652,   84.0519,   15.3778,    3.2343, 1090.7343,  103.6287,\n",
      "           44.2391,    0.0000,   18.1430,   50.6075]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 19.58 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[1185.0125,  105.7362,   14.3569,    0.0000, 1070.3086,  159.8144,\n",
      "           44.5548,    3.7873,    0.0000,   41.6957]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 18.62 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[1156.2293,   77.7539,   18.1869,    0.0000, 1064.8277,  100.8543,\n",
      "           45.1659,    0.0000,    1.4685,   57.4910]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 19.38 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[1156.5873,  104.1347,   11.7301,    2.9837, 1083.9001,  141.4242,\n",
      "           44.5156,    0.0000,   27.8968,   56.2201]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 19.92 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[1199.7810,   86.8322,   12.0693,   10.8194, 1103.7753,  124.0548,\n",
      "           44.5610,    0.0000,   13.8688,   46.4014]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 22 took 19.30 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[1022.8199,   85.8967,    7.6097,    8.7018, 1059.1962,   99.8183,\n",
      "           43.4405,    0.0000,   14.6026,   50.1298]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 19.73 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[1082.4178,   92.0453,   29.6486,    7.7041, 1088.8076,   99.0934,\n",
      "           43.6684,    0.0000,   13.6903,   49.3740]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 24 took 20.17 seconds\n",
      "最优点: [0.9912552237510681, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.397157073020935, 1.397157073020935, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177]\n",
      "tensor([[1089.2396,   78.0076,  107.9582,   13.6721,  915.9850,  434.3955,\n",
      "           52.9896,  100.5988,  106.1669,   11.1080],\n",
      "        [ 371.2330,   54.2200,   35.3618,   18.7707,  286.2199,  734.8804,\n",
      "           53.1260,   26.9835,   76.6771,   37.6968],\n",
      "        [ 266.2530,  104.6275,   44.1561,   47.7926, 1079.6652,  525.3959,\n",
      "           50.5033,   61.2882,   62.1187,   63.1404],\n",
      "        [ 402.3087,  113.9892,    4.3447,   10.2045,  129.0450,  304.5634,\n",
      "           43.3355,   73.3621,   52.7524,   36.7417],\n",
      "        [ 200.1535,  101.3917,   92.5688,   10.5239,  239.4705,  398.5315,\n",
      "           53.3588,   55.9908,   22.0208,   77.6007]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[477.7602, 113.0612,   0.0000,   4.6320,  68.9535, 279.1472,  41.3848,\n",
      "          76.2532,  59.0771,  25.3326]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 19.50 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[373.7620, 120.0000,   0.0000,  10.3746,   0.0000, 229.4030,  40.7976,\n",
      "          78.6804,  43.7245,  39.1259]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 18.16 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[372.5647, 120.0000,   0.0000,   1.8672,   0.0000, 331.7048,  42.3176,\n",
      "          85.9473,  59.1601,  44.1983]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 16.09 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[239.8390, 119.9797,   0.0000,   1.9482,   0.0000, 292.5891,  42.2352,\n",
      "          64.7297,  52.0717,  31.8581]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 17.97 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[348.9654, 120.0000,   0.0000,   3.1391,   0.0000, 238.2110,  44.6408,\n",
      "          82.8389,  44.9333,  27.4426]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 14.75 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[415.0368, 118.9835,   0.0000,   4.0456,   0.0000, 369.7064,  42.5314,\n",
      "          75.8394,  34.2387,  29.0509]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 17.72 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[259.2605, 104.3064,   0.0000,   3.6499,   0.0000, 294.9356,  42.6019,\n",
      "          80.7839,  41.1384,  32.8777]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 13.84 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[476.9667, 111.8963,   0.0000,   0.0000,   0.0000, 248.0189,  43.5937,\n",
      "          67.3418,  40.1516,  40.3026]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 18.59 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[309.5593, 120.0000,   0.0000,   0.0000, 251.3022, 276.7958,  42.2147,\n",
      "          79.6649,  38.7809,  32.5842]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 13.84 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[342.3605, 117.8517,  24.3237,   1.7586,  27.6510, 284.4805,  42.3966,\n",
      "          78.3329,  43.3335,  30.6162]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 13.31 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[1103.8077,   69.6118,  100.9738,    7.2954,  733.9646,  466.0854,\n",
      "           52.9121,   94.5337,  108.6058,    4.7971]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 13.45 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[1.2000e+03, 7.2961e+01, 1.1520e+02, 6.7952e+00, 8.6033e+02, 4.2006e+02,\n",
      "         5.3098e+01, 1.0686e+02, 1.1437e+02, 3.9861e-01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 11.89 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[1200.0000,   66.7447,  116.9455,   12.9739,  907.2803,  490.3661,\n",
      "           54.6108,   96.0601,  113.2363,    7.8350]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 14.17 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[1200.0000,   69.8271,  108.4244,   17.5810,  729.9207,  420.6281,\n",
      "           54.3333,  104.9370,  105.1603,    1.4789]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 12.84 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[1200.0000,   75.1059,  113.3637,   10.6851,  830.0797,  529.5841,\n",
      "           53.6703,  107.0643,   97.9309,    1.9562]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 14 took 14.78 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[1.2000e+03, 6.6140e+01, 1.0688e+02, 1.0563e+01, 9.6219e+02, 4.1893e+02,\n",
      "         5.3480e+01, 9.8141e+01, 9.3383e+01, 6.6266e-01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 12.41 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[1200.0000,   65.1146,  119.2582,   15.6172,  834.7842,  468.9487,\n",
      "           51.1108,  102.2236,  104.5354,    5.5676]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 13.33 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[1200.0000,   63.7549,  100.7512,   10.0148,  867.2210,  457.1566,\n",
      "           53.5188,  112.9217,  104.1637,   12.9929]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 10.33 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[1012.0622,   63.8020,  116.5917,   12.5442,  885.7944,  463.6727,\n",
      "           53.8120,  110.4072,  104.4212,    0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 10.38 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[1200.0000,   69.0529,   94.1412,   15.2206,  943.1560,  488.4086,\n",
      "           52.6663,  105.1961,  113.1235,    0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 8.33 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[1180.6941,   69.0053,  116.0967,   11.3915,  834.6460,  441.6895,\n",
      "           53.4478,  103.4114,  101.3616,    7.0452]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 10.94 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[1133.7619,   75.0010,   92.2601,    5.6654,  922.7138,  440.2867,\n",
      "           58.0933,  105.8867,  106.7812,    0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 5.94 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[1121.9968,   66.2768,  111.9008,    0.0000, 1120.1371,  537.5546,\n",
      "           50.9103,  100.3565,  105.4021,    7.5476]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 22 took 3.97 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[1200.0000,   46.3799,  106.3945,    5.2565,  880.0543,  592.0586,\n",
      "           53.3142,   99.0464,   94.9498,    0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 4.41 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[1175.1911,   38.5332,  106.7637,    3.9696, 1019.0721,  423.8364,\n",
      "           51.8482,   95.8606,  114.7704,    4.9552]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 24 took 6.08 seconds\n",
      "最优点: [1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.372055172920227, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3795801401138306]\n",
      "tensor([[ 975.5257,   75.7973,   97.4184,    9.7173,  106.6926,  451.4654,\n",
      "           45.1821,   12.0112,   24.6909,   16.3742],\n",
      "        [ 641.8907,   59.1715,    2.3275,   12.8983,  675.0399,  796.5588,\n",
      "           55.6736,   49.7215,   81.3868,    8.0365],\n",
      "        [ 131.6560,    8.9748,    2.9430,   19.5062,  960.8623,  117.0835,\n",
      "           42.6072,   12.9522,   77.2567,   31.8659],\n",
      "        [ 957.4030,  108.2847,    3.7889,    6.0420, 1169.0379,  507.3486,\n",
      "           41.9790,  114.1495,   56.5446,   46.6285],\n",
      "        [ 543.9748,   78.4735,   94.0992,   27.6257, 1144.5549,  292.3492,\n",
      "           43.3666,  109.5231,   53.6293,   76.3860]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[924.7907,  73.1946,  75.7249,   9.3832, 210.2057, 526.2765,  47.2328,\n",
      "          17.1272,  35.3284,  12.5501]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 16.31 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[7.9503e+02, 5.9450e+01, 8.0778e+01, 9.2993e+00, 1.5811e+02, 4.2917e+02,\n",
      "         4.4902e+01, 4.3700e-01, 2.9108e+01, 8.0106e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 15.01 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[928.9397,  75.4442,  74.2201,   5.2048, 260.0257, 450.1166,  43.6537,\n",
      "           8.5957,  27.6759,  11.8010]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 18.47 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[1057.6588,   59.0095,   83.4386,    7.2620,  172.3704,  389.6927,\n",
      "           45.3252,    4.6623,   34.5154,    4.7080]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 15.98 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[986.5535,  72.4906,  66.6987,   8.7651, 140.7129, 435.9859,  46.5453,\n",
      "           0.0000,  19.1339,   8.2171]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 10.03 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[848.1405,  77.2455,  74.9998,   5.9551,  24.7849, 386.1317,  45.7710,\n",
      "           1.8770,  35.5495,  17.5105]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 13.23 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[9.8536e+02, 7.2041e+01, 7.0916e+01, 1.1012e+01, 9.7985e+01, 5.0819e+02,\n",
      "         4.2775e+01, 8.0414e-01, 3.3690e+01, 1.0872e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 11.39 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[963.5301,  54.4977,  77.7134,   6.6669, 115.7508, 558.4164,  44.5345,\n",
      "           0.0000,  26.7891,  18.6852]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 18.34 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[906.6725,  61.4573,  74.3046,   7.4168,   0.0000, 510.2793,  43.7637,\n",
      "          22.1815,  25.5940,   5.9403]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 13.58 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[950.6095,  55.4740,  69.1139,   9.9947, 190.6173, 413.8560,  43.8194,\n",
      "          18.5335,  27.0251,  21.0475]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 9.14 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[968.4009,  55.8733,  78.8740,  10.6063, 340.1766, 556.1211,  43.3297,\n",
      "          12.4601,  21.8885,   6.6692]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 11.53 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[876.0575,  46.1761,  52.5333,   8.4955, 366.5501, 557.6694,  43.7035,\n",
      "           7.4397,  32.4842,   5.1132]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 9.92 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[734.9110,  62.8467,  56.3153,  10.3417, 316.8394, 632.3076,  42.9738,\n",
      "           9.7677,  20.4107,  16.5319]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 5.42 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[766.4813,  49.7336,  76.7744,   8.6797, 367.1551, 623.8245,  41.4967,\n",
      "          17.7693,  37.3481,  14.0989]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 6.17 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[922.5071,  50.4926,  47.6626,  10.1521, 267.3139, 540.5759,  42.9407,\n",
      "           1.6576,  15.2344,   7.0656]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 9.05 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[879.0310,  57.7047,  46.9389,  10.4513, 458.1998, 613.3803,  46.1216,\n",
      "          15.1652,  20.9468,   9.4075]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 17.66 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[682.7026,  53.4191,   8.2351,  11.5179, 547.8172, 652.0730,  50.9415,\n",
      "          27.4914,  61.8121,   7.3085]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 7.19 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[682.7906,  60.1098,  23.8867,  10.2250, 301.8910, 507.1091,  45.6612,\n",
      "           2.0938,  36.0529,  12.5251]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 8.66 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[469.7670,  38.9247,   0.0000,  14.0175, 794.9441, 579.9219,  52.5649,\n",
      "          33.1064,  83.3930,  10.5676]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 11.59 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[673.8368,  53.1901,   0.0000,   8.8917, 926.9773, 594.1578,  52.5327,\n",
      "          47.2888,  79.3192,   7.1327]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 11.25 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[7.9880e+02, 2.9235e+01, 0.0000e+00, 1.3272e+01, 7.8763e+02, 6.5195e+02,\n",
      "         5.3340e+01, 3.9540e+01, 8.0021e+01, 3.8434e-01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 14.55 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[ 597.7422,   51.3980,    0.0000,   12.4058, 1014.8412,  757.0350,\n",
      "           52.7859,   25.2817,   75.7495,    0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 15.78 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[651.8457,  32.3584,   0.0000,   8.6242, 785.6752, 711.2727,  54.1601,\n",
      "          27.2634,  78.7029,  18.0923]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 14.09 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[480.7073,  29.3518,   0.0000,   9.2528, 753.5841, 692.7422,  53.6635,\n",
      "          47.6490,  70.9494,   0.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 14.17 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[584.5350,  41.8573,   0.0000,   8.6891, 640.0320, 725.1297,  51.7773,\n",
      "          35.2798,  89.5955,   0.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 7.34 seconds\n",
      "最优点: [1.3367308378219604, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103]\n",
      "tensor([[ 957.2990,  114.5814,  119.7566,   22.1784,  580.8580,  369.7469,\n",
      "           43.1374,  153.0257,   88.2778,   25.1513],\n",
      "        [1005.1571,   78.6979,  107.4027,   31.9806,  731.7871,  363.0733,\n",
      "           43.2728,   19.5839,  127.7233,   21.5319],\n",
      "        [ 204.9743,  114.6409,   69.5192,   14.9780, 1326.8383,   32.1989,\n",
      "           49.7994,  125.6573,  159.3024,   19.6523],\n",
      "        [ 705.0015,   98.5678,   71.2594,    2.5301,   55.8065,  531.0915,\n",
      "           47.0542,   24.5839,  100.1481,   78.0224],\n",
      "        [  44.6417,   98.2833,   33.8330,   46.5741,  886.5213,  364.4133,\n",
      "           40.3616,  120.4623,   53.2566,   32.8309]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 293.7869,  115.4992,   78.3451,   16.2620, 1226.5852,   83.0324,\n",
      "           48.6865,  131.8454,  146.0914,   20.4718]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 0 took 16.05 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[820.4078, 116.1598, 111.4245,  20.6670, 711.0353, 310.1518,  44.2944,\n",
      "         153.9174,  98.9864,  23.9651]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 7.01 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[881.3764, 119.8147, 120.0000,  19.3416, 659.3979, 289.5221,  42.7690,\n",
      "         159.9993,  85.2824,  21.7049]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 10.55 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[848.3948, 120.0000, 120.0000,  21.5072, 637.6049, 356.7653,  44.7957,\n",
      "         160.0000,  80.3620,  26.2775]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 13.36 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[936.0618, 117.9277, 111.2312,  19.8723, 617.8278, 328.5718,  42.5205,\n",
      "         160.0000, 107.5426,  24.0088]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 19.24 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[861.2048, 111.1899, 118.4427,  21.0234, 710.3445, 285.5526,  43.0877,\n",
      "         149.2353,  86.5595,  20.7080]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 17.55 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[888.1515, 118.1941, 117.5806,  20.6693, 670.9620, 300.4545,  43.3763,\n",
      "         131.9327,  92.1641,  22.2087]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 16.45 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[900.9661, 113.9506, 114.9918,  17.9420, 536.4060, 296.8704,  44.1790,\n",
      "         147.9864,  90.8624,  17.5565]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 18.45 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[859.1742, 116.0750, 115.7641,  26.2158, 592.6158, 288.2117,  43.5317,\n",
      "         149.7928,  92.7833,  17.1296]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 9.06 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[972.8749, 115.4491, 120.0000,  20.3046, 796.5990, 308.6742,  44.0273,\n",
      "         149.8900,  94.3153,  17.6181]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 18.70 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[765.0437, 115.1442, 120.0000,  18.4472, 659.7138, 346.0590,  43.0787,\n",
      "         145.4839,  94.0348,  17.9130]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 18.86 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[876.6627, 115.5855, 104.9436,  19.9506, 700.3791, 315.0395,  43.1447,\n",
      "         145.1026,  82.8654,  20.4827]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 14.86 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[860.9831, 115.2253, 113.6784,  19.8989, 640.9911, 281.0515,  43.3893,\n",
      "         146.0443,  89.0533,  24.2572]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 18.88 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[709.3813, 116.8596, 101.8471,  18.1989, 830.3450, 215.5146,  44.4582,\n",
      "         141.1033,  97.4625,  16.0319]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 15.83 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[764.1050, 112.5569,  99.3484,  21.3993, 763.4988, 282.4063,  44.8304,\n",
      "         134.9236,  99.0385,  19.5783]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 9.08 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[800.3006, 117.0814, 108.3359,  19.3470, 747.5521, 251.1531,  43.6602,\n",
      "         145.8735,  91.4021,  17.0889]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 19.48 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[607.4362, 115.8379, 104.0958,  16.4784, 879.8988, 151.3640,  45.6492,\n",
      "         155.9462, 113.8390,  23.1733]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 11.23 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[ 613.6713,  119.0319,  101.5408,   20.2123, 1049.9910,  202.1836,\n",
      "           44.2268,  144.5491,  103.4952,   26.3479]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 11.86 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[644.1614, 114.4214,  94.0110,  14.5349, 953.9135, 223.9777,  44.5729,\n",
      "         160.0000,  97.3362,  22.2241]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 15.88 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[639.2289, 120.0000, 110.0297,  20.9690, 842.9053, 164.8026,  45.2954,\n",
      "         136.8723, 113.3881,  20.9915]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 11.70 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[659.9629, 115.5912, 113.1694,  21.5749, 886.1721, 174.1703,  44.6177,\n",
      "         145.5856, 104.4034,  21.4460]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 15.36 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[723.2205, 120.0000,  98.3264,  17.9064, 860.8093, 189.5680,  45.3135,\n",
      "         139.3966, 112.9152,  23.1083]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 13.77 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[439.1860, 120.0000, 101.7223,  19.1148, 866.4042, 191.3461,  45.4534,\n",
      "         143.1264, 114.4578,  16.9001]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 15.25 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[ 469.9399,  120.0000,  108.7116,   14.6481, 1008.2771,  118.6628,\n",
      "           45.9739,  134.1171,  112.0542,   20.4078]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 9.26 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[450.0655, 120.0000,  98.7115,  18.8096, 926.8772,  42.1231,  46.0162,\n",
      "         141.4759, 112.8662,  19.7820]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 18.95 seconds\n",
      "最优点: [1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3946266174316406, 1.3946266174316406]\n",
      "tensor([[8.3487e+02, 3.7781e+01, 6.7576e+01, 3.4817e+01, 7.3967e+02, 1.1073e+02,\n",
      "         4.6184e+01, 9.7690e+00, 1.8519e+00, 2.6908e+01],\n",
      "        [1.9834e+02, 3.5492e+01, 6.4748e+01, 2.5186e+01, 8.3869e+01, 5.7601e+02,\n",
      "         5.7008e+01, 3.5315e+01, 1.4418e+02, 7.2061e+00],\n",
      "        [1.2088e+02, 3.1864e+01, 6.3096e+01, 4.4615e+01, 1.2117e+03, 4.6117e+02,\n",
      "         5.8921e+01, 1.1346e+02, 2.2059e+01, 7.3192e+01],\n",
      "        [1.0915e+03, 8.4056e+01, 4.3915e+01, 1.2070e+01, 6.9677e+02, 7.9252e+02,\n",
      "         4.2287e+01, 8.3152e+01, 1.1297e+01, 3.6502e+01],\n",
      "        [7.6507e+02, 6.6852e+01, 3.5124e+01, 3.9579e+01, 1.8612e+02, 5.5315e+02,\n",
      "         5.2762e+01, 1.2542e+02, 9.1622e+01, 2.3322e-01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[1043.4776,   80.9066,   41.4225,   16.6852,  614.9193,  766.7613,\n",
      "           44.2961,   94.0302,   28.9655,   29.4036]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 0 took 18.81 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[1022.5035,   93.1433,   41.8205,   14.8431,  499.1825,  796.4213,\n",
      "           43.3821,   89.1623,   16.0987,   33.3881]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 17.58 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[1119.2320,   86.2950,   40.1686,   10.5436,  625.1207,  799.2483,\n",
      "           42.7612,   99.2896,   27.3611,   30.7073]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 2 took 5.03 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[1023.9421,   85.6494,   37.2094,   15.1358,  681.9872,  800.0000,\n",
      "           42.8151,   86.4519,   17.7856,   37.0418]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 13.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[1007.5878,   85.5901,   45.5346,   10.4606,  584.7633,  800.0000,\n",
      "           44.0866,   86.7323,   29.7725,   31.2904]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 4 took 15.14 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[1159.8344,   85.8917,   44.8854,   15.9508,  565.3015,  790.0667,\n",
      "           42.9125,   97.1518,   12.1503,   29.8403]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 12.56 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[1094.6217,   87.9000,   42.5750,   12.7779,  572.2159,  685.8958,\n",
      "           42.7526,   90.7428,   18.6481,   31.7203]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 9.05 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[1064.9344,   91.0809,   42.8919,   13.3535,  702.9443,  774.9008,\n",
      "           44.4516,   96.6922,    9.0146,   28.3970]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 7 took 12.84 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[1143.7140,   92.8139,   43.5808,   15.8510,  675.1125,  783.6617,\n",
      "           43.2097,   89.0593,   31.7264,   32.6531]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 15.44 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[1186.0942,   86.8503,   41.4164,   12.9960,  558.7930,  787.1209,\n",
      "           44.7153,   84.1372,   15.3593,   31.3833]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 9 took 18.11 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[1083.6324,   88.1614,   42.0172,   14.1866,  610.0038,  792.2520,\n",
      "           42.1528,   83.5380,   17.9480,   23.4137]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 9.92 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[1092.9893,   87.6798,   42.5598,   13.9866,  601.0954,  780.2097,\n",
      "           43.2365,   92.9471,   19.3796,   32.0445]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 18.98 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[1111.8843,   94.7708,   40.2199,   16.9146,  444.9345,  743.8574,\n",
      "           45.1526,  102.8941,   32.8841,   19.3484]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 15.44 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[1200.0000,  102.1459,   44.0941,    8.9895,  566.2544,  790.8565,\n",
      "           41.6012,   86.9076,    2.3587,   31.7833]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 13.05 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[1044.1044,   93.3452,   44.2291,   21.2576,  502.0918,  729.8894,\n",
      "           45.2937,   80.0403,   11.7665,   26.2355]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 14 took 7.17 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[1200.0000,   79.0133,   42.8296,   12.5626,  781.6298,  726.7041,\n",
      "           43.5538,   96.4827,   26.7973,   21.5348]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 13.55 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[1029.5035,   79.2480,   40.2240,   12.4554,  395.0411,  751.1691,\n",
      "           44.3545,  102.8994,    4.1681,   20.0254]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 13.81 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[1120.8639,   80.3656,   40.6641,   16.1329,  242.7776,  764.8306,\n",
      "           42.4491,   92.0208,   32.0420,   27.1910]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 8.81 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[925.2106,  87.4990,  42.1396,  17.2771, 420.5307, 745.0537,  41.4753,\n",
      "         113.0980,  23.2348,  22.0849]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 12.39 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[1127.2092,   83.0547,   41.1231,   13.6326,  460.2877,  752.7548,\n",
      "           44.3727,   92.8568,   20.5617,   23.7092]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 17.55 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[1071.5110,   86.8706,   40.3435,   15.2136,  194.5622,  800.0000,\n",
      "           47.2697,  103.4109,   13.1207,   35.4195]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 8.16 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[1179.7236,   63.4871,   42.1214,    9.7942,  507.9922,  777.0882,\n",
      "           42.0973,   91.4820,    0.0000,   28.2270]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 8.67 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[1059.2066,   75.5023,   43.3237,   15.5841,  377.8606,  792.2065,\n",
      "           42.7820,   75.9064,    0.0000,   32.2662]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 22 took 8.66 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[1111.6298,   73.4272,   37.2829,    5.4084,  463.4827,  695.5682,\n",
      "           44.4531,   94.8127,   38.1730,   18.3463]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 8.64 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[1200.0000,   69.9774,   38.1604,   11.4653,  560.7920,  800.0000,\n",
      "           45.1258,  110.7451,   23.7284,   13.5144]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 24 took 8.22 seconds\n",
      "最优点: [0.7767000198364258, 1.3188371658325195, 1.3188371658325195, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521]\n",
      "tensor([[2.7407e+02, 1.0158e+02, 2.6207e+01, 2.9812e+01, 1.2403e+03, 4.2020e+02,\n",
      "         4.3232e+01, 4.6422e+01, 1.3633e+02, 1.2846e+01],\n",
      "        [1.1588e+03, 6.7166e+01, 3.6018e+01, 2.0330e+01, 7.3465e+02, 2.7304e+02,\n",
      "         4.3777e+01, 1.0825e+02, 7.3245e+01, 1.7409e+00],\n",
      "        [7.2736e+02, 3.7359e+01, 2.7838e+01, 4.4994e+01, 6.7884e+02, 5.7656e+02,\n",
      "         4.7248e+01, 1.5862e+01, 1.5852e+02, 4.8607e+01],\n",
      "        [7.0483e+02, 3.2612e-01, 4.9636e+01, 3.2278e+01, 6.3977e+02, 2.6749e+02,\n",
      "         5.9483e+01, 1.3580e+02, 8.0070e+01, 5.5668e+01],\n",
      "        [9.3328e+02, 2.0649e+01, 3.8957e+01, 1.3124e+01, 1.2519e+03, 1.2955e+02,\n",
      "         5.9328e+01, 1.3711e+02, 1.3935e+02, 6.2361e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 378.2891,  104.5382,   28.0017,   26.0214, 1224.8785,  370.0587,\n",
      "           42.9779,   63.4761,  121.5659,    5.5645]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 0 took 19.91 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[ 231.4466,  115.8205,   25.9201,   25.8179, 1355.9826,  398.2973,\n",
      "           41.9660,   54.7057,  128.4882,    3.2837]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 10.16 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[ 129.0839,  103.7303,   27.3332,   27.9019, 1254.3758,  302.8730,\n",
      "           44.1144,   57.7187,  128.0645,   10.8093]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 2 took 14.92 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[ 276.1914,   94.9211,   26.6480,   23.7527, 1273.3858,  328.8047,\n",
      "           40.3707,   40.7242,  126.2422,   13.8871]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 13.09 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[ 208.5439,  114.5409,   31.4110,   28.2485, 1239.0898,  367.2293,\n",
      "           40.0386,   57.9931,  135.1565,   10.4253]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 4 took 12.25 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[ 227.8322,  118.5969,   28.7803,   25.9591, 1182.8702,  360.4597,\n",
      "           44.1646,   30.7577,  126.3763,    4.1866]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 9.59 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[1.3216e+02, 9.8152e+01, 2.7262e+01, 3.0180e+01, 1.1904e+03, 3.8184e+02,\n",
      "         4.0971e+01, 4.3250e+01, 1.2031e+02, 5.1423e-01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 7.27 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[ 312.8473,  118.3036,   28.3250,   24.5915, 1275.8690,  350.9290,\n",
      "           44.3553,   51.9409,  133.7229,   12.2328]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 7 took 18.53 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[ 299.4513,  105.6405,   27.1084,   26.4213, 1330.8224,  361.6025,\n",
      "           42.4144,   71.1593,  133.0834,   13.5014]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 18.78 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[ 281.2257,  106.8339,   29.7641,   23.9351, 1267.9315,  372.5865,\n",
      "           44.3798,   46.3267,  135.8668,    5.5928]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 9 took 18.41 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[ 332.0243,  120.0000,   28.0965,   27.5030, 1294.4141,  335.0851,\n",
      "           43.4254,   35.8641,  129.8054,   10.2979]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 18.95 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[ 232.9433,  120.0000,   26.5545,   24.6366, 1202.5931,  398.3681,\n",
      "           43.4074,   53.2078,  125.6573,    9.7214]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 19.48 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[ 226.3911,  107.9686,   29.0637,   27.4866, 1157.8334,  347.6516,\n",
      "           44.3683,   48.1099,  140.0862,   14.8635]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 19.58 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[ 265.9427,  120.0000,   28.1710,   24.5345, 1235.9473,  270.5711,\n",
      "           42.9892,   55.9480,  128.1007,    5.9013]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 19.30 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[ 204.0269,  114.5437,   32.1056,   25.8182, 1299.0716,  363.7861,\n",
      "           44.5413,   50.0556,  124.1139,   10.2721]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 14 took 19.91 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[ 274.4095,  120.0000,   27.1396,   26.9354, 1244.0294,  380.1699,\n",
      "           45.1309,   58.4601,  139.6966,    7.7382]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 19.08 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[ 385.8315,  120.0000,   25.3619,   24.2952, 1294.1349,  362.1211,\n",
      "           45.4567,   33.6440,  121.6321,    4.8311]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 19.50 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[ 412.6645,  120.0000,   28.3169,   24.8661, 1236.4296,  386.6476,\n",
      "           40.8724,   36.7827,  131.8617,    6.6948]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 19.24 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[ 244.0983,  104.8722,   25.3279,   25.6367, 1259.9843,  342.8400,\n",
      "           44.1563,   37.2975,  132.3268,    9.2055]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 19.17 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[983.9765,  79.2251,  34.1545,  20.9915, 859.3145, 290.1096,  44.1002,\n",
      "          95.4006,  85.8447,   3.9378]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 19.66 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[1061.9673,   58.9225,   34.9909,   21.1119,  783.0956,  256.7546,\n",
      "           41.8092,  108.1278,   78.4652,    7.3341]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 19.66 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[951.5446,  68.9092,  33.7696,  19.4974, 786.7988, 249.3463,  42.5444,\n",
      "          81.5886,  71.8797,   1.5599]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 19.56 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[981.0140,  75.2993,  37.2463,  20.7976, 700.2315, 272.1690,  45.7656,\n",
      "          77.3700,  72.3741,   3.7954]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 19.53 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[873.4034,  78.8889,  32.8407,  20.4589, 688.8163, 239.2238,  44.4362,\n",
      "         112.3415,  74.8743,   2.1963]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 19.33 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[866.9898,  75.4599,  37.8787,  20.3907, 801.6000, 322.4513,  41.9627,\n",
      "         104.7215,  68.6458,   2.2017]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 19.41 seconds\n",
      "最优点: [1.3001327514648438, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3515031337738037, 1.3515031337738037, 1.3515031337738037, 1.3515031337738037]\n",
      "tensor([[1.0477e+03, 1.0276e+02, 9.8685e+01, 1.9143e+01, 2.8138e+02, 4.0193e+02,\n",
      "         4.4285e+01, 8.3141e+01, 6.2694e+01, 6.9649e+01],\n",
      "        [3.3544e+02, 8.7918e+00, 1.1059e+02, 3.8653e+01, 4.5654e+02, 5.7986e+02,\n",
      "         4.7938e+01, 5.0211e+01, 1.1085e+02, 2.5496e+01],\n",
      "        [1.1548e+03, 7.4763e+01, 1.1039e+02, 4.8142e+01, 1.5808e+02, 2.0698e+02,\n",
      "         4.6601e+01, 1.0942e+02, 5.9340e+01, 2.3616e+01],\n",
      "        [3.5968e+02, 2.6152e+01, 8.1701e+01, 2.4089e+01, 1.4360e+03, 3.1059e+00,\n",
      "         5.1369e+01, 5.1384e+01, 1.3409e+00, 2.2767e+01],\n",
      "        [9.7731e+02, 3.8286e+01, 3.0578e+01, 1.0762e+01, 1.3673e+03, 1.7356e+02,\n",
      "         4.2212e+01, 1.1171e+02, 1.5604e+02, 4.8352e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 376.7011,   30.5296,   71.4630,   19.3172, 1500.0000,    0.0000,\n",
      "           52.2432,   52.2364,    0.0000,   22.4084]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 0 took 20.08 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[ 276.8179,   28.5889,   69.7195,   19.2514, 1500.0000,    0.0000,\n",
      "           50.6123,   59.5152,    0.0000,   25.4429]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 19.38 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[ 469.5375,   20.3790,   64.6096,   19.2445, 1446.2313,    0.0000,\n",
      "           50.5278,   54.9027,    0.0000,   26.6095]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 2 took 19.16 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[ 419.8990,   22.8291,   77.8325,   14.3879, 1500.0000,    0.0000,\n",
      "           50.7517,   56.7113,    0.0000,   23.1187]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 18.62 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[ 455.3257,   21.3045,   75.4369,   17.1353, 1500.0000,    0.0000,\n",
      "           52.1060,   64.5494,    0.0000,   26.9244]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 4 took 18.91 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[ 464.0197,   29.0882,   74.5051,   15.5774, 1500.0000,    0.0000,\n",
      "           51.1310,   61.3412,   22.4326,   26.0632]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 18.91 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[4.9576e+02, 2.8817e+01, 7.1897e+01, 1.7508e+01, 1.5000e+03, 0.0000e+00,\n",
      "         5.0838e+01, 6.6379e+01, 2.7593e-01, 2.0105e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 18.89 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[ 417.0069,   15.5381,   70.5469,   16.0388, 1500.0000,    0.0000,\n",
      "           51.4303,   63.6811,   17.7987,   19.5242]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 7 took 18.62 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[ 430.9445,   26.1020,   72.6705,   13.8803, 1340.2007,    0.0000,\n",
      "           51.4417,   64.0724,    4.7560,   22.7289]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 17.42 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[ 475.2912,   17.5452,   78.5160,   17.7643, 1500.0000,    0.0000,\n",
      "           50.4072,   65.1153,   10.4975,   24.3913]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 9 took 18.84 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[ 463.0591,   22.9800,   72.9485,   15.7828, 1500.0000,   66.2115,\n",
      "           51.1670,   62.3252,    6.4621,   23.3783]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 18.97 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[ 500.5349,   20.0617,   69.7904,   12.4999, 1500.0000,    0.0000,\n",
      "           50.9303,   64.6640,    4.1006,   25.2823]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 19.25 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[ 568.3322,   20.8881,   76.7571,   14.8738, 1500.0000,    0.0000,\n",
      "           51.7563,   60.1155,    9.6235,   21.0544]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 13.86 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[4.7269e+02, 2.3186e+01, 7.3819e+01, 1.5633e+01, 1.5000e+03, 8.9734e-01,\n",
      "         5.1273e+01, 6.2205e+01, 7.0554e+00, 2.3101e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 19.64 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[ 462.7036,   26.6812,   87.9492,   10.1741, 1500.0000,   29.2974,\n",
      "           51.7019,   72.9886,   11.5798,   20.9639]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 14 took 12.58 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[ 598.7926,   37.1146,   87.3188,   11.7500, 1500.0000,   36.6203,\n",
      "           50.7826,   65.7050,    0.0000,   30.2332]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 16.84 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[ 633.1569,   31.1776,   74.2169,   15.9000, 1500.0000,   48.5140,\n",
      "           51.9084,   81.5683,   23.8685,   27.4003]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 15.50 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[ 635.9677,   37.1959,   72.8086,   11.8785, 1500.0000,   62.1879,\n",
      "           49.1324,   76.5065,   39.4670,   21.4030]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 10.62 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[ 721.4208,   34.9267,   54.9879,   12.6232, 1500.0000,   83.7571,\n",
      "           47.3302,   87.5940,   77.9710,   33.7481]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 8.72 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[ 638.0988,   46.5541,   60.9600,   13.6913, 1500.0000,   71.5112,\n",
      "           47.2546,   90.7193,   40.3512,   31.6550]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 13.77 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[ 685.9303,   34.1978,   51.6166,   15.4018, 1500.0000,   76.2717,\n",
      "           47.7342,   91.8490,   63.8667,   20.4235]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 11.45 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[ 881.2211,   44.2938,   54.4092,   15.5488, 1500.0000,   79.6491,\n",
      "           47.1789,   83.4957,   57.8093,   25.3465]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 16.06 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[ 590.7529,   58.0335,    0.0000,    9.8452, 1500.0000,   36.9281,\n",
      "           48.7660,   91.1948,   98.2710,   27.6625]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 22 took 5.38 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[ 686.0247,   52.4875,   33.2089,   11.3320, 1500.0000,   65.9019,\n",
      "           48.0661,   89.4354,   83.1226,   25.7144]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 10.59 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[ 681.0171,   32.6896,    2.7133,   14.2194, 1500.0000,   47.2790,\n",
      "           47.0294,   94.8537,   80.2429,   34.4315]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 24 took 10.03 seconds\n",
      "最优点: [0.9895653128623962, 0.9895653128623962, 0.9895653128623962, 1.2919471263885498, 1.3033850193023682, 1.3210777044296265, 1.3210777044296265, 1.328645944595337, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3577828407287598, 1.369498610496521, 1.3729560375213623, 1.3729560375213623, 1.3755927085876465, 1.3755927085876465, 1.3755927085876465, 1.3755927085876465, 1.3755927085876465]\n",
      "tensor([[6.5417e+02, 4.5062e+01, 7.2948e+01, 1.2145e+01, 1.3197e+03, 2.3310e+01,\n",
      "         4.3512e+01, 3.3130e+01, 3.8106e+01, 1.4550e+01],\n",
      "        [2.2071e+02, 1.3995e+01, 3.2416e+01, 2.8952e+01, 5.5420e+02, 6.3027e+02,\n",
      "         5.8717e+01, 1.0903e+02, 8.5038e+01, 2.4416e-01],\n",
      "        [3.4589e+02, 4.4364e+01, 8.1701e+01, 2.8330e+01, 1.0728e+03, 7.6572e+02,\n",
      "         5.3650e+01, 1.6991e+01, 1.2770e+02, 2.3919e+01],\n",
      "        [9.5245e+02, 5.5016e+01, 5.0517e-01, 4.9695e+01, 1.1746e+03, 2.5010e+02,\n",
      "         4.1631e+01, 1.9245e+01, 1.4036e+02, 6.4667e+01],\n",
      "        [1.4139e+02, 8.4173e+01, 1.1177e+02, 1.6270e+01, 4.2586e+02, 2.7306e+01,\n",
      "         5.4309e+01, 1.3814e+02, 5.1891e+00, 2.3243e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[270.0939,  26.2533,  52.4555,  28.5662, 761.3547, 681.2295,  56.6717,\n",
      "          72.3833, 101.5134,   9.6251]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 7.20 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[340.2861,  37.0948,  71.8468,  24.2343, 976.9379, 604.1172,  53.5991,\n",
      "          45.2246,  97.4392,  14.3796]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 5.20 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[243.8731,  42.3514,  83.8549,  27.4621, 884.1771, 792.3589,  57.6105,\n",
      "          52.4677, 116.3386,  17.1828]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 7.16 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[285.4190,  22.7376,  61.6408,  26.9964, 940.4892, 799.1212,  55.1668,\n",
      "          26.2102, 123.1428,  10.4094]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 6.75 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[180.3085,  41.6953,  58.2140,  33.1445, 856.8869, 736.7157,  52.2443,\n",
      "          41.7618, 111.1680,  19.5581]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 11.70 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[390.8371,  30.3409,  80.0826,  22.8142, 999.7969, 723.1175,  57.2524,\n",
      "          39.5332, 116.2250,  12.8763]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 19.38 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[277.5277,  21.2018,  66.7759,  22.7612, 814.7540, 713.2415,  58.6199,\n",
      "          65.6556, 101.0248,   3.3180]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 13.25 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[ 344.7816,   35.4991,   89.0848,   21.3384, 1124.4812,  735.8114,\n",
      "           54.0460,    9.7799,  117.0979,   14.1530]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 7 took 20.14 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[414.5946,  16.3651,  49.6030,  24.4327, 886.9187, 611.7932,  55.9271,\n",
      "          57.5602, 102.0925,   6.7387]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 16.36 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[391.9667,  27.2195,  55.7779,  26.9276, 740.1552, 599.5512,  59.2504,\n",
      "          96.1652,  96.2241,  11.1353]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 23.44 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[ 360.2418,   39.2259,   92.4384,   26.6396, 1078.5022,  800.0000,\n",
      "           57.3658,   13.2583,  143.6981,   21.6785]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 16.59 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[346.3202,  13.6328,  48.6893,  27.6031, 764.2384, 788.8687,  59.6034,\n",
      "          71.2514, 115.7119,   5.9046]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 21.92 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[380.8053,  28.0526,  68.0277,  24.7515, 737.3232, 800.0000,  56.4813,\n",
      "          54.5965, 104.7163,  15.6170]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 25.41 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[ 294.7533,   29.0718,   63.3526,   26.1919, 1030.1481,  718.7028,\n",
      "           58.1505,   69.5261,  107.3846,    5.4849]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 19.83 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[233.9292,  16.2211,  55.0813,  26.2693, 695.4070, 535.2177,  58.6781,\n",
      "          66.7144, 107.8031,   3.8077]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 19.53 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[ 370.6349,   37.1777,   93.2014,   25.3465, 1129.7178,  800.0000,\n",
      "           53.2921,   40.3150,  120.7250,   17.8773]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 19.64 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[ 332.1874,   45.1701,   67.1063,   24.6455, 1048.1350,  730.3806,\n",
      "           56.2999,    6.9316,  112.6871,   18.0270]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 13.45 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[331.5611,  28.1895,  88.4814,  25.9531, 890.5396, 618.9104,  56.6329,\n",
      "          21.8062, 110.7692,   5.3164]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 25.05 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[271.0499,  14.2332,  47.8752,  26.3605, 764.7754, 707.5894,  57.9400,\n",
      "          79.4029,  68.5581,   4.1738]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 13.19 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[327.4369,  19.8643,  64.8946,  24.6263, 952.1542, 585.3000,  56.6808,\n",
      "          48.9853, 125.4766,  21.4853]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 27.05 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[ 407.2552,   33.5086,   60.8365,   25.7031, 1025.0159,  642.4714,\n",
      "           54.3385,   20.9840,  139.9449,    9.9239]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 14.39 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[239.2829,  71.3324, 101.0964,  16.4115, 626.8177, 106.4260,  52.9221,\n",
      "         110.0199,  23.1587,  20.0035]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 26.47 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[ 94.9267,  78.1415, 107.9197,  18.3472, 389.3899, 153.5023,  56.4415,\n",
      "         137.2572,  20.0778,  20.8753]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 22.97 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[185.8823,  72.8929,  91.7283,  17.6531, 368.2835,  12.6587,  55.1205,\n",
      "         158.4864,   0.0000,  16.3810]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 29.44 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[ 30.8535,  70.6620, 103.4914,  16.2425, 398.0350, 156.6910,  57.5367,\n",
      "         146.5791,   1.1889,  17.1857]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 20.70 seconds\n",
      "最优点: [1.334701418876648, 1.334701418876648, 1.334701418876648, 1.334701418876648, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.381850004196167, 1.381850004196167, 1.381850004196167]\n",
      "tensor([[ 373.5851,   42.3481,   28.2132,   47.7716,  401.0603,  708.0976,\n",
      "           45.3799,  139.8014,   74.1156,   70.0049],\n",
      "        [ 365.8422,   60.6736,   12.3250,   27.3812,  229.3148,  487.7974,\n",
      "           56.4798,  100.3647,  140.4854,   72.4745],\n",
      "        [ 199.3768,   19.6290,   91.8926,   33.6921,  706.9081,  493.1646,\n",
      "           41.0089,   87.0028,   48.8923,   73.7453],\n",
      "        [ 912.3393,   44.5452,   84.8709,   35.8131,  475.3241,  493.1233,\n",
      "           41.8152,  147.0894,  131.1938,   63.9720],\n",
      "        [ 943.6881,   30.6485,   73.7431,   43.8560, 1003.7825,  326.9272,\n",
      "           42.8058,  100.8544,   36.5746,   53.3754]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[465.4839,  42.9654,  36.8553,  46.0322, 408.3270, 676.2065,  44.7876,\n",
      "         142.0343,  83.8905,  68.9810]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 7.20 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[358.6146,  44.2366,  42.9823,  47.7054, 401.3991, 721.7143,  45.5870,\n",
      "         145.6797,  83.9823,  67.7383]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 5.88 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[805.2528,  44.3854,  74.4281,  38.2242, 458.0555, 538.3420,  42.5246,\n",
      "         146.6261, 121.0756,  65.0474]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 3.61 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[939.0977,  43.6656,  74.0786,  38.6881, 361.2072, 553.8975,  41.9836,\n",
      "         145.0360, 123.4271,  65.1452]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 20.80 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[753.7100,  45.7184,  85.8250,  38.1004, 392.4361, 563.2495,  42.8843,\n",
      "         150.1474, 125.2529,  63.2044]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 19.23 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[756.9083,  47.1278,  77.4554,  38.3480, 397.7677, 525.4407,  41.6054,\n",
      "         155.3840, 122.9495,  65.1513]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 10.97 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[811.9055,  44.4224,  78.2848,  38.0836, 490.2062, 588.9229,  43.7404,\n",
      "         149.4885, 131.6483,  63.9336]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 13.02 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[738.4153,  46.7628,  78.6427,  38.9386, 445.3711, 558.4559,  43.3273,\n",
      "         139.5534, 131.9354,  63.8110]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 14.41 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[776.6900,  45.1112,  76.4755,  37.3134, 423.6551, 550.4472,  44.9032,\n",
      "         144.8199, 119.1054,  63.4420]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 16.33 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[734.2587,  43.3794,  76.7816,  37.4014, 460.2212, 592.8202,  42.4953,\n",
      "         142.8245, 119.9843,  62.7809]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 29.33 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[749.0429,  42.7724,  85.6198,  39.7725, 464.5585, 569.3294,  43.9164,\n",
      "         144.2075, 120.3860,  64.4728]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 7.16 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[807.1273,  47.3983,  80.5882,  39.1377, 480.2083, 574.0123,  43.2497,\n",
      "         145.2449, 118.0331,  62.9146]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 17.19 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[757.8280,  43.0645,  74.8492,  39.5623, 448.8776, 547.8429,  43.4368,\n",
      "         146.7732, 127.1579,  62.1360]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 17.31 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[760.6693,  45.0064,  79.1041,  38.1098, 446.3500, 569.7292,  43.4265,\n",
      "         145.5473, 124.9458,  63.9271]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 15.92 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[705.3414,  44.8101,  64.5945,  41.5105, 431.9870, 625.3597,  44.4076,\n",
      "         143.8968, 115.0170,  64.3325]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 11.72 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[801.3683,  43.3709,  86.8684,  37.7589, 467.8304, 554.1055,  43.4239,\n",
      "         142.9810, 125.8216,  62.0769]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 16.33 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[684.0945,  45.5064,  82.6014,  37.5765, 542.0250, 541.6039,  43.7596,\n",
      "         147.2344, 123.0829,  62.8177]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 13.47 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[813.1641,  41.3186,  81.9700,  37.3958, 483.1521, 567.5563,  43.5369,\n",
      "         152.3315, 112.4737,  62.7896]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 14.64 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[826.4187,  42.2207,  73.2007,  38.0137, 545.5569, 550.5978,  43.7183,\n",
      "         142.6578, 120.4941,  63.9210]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 28.28 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[742.3619,  43.9444,  82.3452,  38.3004, 430.5209, 534.2449,  42.8852,\n",
      "         143.3402, 112.0543,  62.8245]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 12.08 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[787.3714,  43.8099,  81.8545,  38.1596, 468.8550, 556.2089,  43.2567,\n",
      "         147.4188, 121.9781,  63.1632]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 21.16 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[735.9471,  44.3308,  93.5050,  37.3041, 412.2139, 610.5286,  44.6963,\n",
      "         150.2778, 121.8137,  59.9017]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 12.97 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[753.7851,  44.8609,  87.7834,  37.8523, 427.7685, 582.2364,  43.9390,\n",
      "         147.1845, 123.1284,  61.3203]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 16.03 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[776.0779,  41.8063,  97.5964,  35.6741, 439.0047, 627.9023,  44.4670,\n",
      "         154.0879, 119.2180,  63.5408]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 12.64 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[720.7195,  37.9053,  89.4787,  36.4103, 395.1664, 584.8303,  44.8048,\n",
      "         154.0741, 127.5988,  61.5869]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 14.05 seconds\n",
      "最优点: [1.1667718887329102, 1.1667718887329102, 1.1667718887329102, 1.1799306869506836, 1.1799306869506836, 1.1799306869506836, 1.1799306869506836, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2088252305984497, 1.2088252305984497, 1.2088252305984497, 1.2120479345321655]\n",
      "Bayes Best Values Over All Experiments:\n",
      "[[0.8331813812255859, 0.8331813812255859, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.361149787902832, 1.361149787902832, 1.361149787902832, 1.361149787902832, 1.361149787902832, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638, 1.3666106462478638], [0.9912552237510681, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.397157073020935, 1.397157073020935, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177, 1.4012643098831177], [1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.372055172920227, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3741945028305054, 1.3795801401138306], [1.3367308378219604, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103, 1.355099081993103], [1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.382589340209961, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3884788751602173, 1.3946266174316406, 1.3946266174316406], [0.7767000198364258, 1.3188371658325195, 1.3188371658325195, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521, 1.3812329769134521], [1.3001327514648438, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3515031337738037, 1.3515031337738037, 1.3515031337738037, 1.3515031337738037], [0.9895653128623962, 0.9895653128623962, 0.9895653128623962, 1.2919471263885498, 1.3033850193023682, 1.3210777044296265, 1.3210777044296265, 1.328645944595337, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3540478944778442, 1.3577828407287598, 1.369498610496521, 1.3729560375213623, 1.3729560375213623, 1.3755927085876465, 1.3755927085876465, 1.3755927085876465, 1.3755927085876465, 1.3755927085876465], [1.334701418876648, 1.334701418876648, 1.334701418876648, 1.334701418876648, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.381850004196167, 1.381850004196167, 1.381850004196167], [1.1667718887329102, 1.1667718887329102, 1.1667718887329102, 1.1799306869506836, 1.1799306869506836, 1.1799306869506836, 1.1799306869506836, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2081372737884521, 1.2088252305984497, 1.2088252305984497, 1.2088252305984497, 1.2120479345321655]]\n",
      "Bayes Best Values Over All Experiments (Array):\n",
      "[[0.83318138 0.83318138 1.35286713 1.35286713 1.35286713 1.35286713\n",
      "  1.35286713 1.35286713 1.35286713 1.35286713 1.35286713 1.35286713\n",
      "  1.35286713 1.36114979 1.36114979 1.36114979 1.36114979 1.36114979\n",
      "  1.36661065 1.36661065 1.36661065 1.36661065 1.36661065 1.36661065\n",
      "  1.36661065 1.36661065 1.36661065 1.36661065 1.36661065 1.36661065]\n",
      " [0.99125522 1.39149904 1.39149904 1.39149904 1.39149904 1.39149904\n",
      "  1.39149904 1.39149904 1.39149904 1.39149904 1.39149904 1.39149904\n",
      "  1.39149904 1.39149904 1.39149904 1.39149904 1.39149904 1.39715707\n",
      "  1.39715707 1.40126431 1.40126431 1.40126431 1.40126431 1.40126431\n",
      "  1.40126431 1.40126431 1.40126431 1.40126431 1.40126431 1.40126431]\n",
      " [1.36864507 1.36864507 1.36864507 1.36864507 1.36864507 1.36864507\n",
      "  1.36864507 1.36864507 1.36864507 1.36864507 1.36864507 1.36864507\n",
      "  1.36864507 1.36864507 1.36864507 1.36864507 1.37205517 1.3741945\n",
      "  1.3741945  1.3741945  1.3741945  1.3741945  1.3741945  1.3741945\n",
      "  1.3741945  1.3741945  1.3741945  1.3741945  1.3741945  1.37958014]\n",
      " [1.33673084 1.34620559 1.34620559 1.34620559 1.34620559 1.34620559\n",
      "  1.34620559 1.34620559 1.34620559 1.34620559 1.34620559 1.34620559\n",
      "  1.34620559 1.34620559 1.34620559 1.35509908 1.35509908 1.35509908\n",
      "  1.35509908 1.35509908 1.35509908 1.35509908 1.35509908 1.35509908\n",
      "  1.35509908 1.35509908 1.35509908 1.35509908 1.35509908 1.35509908]\n",
      " [1.3735255  1.3735255  1.3735255  1.3735255  1.3735255  1.3735255\n",
      "  1.38258934 1.38258934 1.38258934 1.38258934 1.38258934 1.38258934\n",
      "  1.38258934 1.38258934 1.38258934 1.38258934 1.38847888 1.38847888\n",
      "  1.38847888 1.38847888 1.38847888 1.38847888 1.38847888 1.38847888\n",
      "  1.38847888 1.38847888 1.38847888 1.38847888 1.39462662 1.39462662]\n",
      " [0.77670002 1.31883717 1.31883717 1.37512541 1.37512541 1.37512541\n",
      "  1.38123298 1.38123298 1.38123298 1.38123298 1.38123298 1.38123298\n",
      "  1.38123298 1.38123298 1.38123298 1.38123298 1.38123298 1.38123298\n",
      "  1.38123298 1.38123298 1.38123298 1.38123298 1.38123298 1.38123298\n",
      "  1.38123298 1.38123298 1.38123298 1.38123298 1.38123298 1.38123298]\n",
      " [1.30013275 1.34732807 1.34732807 1.34732807 1.34732807 1.34732807\n",
      "  1.34732807 1.34732807 1.34732807 1.34732807 1.34732807 1.34732807\n",
      "  1.34732807 1.34732807 1.34732807 1.34732807 1.34732807 1.34732807\n",
      "  1.34732807 1.34732807 1.34732807 1.34732807 1.34732807 1.34732807\n",
      "  1.34732807 1.34732807 1.35150313 1.35150313 1.35150313 1.35150313]\n",
      " [0.98956531 0.98956531 0.98956531 1.29194713 1.30338502 1.3210777\n",
      "  1.3210777  1.32864594 1.35404789 1.35404789 1.35404789 1.35404789\n",
      "  1.35404789 1.35404789 1.35404789 1.35404789 1.35404789 1.35404789\n",
      "  1.35404789 1.35404789 1.35404789 1.35778284 1.36949861 1.37295604\n",
      "  1.37295604 1.37559271 1.37559271 1.37559271 1.37559271 1.37559271]\n",
      " [1.33470142 1.33470142 1.33470142 1.33470142 1.38128507 1.38128507\n",
      "  1.38128507 1.38128507 1.38128507 1.38128507 1.38128507 1.38128507\n",
      "  1.38128507 1.38128507 1.38128507 1.38128507 1.38128507 1.38128507\n",
      "  1.38128507 1.38128507 1.38128507 1.38128507 1.38128507 1.38128507\n",
      "  1.38128507 1.38128507 1.38128507 1.38185    1.38185    1.38185   ]\n",
      " [1.16677189 1.16677189 1.16677189 1.17993069 1.17993069 1.17993069\n",
      "  1.17993069 1.20813727 1.20813727 1.20813727 1.20813727 1.20813727\n",
      "  1.20813727 1.20813727 1.20813727 1.20813727 1.20813727 1.20813727\n",
      "  1.20813727 1.20813727 1.20813727 1.20813727 1.20813727 1.20813727\n",
      "  1.20813727 1.20813727 1.20882523 1.20882523 1.20882523 1.21204793]]\n"
     ]
    }
   ],
   "source": [
    "results1 = Hartmannb.bayesian_optimization_experiment(\n",
    "    num_experiments=10,\n",
    "    n=25,\n",
    "    obj_fn1=predict_bi_function_xg,\n",
    "\n",
    "    obj_fn3=predict_bi_function_xg,\n",
    "    initial_points_task1=initial_points_task11,  # 传递生成的初始样本\n",
    "    initial_points_task2=initial_points_task22,  # 传递生成的初始样本\n",
    "    fit_task_fn=fit_gp_model_and_select_next_point,\n",
    "    device='cuda',\n",
    "    task_type='single'  # 表示运行单任务模型\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b88c9e1-7a53-4fbb-9c42-54596a13391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_samples(num_samples, dim_ranges):\n",
    "    # 选择计算设备\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dtype = torch.double\n",
    "    \n",
    "    # 从 dim_ranges 中提取每个维度的上下限并转换为张量\n",
    "    lower_bounds = torch.tensor([lower for lower, upper in dim_ranges], dtype=dtype, device=device).clone().detach()\n",
    "    upper_bounds = torch.tensor([upper for lower, upper in dim_ranges], dtype=dtype, device=device).clone().detach()\n",
    "    \n",
    "    # 计算维度数量\n",
    "    dim = len(dim_ranges)\n",
    "    \n",
    "    # 创建 Sobol 序列生成器\n",
    "    sobol_engine = torch.quasirandom.SobolEngine(dim, scramble=True, seed=None)\n",
    "    \n",
    "    # 生成 Sobol 样本点\n",
    "    train_x = sobol_engine.draw(num_samples).to(device, dtype=dtype)\n",
    "\n",
    "    # 将 Sobol 点映射到每个维度的指定范围内\n",
    "    train_x = lower_bounds + (upper_bounds - lower_bounds) * train_x\n",
    "\n",
    "    return train_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97dd6e14-c9df-4710-881b-9f9eedaebfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[740.4133,  81.2390,  71.2741,  47.7964, 999.6783, 130.5784,  43.1893,\n",
      "         120.5146, 100.7689,  62.0057]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "num_samples = 1  # 样本数量\n",
    "dim_ranges = [\n",
    "    (0, 1200),    # 第1维度范围\n",
    "    (0, 120),     # 第2维度范围\n",
    "    (0, 120),     # 第3维度范围\n",
    "    (0, 50),      # 第4维度范围\n",
    "    (0, 1500),    # 第5维度范围\n",
    "    (0, 800),     # 第6维度范围\n",
    "    (40, 60),     # 第7维度范围\n",
    "    (0, 160),     # 第8维度范围\n",
    "    (0, 160),     # 第9维度范围\n",
    "    (0, 80)       # 第10维度范围\n",
    "]\n",
    "\n",
    "samples = generate_initial_samples(num_samples, dim_ranges)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d274ff3f-ef72-422c-ab69-1dae49cab9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gp_model_and_select_next_point2(train_x, train_obj, device):\n",
    "        # 生成样本点\n",
    "    initial_samples_np = generate_initial_samples(num_samples, dim_ranges)\n",
    "    \n",
    "    # 转换为张量\n",
    "    initial_samples_tensor = torch.tensor(initial_samples_np, dtype=torch.float64)\n",
    "    return initial_samples_tensor.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edff1a7b-3298-4601-8d1c-1d898eb8a3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.4184e+02, 1.9690e+00, 9.8791e+01, 3.7921e+01, 7.5024e+02, 2.0982e+02,\n",
      "         5.3923e+01, 7.5682e+01, 1.4006e+02, 1.9229e+01],\n",
      "        [3.6221e+02, 1.2058e+00, 5.6277e+01, 4.0617e+01, 1.0702e+03, 7.9879e+02,\n",
      "         5.8215e+01, 1.5645e+01, 1.4941e+02, 5.1372e+01],\n",
      "        [8.5012e+02, 6.2660e+01, 1.4704e+01, 2.6075e+01, 1.1994e+03, 5.8682e+02,\n",
      "         4.3437e+01, 5.0589e+01, 2.1980e+01, 8.3418e+00],\n",
      "        [9.9788e+02, 8.6128e+01, 8.2381e+01, 2.0644e+01, 1.3724e+03, 5.7371e+02,\n",
      "         5.0069e+01, 5.4028e+01, 1.4771e+02, 4.9593e+01],\n",
      "        [6.4233e+02, 1.1346e+02, 3.4487e+01, 2.5174e+00, 8.2257e+02, 3.7235e+01,\n",
      "         4.6280e+01, 6.7757e+01, 8.1175e+01, 9.9483e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[880.8672,  39.5539, 109.7672,  12.1504,  11.8141, 583.5682,  45.6444,\n",
      "         131.5381, 131.7804,  47.7474]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.00 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[ 374.1254,    8.0677,  106.9656,   15.3071, 1328.8734,  254.7906,\n",
      "           41.1297,   94.6125,   40.4662,   26.8037]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 0.01 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[ 411.7811,   77.8455,   90.6710,    5.9959, 1401.3339,  470.6504,\n",
      "           53.6430,  114.7744,   16.8264,   67.9550]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 2 took 0.02 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[ 224.7533,   28.2235,   17.8580,   13.4345, 1265.7415,  762.1514,\n",
      "           42.1818,  125.9422,   64.7095,   79.9290]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[ 161.1334,   49.7870,   73.2788,   13.0006, 1080.5764,  706.0893,\n",
      "           57.1469,  152.6870,   78.6531,   40.4284]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 4 took 0.02 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[7.0958e+02, 4.6135e+01, 5.7003e+01, 4.1829e-01, 9.4734e+02, 5.4236e+02,\n",
      "         4.1327e+01, 6.3082e+01, 4.4378e+01, 2.6361e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 0.01 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[866.7920,  63.0653,  25.6512,  42.5086, 618.7935, 559.2806,  40.6127,\n",
      "         155.3383,  24.2734,  10.8998]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.02 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[228.3840,  11.4287,  63.1144,  28.4957, 300.5357, 196.8107,  54.8992,\n",
      "         109.2993,  41.0679,  44.0839]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.00 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[770.1623, 101.2495,  58.6904,  42.3996, 304.3421, 131.2749,  49.0493,\n",
      "         158.3195,  29.8737,  50.2800]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.02 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[951.5139,  14.0164,  44.9198,   9.6817, 177.0607, 420.9098,  44.8349,\n",
      "          62.8243, 136.6520,  72.9535]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.01 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[631.0920, 103.1136, 116.6294,  31.6173, 639.1802,  18.4312,  57.7971,\n",
      "         100.9847, 111.3814,  64.2894]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.02 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[711.4896,  47.1170, 105.3802,  13.5432, 548.3976, 600.2134,  47.2615,\n",
      "         124.7925,  84.9602,  41.0939]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.00 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[645.9816,   7.3615,   5.5096,  32.9381, 577.1810, 118.8439,  46.6082,\n",
      "          62.5094,  78.4481,  40.9423]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.01 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[ 964.6594,  114.1239,   64.6865,    7.8427, 1354.6010,  500.3190,\n",
      "           42.0527,   28.4031,   64.8660,    7.0754]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 0.02 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[740.8783,  34.8755,  86.4720,  33.4019, 276.8551, 408.2254,  57.9273,\n",
      "         123.5623,  24.9643,  35.5541]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[232.2633,  55.0773, 103.4264,  45.8771, 403.0608, 419.4045,  46.4833,\n",
      "         145.8808,  54.8558,  16.9999]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.02 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[  86.7825,   56.1746,   67.0735,    2.6770, 1054.1288,  574.6471,\n",
      "           56.2753,   11.6867,   49.0649,    6.6608]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.01 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[  5.8395,  76.2677,  44.4413,  49.8637, 692.6647, 344.4141,  47.1091,\n",
      "          84.8393,  20.6194,  39.8764]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.02 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[735.0504,  77.9539,  26.6030,  44.2644, 788.5017, 574.9083,  44.5221,\n",
      "          99.3294,  36.0339,  39.0462]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.00 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[350.1053,  21.0044, 119.5431,  28.4157, 372.5929, 687.6104,  54.8716,\n",
      "          48.2928,  51.8040,  43.8675]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[715.2213, 110.6339,  96.9318,  16.3203, 397.0165, 605.7917,  41.5168,\n",
      "         105.3976,  83.3951,  60.8277]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.01 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[988.6622,  66.0169,  84.3009,  15.6086, 423.9643, 427.0056,  56.4489,\n",
      "          55.9959,  70.3967,  42.5632]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.02 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[1096.4728,  119.2791,   59.3090,    6.9683,  710.3641,  246.0826,\n",
      "           52.7895,   73.4658,  138.3754,   60.3252]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 22 took 0.00 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[634.8925, 101.1518,  51.3462,  47.7248, 765.3484, 422.4976,  58.0594,\n",
      "          67.6513,  44.2356,  78.2228]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.01 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[ 283.3428,   71.3490,  116.5144,   44.3385, 1332.1361,  784.1617,\n",
      "           46.0973,  158.9374,  144.5969,   77.9391]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 24 took 0.02 seconds\n",
      "最优点: [0.8331813812255859, 0.8331813812255859, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002]\n",
      "tensor([[8.7163e+01, 3.5610e+00, 1.7020e+01, 1.1857e+01, 1.1409e+03, 2.9783e+02,\n",
      "         4.7401e+01, 2.8070e+01, 8.0562e+01, 7.9235e+01],\n",
      "        [1.1215e+03, 8.1793e+01, 1.2646e+01, 7.2920e+00, 1.1105e+03, 7.1397e+01,\n",
      "         4.3776e+01, 4.1093e-01, 2.2449e+01, 5.7891e+01],\n",
      "        [7.2925e+02, 4.5991e+01, 4.7922e+01, 4.3188e+01, 1.0140e+03, 1.4440e+02,\n",
      "         4.5051e+01, 7.7157e+01, 9.5538e+01, 6.6766e+01],\n",
      "        [2.4841e+02, 3.9029e+01, 2.3172e+01, 2.7306e+01, 9.4365e+02, 1.5132e+02,\n",
      "         4.6110e+01, 6.1055e+01, 7.5956e+01, 7.6859e+01],\n",
      "        [1.0197e+03, 7.4210e+01, 8.5811e+01, 5.1069e+00, 8.1936e+02, 7.9870e+02,\n",
      "         5.2401e+01, 1.3262e+02, 4.6005e+01, 2.0828e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[374.5545,  34.7893,   5.3260,  11.5380, 215.5953, 220.1666,  50.7182,\n",
      "          48.4664, 115.7568,  12.9341]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.01 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[714.2782,  94.7939, 113.3217,  17.6697, 992.7894, 798.1758,  46.5811,\n",
      "          19.9782,  48.8483,  48.2171]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.02 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[699.2604, 104.8553,  88.0715,  40.6960, 421.4952, 230.3159,  44.9663,\n",
      "         135.5579, 157.2064,  20.6872]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.00 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[ 61.8684,  11.4277,  50.3299,  20.2586, 923.1014, 791.0380,  52.3705,\n",
      "         141.6651,  20.1302,  49.6280]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.02 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[ 779.7928,   53.3375,   91.5502,   17.1762, 1242.9220,  265.8487,\n",
      "           46.1562,   17.8442,  117.3780,   31.8208]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 4 took 0.01 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[ 83.8506,  98.1026, 112.6656,  42.9748,  16.7217, 727.3795,  55.7488,\n",
      "         114.6593,  99.1625,  10.8004]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.02 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[1019.8589,   75.1858,   95.6588,    1.6368, 1498.6821,  166.9605,\n",
      "           56.9935,  110.2092,   57.3463,   19.2795]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[ 322.9507,   90.5945,   59.3505,   29.6812, 1033.8936,  327.4425,\n",
      "           46.3043,  144.7007,   62.4898,   66.3664]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 7 took 0.01 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[1000.0576,    7.9669,   26.1754,   32.3949,  529.6651,  716.0182,\n",
      "           47.9277,   28.2217,  111.1341,   74.9089]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 0.02 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[7.6515e+02, 4.0047e-01, 3.2792e+01, 4.0361e+01, 1.0135e+03, 5.7196e+02,\n",
      "         5.8909e+01, 1.5536e+02, 8.4502e+01, 7.7237e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 9 took 0.00 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[1047.2663,   76.6163,   53.4558,   43.7225,  780.5066,  477.7234,\n",
      "           44.5570,   91.9842,    8.3334,   26.4111]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 0.02 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[441.8331,  36.0476,  58.4508,   6.0528, 532.4536, 528.6250,  52.4643,\n",
      "          87.2521,  60.0968,  41.0985]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.01 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[ 27.8876,  16.1520,  91.8142,  43.6773, 136.5892, 505.5691,  58.1795,\n",
      "          47.0676,  80.5869,  72.0630]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.00 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[4.8864e+02, 8.0143e+00, 5.5210e+01, 7.1644e-01, 7.5467e+02, 3.3490e+02,\n",
      "         5.3649e+01, 9.4446e+01, 1.1879e+02, 7.4082e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 0.02 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[283.4554,  22.8808,  96.9039,  25.4968, 312.4467, 673.5272,  57.5316,\n",
      "          70.1801,   4.8979,  59.8230]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[521.6075,  64.6804,  81.8232,  44.9824, 458.3225, 735.8918,  53.6235,\n",
      "          68.6801,  93.5372,  25.0690]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.00 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[1076.4678,    7.0938,   87.8658,   17.0621,   77.2667,  548.0000,\n",
      "           58.9030,  118.9081,   27.6000,   22.2583]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.01 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[590.3355,  84.1303,  58.6846,  14.8127, 197.0674,  71.7371,  57.3976,\n",
      "          35.8890,  50.1907,  44.6188]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.02 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[ 660.2472,   97.5130,   80.9591,   45.7562, 1132.6721,  543.2574,\n",
      "           51.6818,   68.3395,   16.2316,   51.0947]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 0.00 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[467.8591,  47.4016,   5.2764,  10.1144,  63.8388, 174.8438,  53.4109,\n",
      "          27.1432, 129.9547,  55.9721]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.01 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[ 195.2172,   29.8719,  106.7363,   21.6865, 1477.9750,  546.9236,\n",
      "           51.4737,   44.7827,   70.2052,   31.4929]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 0.02 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[464.9599,  63.9633,  28.5593,  30.4388, 500.9750, 744.8533,  46.1215,\n",
      "         126.6688,  34.3750,  23.7361]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.00 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[214.1956,  75.5793,  34.7824,   7.8104, 904.5437,  33.5947,  54.0009,\n",
      "          49.6771,  35.3872,  32.8763]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.02 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[667.3204, 109.9914,  67.6222,  45.8895, 853.2160,  45.0292,  42.0296,\n",
      "         124.5377, 113.4517,  73.3656]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.01 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[2.1451e+02, 1.1810e+02, 8.1244e+01, 2.6903e-01, 1.4053e+03, 2.3213e+02,\n",
      "         5.8192e+01, 1.3959e+02, 6.1265e+01, 7.8144e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 24 took 0.02 seconds\n",
      "最优点: [0.9912552237510681, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863]\n",
      "tensor([[1089.2396,   78.0076,  107.9582,   13.6721,  915.9850,  434.3955,\n",
      "           52.9896,  100.5988,  106.1669,   11.1080],\n",
      "        [ 371.2330,   54.2200,   35.3618,   18.7707,  286.2199,  734.8804,\n",
      "           53.1260,   26.9835,   76.6771,   37.6968],\n",
      "        [ 266.2530,  104.6275,   44.1561,   47.7926, 1079.6652,  525.3959,\n",
      "           50.5033,   61.2882,   62.1187,   63.1404],\n",
      "        [ 402.3087,  113.9892,    4.3447,   10.2045,  129.0450,  304.5634,\n",
      "           43.3355,   73.3621,   52.7524,   36.7417],\n",
      "        [ 200.1535,  101.3917,   92.5688,   10.5239,  239.4705,  398.5315,\n",
      "           53.3588,   55.9908,   22.0208,   77.6007]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 813.6232,   58.4435,   74.5118,   46.2125, 1157.2433,  407.5278,\n",
      "           55.0456,  149.4076,   35.4046,   41.3994]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 0 took 0.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[1.1033e+03, 3.9688e-01, 7.8742e+01, 1.7979e+00, 1.1685e+03, 1.0698e+02,\n",
      "         4.0343e+01, 3.2372e+01, 3.8698e+01, 3.1852e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 0.02 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[ 923.2198,   65.7967,  109.2990,   24.7870, 1469.5474,  236.9924,\n",
      "           55.8933,  154.9544,   78.9359,    2.0778]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 2 took 0.00 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[ 486.7327,   97.2149,   45.4034,    5.8261, 1456.3628,  542.9847,\n",
      "           44.3601,  112.9864,   92.8104,   38.5697]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 0.01 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[ 323.6258,   79.9807,   18.5462,    4.3013, 1267.1904,   41.5582,\n",
      "           46.1712,  154.9080,   93.1631,   43.0481]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 4 took 0.02 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[965.1584,  83.9353,  72.9576,  40.7333, 879.9700, 240.0229,  53.3083,\n",
      "         116.5183,  59.9735,  58.3431]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.00 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[946.3406,  21.6160,  64.7166,  30.6770, 476.4441, 406.2560,  51.7975,\n",
      "         122.1791,  22.5816,  28.7458]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.02 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[116.3586,  52.2387,  23.7770,   1.0620, 318.7533, 628.7025,  51.5287,\n",
      "          28.0652, 147.4432,  50.7027]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.01 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[817.7496,  91.4621,  50.6157,   2.8842,  16.4694, 794.1732,  50.3500,\n",
      "          44.9877,  71.6502,  52.8917]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.00 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[ 787.6709,   16.5026,    2.9513,   28.2127, 1366.2787,  780.0783,\n",
      "           54.4673,  129.2586,  146.2258,   21.1634]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 9 took 0.02 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[  8.5338,  71.5491,   3.3209,  46.3105, 119.3944, 486.3355,  55.8687,\n",
      "          87.6470,  35.6198,  51.1778]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.02 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[8.9648e+02, 1.2666e-01, 1.1998e+02, 2.7302e+01, 5.5950e+02, 3.5245e+02,\n",
      "         5.1448e+01, 1.4018e+01, 1.2947e+02, 7.3139e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 0.01 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[1137.0381,   48.5654,   49.2748,    4.7636, 1040.2013,   92.5230,\n",
      "           55.5841,   46.0314,  157.3646,   65.1560]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 0.00 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[ 53.2814,  26.4045,  88.4623,  27.1837, 633.7545, 430.9765,  46.3663,\n",
      "          70.1425, 111.6840,  50.4981]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 0.02 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[ 612.1526,   52.0144,   28.7251,   12.5673, 1092.4619,  707.6286,\n",
      "           45.9598,   13.5429,  136.3430,   47.7444]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 14 took 0.01 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[1.0732e+03, 5.5354e+01, 7.4607e-01, 2.0359e+01, 6.4194e+02, 1.0762e+02,\n",
      "         5.4899e+01, 2.6659e+00, 1.0105e+02, 9.0724e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 0.02 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[ 507.3554,   90.3496,   80.6169,    6.0885, 1155.8700,  409.0855,\n",
      "           40.7574,  102.1387,   71.3950,   37.1408]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.00 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[588.7716,   8.9122,  84.7515,   2.5927, 871.7907,  40.4393,  53.9344,\n",
      "         131.9249,  42.3461,  26.9042]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.02 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[ 961.4285,   27.3074,   62.1160,    3.9325, 1244.4801,  599.7605,\n",
      "           51.1245,   37.6031,  110.0178,   52.0620]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 0.01 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[ 635.6297,   84.0952,   43.9457,   27.9468, 1244.2706,   35.6640,\n",
      "           42.5827,    7.6391,  104.9715,   24.8471]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 0.00 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[1.0392e+03, 1.1875e+02, 3.9544e+01, 8.3047e-01, 7.4606e+02, 3.2328e+02,\n",
      "         4.9607e+01, 1.5763e+02, 9.8525e+01, 4.2603e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 0.02 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[ 643.4496,   66.5932,  109.6665,   47.2266, 1423.5082,  599.7885,\n",
      "           54.1035,   54.5659,   55.9411,   76.0897]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 0.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[890.9104,  61.2629,  30.0504,  26.8039, 734.5144, 152.2962,  46.2029,\n",
      "          38.0291, 154.2347,  44.0770]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.01 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[615.5395,  67.9985,  40.8787,   4.4018, 846.5736, 317.6197,  50.9569,\n",
      "         157.6000,  65.2690,  66.9952]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.00 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[1053.6294,   27.2379,   75.0113,   46.1929, 1151.1587,  328.4516,\n",
      "           40.0467,   98.3047,   82.2185,   24.6214]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 24 took 0.02 seconds\n",
      "最优点: [1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995]\n",
      "tensor([[ 975.5257,   75.7973,   97.4184,    9.7173,  106.6926,  451.4654,\n",
      "           45.1821,   12.0112,   24.6909,   16.3742],\n",
      "        [ 641.8907,   59.1715,    2.3275,   12.8983,  675.0399,  796.5588,\n",
      "           55.6736,   49.7215,   81.3868,    8.0365],\n",
      "        [ 131.6560,    8.9748,    2.9430,   19.5062,  960.8623,  117.0835,\n",
      "           42.6072,   12.9522,   77.2567,   31.8659],\n",
      "        [ 957.4030,  108.2847,    3.7889,    6.0420, 1169.0379,  507.3486,\n",
      "           41.9790,  114.1495,   56.5446,   46.6285],\n",
      "        [ 543.9748,   78.4735,   94.0992,   27.6257, 1144.5549,  292.3492,\n",
      "           43.3666,  109.5231,   53.6293,   76.3860]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 22.6307, 112.6640, 102.5841,   7.1879, 395.3033,  36.3706,  54.0687,\n",
      "         108.7412, 113.8538,  66.2278]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[ 708.2321,   53.4551,   91.2011,   22.0643, 1033.1778,  202.2253,\n",
      "           53.2007,  123.8823,   62.3300,   19.8959]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 0.02 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[ 142.6315,   82.9258,   81.4943,   14.3591, 1005.0096,  517.3536,\n",
      "           53.4457,  143.6667,  159.1741,   50.0466]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 2 took 0.00 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[917.9288, 110.0273,  96.4044,  15.5786,  30.6317, 756.2915,  55.4783,\n",
      "         156.5106, 125.3202,  41.7220]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.01 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[ 53.6783,  47.9130, 104.2577,  44.0827, 856.7141, 466.6686,  44.3927,\n",
      "           8.9013, 133.0413,  27.3523]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.02 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[163.1714,  33.2591,  11.9047,  40.6021, 370.3150, 270.4279,  40.4264,\n",
      "          78.2782,  80.8770,  17.7181]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.02 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[1194.5298,   52.7061,   31.2800,    4.2321,  398.3265,  741.2293,\n",
      "           43.4907,   69.6345,   94.2946,    5.8638]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 0.00 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[552.6892,  31.3676, 115.0726,  25.1105, 509.7287, 769.2162,  51.6026,\n",
      "          60.3413,  27.3402,  62.5462]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.01 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[1149.1992,   19.7338,   52.7684,    8.8002,  308.6079,  616.0686,\n",
      "           54.1604,    8.8513,    7.6434,   36.3957]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 0.02 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[353.4260, 101.1097,  63.4933,  23.3432, 771.1734, 116.1289,  58.6250,\n",
      "         157.4427, 152.9936,  54.7387]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.00 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[ 822.9755,   64.1306,   28.1639,   27.8285, 1262.1070,  430.8911,\n",
      "           55.7063,   55.8801,    3.1592,    9.2306]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 0.01 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[576.0833,  80.7130,  15.8170,   9.1895, 238.7667, 425.7163,  57.8219,\n",
      "          91.1932, 123.6756,  68.6966]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.02 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[389.9801,  62.2140,  73.2093,  19.7198, 719.4415, 159.6435,  55.4215,\n",
      "          98.8107,  83.9225,  27.9965]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.02 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[1042.1872,   31.5604,   17.3469,   28.7166,  655.2823,   40.1299,\n",
      "           52.6183,   79.2574,   92.0457,   12.8674]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 0.00 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[377.6197,  73.7004,  19.5511,  42.1828,  16.0213,  24.8863,  51.5272,\n",
      "         105.1641,  17.2267,  74.3961]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.01 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[ 348.6701,   49.5849,    6.6765,   11.3148, 1084.4602,  406.3080,\n",
      "           57.4673,    6.9387,   71.6657,   11.4513]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 0.02 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[ 676.2275,   32.5221,   98.7226,   19.3298, 1497.7372,  248.4141,\n",
      "           46.7420,   56.8421,   92.4221,   28.4154]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.00 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[318.9213,  82.3975,  80.8878,  42.9709, 528.1213, 482.8954,  52.4401,\n",
      "          69.5370,  56.6544,  26.2094]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.02 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[ 26.7986,   1.8361,  42.4417,  40.6889, 432.2949, 720.5244,  42.5758,\n",
      "          39.2143,  30.5300,  26.4419]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.01 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[558.3487,  56.3395,  88.9081,  12.5893, 241.4974, 497.0251,  58.2861,\n",
      "          79.0940, 138.8648,  28.2760]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[391.2649, 118.6109,  92.0926,  39.5924, 825.6366, 715.1257,  49.1399,\n",
      "         126.0413,  69.8022,  15.1378]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.00 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[542.5435,  63.0197,  86.8259,  26.9456, 213.9887, 766.8317,  52.0421,\n",
      "          18.0147, 104.5678,  56.3724]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.01 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[ 32.7008,  99.9789, 113.8092,  45.4690, 392.9332, 680.7659,  41.1800,\n",
      "          50.5468,  96.1080,  47.9627]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.02 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[391.9393,  60.5896,  99.2850,  49.2405,  82.4252, 662.5470,  41.1286,\n",
      "           7.0663,  42.1622,  45.0611]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.02 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[141.3326,  41.5173,  74.5129,  24.2174,  97.9462, 598.6879,  42.9288,\n",
      "         128.3200,  80.3582,  14.3445]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.00 seconds\n",
      "最优点: [1.3367308378219604, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113]\n",
      "tensor([[ 957.2990,  114.5814,  119.7566,   22.1784,  580.8580,  369.7469,\n",
      "           43.1374,  153.0257,   88.2778,   25.1513],\n",
      "        [1005.1571,   78.6979,  107.4027,   31.9806,  731.7871,  363.0733,\n",
      "           43.2728,   19.5839,  127.7233,   21.5319],\n",
      "        [ 204.9743,  114.6409,   69.5192,   14.9780, 1326.8383,   32.1989,\n",
      "           49.7994,  125.6573,  159.3024,   19.6523],\n",
      "        [ 705.0015,   98.5678,   71.2594,    2.5301,   55.8065,  531.0915,\n",
      "           47.0542,   24.5839,  100.1481,   78.0224],\n",
      "        [  44.6417,   98.2833,   33.8330,   46.5741,  886.5213,  364.4133,\n",
      "           40.3616,  120.4623,   53.2566,   32.8309]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[8.8169e+02, 6.1823e+00, 5.3278e+01, 3.8255e+00, 4.9446e+02, 6.2573e+02,\n",
      "         4.6407e+01, 6.2915e-01, 1.5246e+02, 7.7207e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 0 took 0.02 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[345.1535,   8.1126,  71.1782,  36.2959, 286.7347, 249.6322,  59.7263,\n",
      "         117.5730, 147.2857,  30.4043]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.01 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[1053.7720,  100.2258,   97.7569,   26.5732,  238.9792,  327.1778,\n",
      "           49.5909,    8.0480,   65.2821,   12.3301]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 2 took 0.00 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[915.4143,  90.5669,  31.4891,  25.8015, 419.8107, 597.1557,  51.9920,\n",
      "          51.7505,  18.8755,  54.0598]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.02 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[1049.9389,   72.3757,   63.3445,   14.6812,  253.2192,   94.3386,\n",
      "           49.5075,  131.0088,   19.6357,   42.2166]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 4 took 0.01 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[ 464.5189,   59.4530,   83.8977,   49.2588, 1017.4077,  288.9275,\n",
      "           40.2105,   30.3185,  149.8453,   66.6959]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[  6.7263, 106.6896,  20.3811,  16.2972,  13.8858, 373.2128,  57.9539,\n",
      "          11.8795, 129.9229,  20.0674]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.02 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[287.0863,  34.1385,  26.9258,   2.3953, 517.5308, 431.6168,  59.2639,\n",
      "         146.5899, 121.1874,  36.3864]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.02 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[243.5015,  62.4025,  80.1816,  27.5489, 802.7036, 153.6331,  53.1042,\n",
      "          80.3581,  39.4661,  35.3117]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.01 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[633.8848,  49.0251,  63.6434,  48.7608, 424.3890, 172.6764,  59.0005,\n",
      "          19.5010, 104.4473,  19.8931]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.00 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[475.0414, 113.4081,   9.1336,   4.6687, 139.9734, 252.8931,  48.1276,\n",
      "          32.4436,  57.1294,  33.7805]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.02 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[156.3194,  10.7393, 105.6361,  46.9255, 942.4417, 331.9179,  51.7961,\n",
      "          10.3236,  69.3907,  57.5022]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.02 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[ 714.4155,   90.4504,   24.8729,   26.2314, 1158.4356,  286.3062,\n",
      "           47.3289,   23.7147,  148.2217,   65.5622]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 0.01 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[ 268.1473,  118.9030,   49.2797,   25.8809, 1399.5086,  403.4691,\n",
      "           59.3467,   77.0299,   24.9307,   61.3732]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 0.00 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[1102.6909,   53.7376,   18.5364,   25.3032, 1122.2481,  558.5054,\n",
      "           55.9429,  141.9894,  102.7755,   45.2840]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[803.0957,  47.2104,  17.7926,  12.6895, 120.6633,  19.2572,  41.6314,\n",
      "          59.6407, 116.8605,   8.5702]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.01 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[838.9918,  11.5665,  33.5324,  29.4703, 835.4545, 664.0751,  45.7318,\n",
      "         111.1996, 117.9890,  29.4067]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 0.00 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[515.2164, 109.9611,  80.2868,  13.6009, 363.1831, 205.6814,  47.0227,\n",
      "          85.7173, 104.0718,  46.6758]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.02 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[286.5524, 116.4154,  95.3368,  41.1712, 483.8701, 769.5979,  58.2923,\n",
      "         125.6011,  23.7163,  42.6683]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.02 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[1029.9773,   73.7517,  104.7500,   49.3672,  360.5003,  788.6111,\n",
      "           48.7335,  111.6051,   18.7389,   66.1582]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 0.01 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[873.0858,  14.0142,  26.3073,  35.0337, 387.8967, 618.1891,  50.0269,\n",
      "         135.6721, 110.7302,  32.7814]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.00 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[337.1679,  44.9265,  81.6039,  22.2695, 453.8797, 681.3134,  54.4461,\n",
      "          34.6737,  44.0020,  53.2353]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.02 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[581.4547,  87.8601, 113.7067,   6.6082, 614.1712, 593.6221,  41.5704,\n",
      "          50.9116,   7.1824,   1.4032]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.02 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[1051.7683,   43.7923,   22.0503,   49.4769,  498.5712,  729.1897,\n",
      "           41.2454,   29.0847,  146.2241,   18.4949]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 0.00 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[1092.2861,   15.5653,   80.7619,   26.4553,  660.7197,    6.4225,\n",
      "           59.5631,  152.2782,   19.7399,   64.3545]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 24 took 0.01 seconds\n",
      "最优点: [1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271]\n",
      "tensor([[8.3487e+02, 3.7781e+01, 6.7576e+01, 3.4817e+01, 7.3967e+02, 1.1073e+02,\n",
      "         4.6184e+01, 9.7690e+00, 1.8519e+00, 2.6908e+01],\n",
      "        [1.9834e+02, 3.5492e+01, 6.4748e+01, 2.5186e+01, 8.3869e+01, 5.7601e+02,\n",
      "         5.7008e+01, 3.5315e+01, 1.4418e+02, 7.2061e+00],\n",
      "        [1.2088e+02, 3.1864e+01, 6.3096e+01, 4.4615e+01, 1.2117e+03, 4.6117e+02,\n",
      "         5.8921e+01, 1.1346e+02, 2.2059e+01, 7.3192e+01],\n",
      "        [1.0915e+03, 8.4056e+01, 4.3915e+01, 1.2070e+01, 6.9677e+02, 7.9252e+02,\n",
      "         4.2287e+01, 8.3152e+01, 1.1297e+01, 3.6502e+01],\n",
      "        [7.6507e+02, 6.6852e+01, 3.5124e+01, 3.9579e+01, 1.8612e+02, 5.5315e+02,\n",
      "         5.2762e+01, 1.2542e+02, 9.1622e+01, 2.3322e-01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 80.9774,  57.0815,  51.3614,  19.7722, 806.8362, 653.6837,  43.0532,\n",
      "          76.5456,   3.6371,  34.4483]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.00 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[ 146.3703,   54.5027,  115.4227,    9.6772, 1415.9367,  276.3376,\n",
      "           41.6262,   29.1981,   49.7647,   31.8600]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 0.02 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[125.4193,   3.8824,  73.7294,  13.9776, 511.6325, 183.0098,  57.9525,\n",
      "          34.3588,  61.1184,  57.5742]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.02 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[582.8564,  55.0633,  98.7274,  34.6660, 226.8829, 141.1359,  51.1198,\n",
      "          20.3567,  74.9637,  67.9327]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[473.4689,  76.0171,  16.4680,  48.7532, 333.4283, 404.0494,  56.9041,\n",
      "         157.8662,  14.3378,  60.4394]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.01 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[ 570.3512,   83.7162,   51.3277,   45.6423, 1430.3140,  697.5411,\n",
      "           52.0694,   67.4609,   34.2467,   14.0169]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 0.02 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[ 368.4474,  114.7078,    8.8683,   25.2781, 1022.9651,  397.7927,\n",
      "           44.7276,   85.8385,   62.2416,   44.0074]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 0.00 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[704.6331,  77.7975,   9.2876,  24.5840, 478.3870, 655.8707,  56.8535,\n",
      "          68.1743,  71.4116,  62.1425]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.02 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[ 511.7203,   61.4216,   65.1953,    7.8548, 1465.6802,  150.1112,\n",
      "           57.7888,    4.5215,    8.5003,   74.1732]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 0.01 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[985.8816,  25.1805,  22.8685,  28.4559, 131.1216, 145.0300,  43.5244,\n",
      "         159.4293,  19.7995,   3.9688]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.00 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[1172.6629,   39.1882,    4.1599,   30.9282, 1051.6702,  706.7349,\n",
      "           45.7221,  122.9487,  139.7346,   57.7732]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 0.02 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[ 50.7498,  91.0668,  60.0087,  35.3488, 126.4984, 246.9520,  42.7225,\n",
      "         148.9391,  26.9397,  30.8205]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.01 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[186.7665, 102.2174,  88.6410,   2.9935,  61.9191,  26.5557,  52.0980,\n",
      "         158.0629, 117.9167,  38.5968]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.00 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[ 226.8227,    6.3034,   88.2798,   39.0248, 1076.2044,  619.3717,\n",
      "           48.8064,  158.9326,   17.7055,   48.9892]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 0.02 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[675.3048,  30.8455,  40.0488,  33.5981, 238.4293, 429.4081,  45.3852,\n",
      "          58.2935,  56.1692,  70.3014]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[681.0453,  18.0833, 117.5832,  29.8999, 109.7772, 470.5271,  45.0871,\n",
      "          80.6432, 112.0434,  43.2298]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.00 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[812.7321,  58.8831, 113.5330,  21.9479, 331.3092, 440.5810,  47.7892,\n",
      "          48.4927, 152.6613,  59.0903]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 0.01 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[ 995.4003,   20.7095,   12.7187,   18.2602, 1294.5996,  344.3145,\n",
      "           41.3254,  143.1975,   46.3028,   16.3700]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 0.02 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[7.1361e+01, 1.1548e+00, 3.8315e+01, 3.4731e+01, 1.4844e+03, 1.1514e+01,\n",
      "         5.4071e+01, 2.9724e+01, 1.1279e+02, 4.4510e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 0.02 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[1046.8456,  111.9086,   94.8487,   14.8640,  160.6138,  477.3487,\n",
      "           53.6559,  154.9818,   18.7057,   71.2491]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 0.03 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[398.3464,   9.5752,  51.1255,  29.7670, 331.1092, 222.2361,  40.4664,\n",
      "          85.2696,  77.7045,  74.2817]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.00 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[ 81.7317,  25.3757,   6.5674,  21.4863, 845.5429, 670.8372,  52.9122,\n",
      "          24.6308,  34.5286,  50.0419]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.01 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[760.4615,  24.2301, 108.1802,  39.8329, 296.3530, 733.0370,  50.2527,\n",
      "         146.5765,  88.5108,  29.9991]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.02 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[1160.8915,   99.6287,   72.8621,   45.3188,    5.4586,  162.8539,\n",
      "           40.7581,   60.8944,  157.6326,   61.2917]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 0.00 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[7.1870e+02, 1.2117e+01, 9.7185e-01, 3.9074e+01, 1.3578e+03, 7.3129e+02,\n",
      "         4.4095e+01, 1.1159e+02, 2.0332e+01, 6.8661e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 24 took 0.02 seconds\n",
      "最优点: [0.7767000198364258, 1.3188371658325195, 1.3188371658325195, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741]\n",
      "tensor([[2.7407e+02, 1.0158e+02, 2.6207e+01, 2.9812e+01, 1.2403e+03, 4.2020e+02,\n",
      "         4.3232e+01, 4.6422e+01, 1.3633e+02, 1.2846e+01],\n",
      "        [1.1588e+03, 6.7166e+01, 3.6018e+01, 2.0330e+01, 7.3465e+02, 2.7304e+02,\n",
      "         4.3777e+01, 1.0825e+02, 7.3245e+01, 1.7409e+00],\n",
      "        [7.2736e+02, 3.7359e+01, 2.7838e+01, 4.4994e+01, 6.7884e+02, 5.7656e+02,\n",
      "         4.7248e+01, 1.5862e+01, 1.5852e+02, 4.8607e+01],\n",
      "        [7.0483e+02, 3.2612e-01, 4.9636e+01, 3.2278e+01, 6.3977e+02, 2.6749e+02,\n",
      "         5.9483e+01, 1.3580e+02, 8.0070e+01, 5.5668e+01],\n",
      "        [9.3328e+02, 2.0649e+01, 3.8957e+01, 1.3124e+01, 1.2519e+03, 1.2955e+02,\n",
      "         5.9328e+01, 1.3711e+02, 1.3935e+02, 6.2361e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 723.4830,  119.6706,   80.9571,   29.0626, 1249.4234,  673.2457,\n",
      "           53.9283,  101.5355,    6.7332,   72.2380]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 0 took 0.02 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[124.3336,  78.2410,  11.0370,  22.8121, 687.6742, 256.2280,  57.2020,\n",
      "          86.1893,  67.2349,  16.8896]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.02 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[340.1007,  42.0175,  39.0883,   3.0193, 457.1044, 255.8566,  43.7794,\n",
      "           5.8175,   1.4296,   1.4938]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.01 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[456.0374, 107.6093,  13.4805,   5.2825, 158.2720, 489.7390,  55.5676,\n",
      "          42.3846,  55.1303,  48.5892]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[796.4996,  94.5756,  50.6700,  20.4160,   3.2213,  80.7515,  48.8848,\n",
      "          62.7489,   8.9992,  11.0951]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.02 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[527.4713,  69.5608,  36.9507,  46.1831, 841.3978, 401.7406,  59.0656,\n",
      "          62.8393, 153.5547,  61.0681]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.01 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[  6.6613,  13.4065,  70.5421,  20.6516, 584.3153, 460.6134,  55.4853,\n",
      "         130.7099,  57.7665,  39.1486]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.00 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[  3.4706,  32.7586,  21.5432,  24.9374, 200.8974, 720.2855,  50.3588,\n",
      "          97.1429,  82.7573,  72.2073]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.02 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[ 37.4862,   7.0543,  31.9887,   7.2157, 102.1776, 765.4109,  49.9856,\n",
      "          22.8727,  36.1787,  26.1797]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.02 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[7.8950e+02, 4.9482e+01, 1.1861e+02, 2.4944e-01, 1.0571e+03, 3.1506e+00,\n",
      "         4.8201e+01, 1.3054e+02, 8.3512e+01, 5.3292e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 9 took 0.00 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[659.9505,  75.4609, 111.2176,  31.5818, 867.9248,  57.3914,  44.9349,\n",
      "         119.7763,  47.5924,  28.3494]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.01 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[690.1875,  43.2564,  76.4667,  33.2381, 301.2131, 446.4274,  57.3828,\n",
      "         140.2030,  15.8923,  63.6263]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.00 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[491.0308,  89.2704,  16.8497,  48.3081, 503.3718, 501.4168,  50.7420,\n",
      "          12.3008,  43.7040,  32.6275]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[ 792.5270,   92.9274,   17.4456,   31.3324, 1131.7423,  145.7962,\n",
      "           54.9527,    7.8879,   13.5031,   31.6844]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 0.02 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[235.0760, 117.6933,  10.3063,  21.2299, 878.3329, 555.9921,  57.4121,\n",
      "          80.7648, 146.6102,  50.4492]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.01 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[1.1963e+03, 1.1293e+02, 5.8984e-01, 1.4083e+01, 7.8979e+02, 2.6842e+02,\n",
      "         4.3266e+01, 7.3029e+00, 5.1320e+01, 6.1442e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 0.00 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[ 962.8834,   96.7512,   87.3006,   48.2752, 1143.6369,  489.5415,\n",
      "           46.8863,   49.6487,  147.9991,   20.6818]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.02 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[2.2765e+01, 6.0003e+01, 6.9771e+01, 3.8780e-01, 1.2376e+02, 7.1280e+02,\n",
      "         4.4319e+01, 4.3790e+01, 1.4057e+02, 4.9766e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 0.01 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[490.6266,  27.9058,   1.6548,  30.2758, 792.9218, 294.7710,  47.2814,\n",
      "         130.1859, 114.7550,  49.8702]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.02 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[586.9935,  75.2629,  35.1966,  10.8182, 293.5464, 571.7955,  55.0652,\n",
      "          71.8252, 106.7085,  77.5356]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.00 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[  17.1942,   44.3700,   43.7054,   43.3758, 1015.4243,  349.5262,\n",
      "           52.7255,   68.9233,  132.9464,   22.8814]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 0.02 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[6.4638e+01, 6.6149e+01, 1.1904e+02, 3.1940e-01, 1.4243e+03, 1.2084e+01,\n",
      "         5.1275e+01, 9.2784e+01, 1.2505e+02, 4.4466e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 0.01 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[1011.0460,   74.9387,   51.4117,   21.7593,  300.3479,  301.5350,\n",
      "           45.8957,   83.4891,   79.0046,   67.7044]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 22 took 0.00 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[6.2977e+02, 7.2412e-01, 1.9186e+01, 4.7470e+01, 1.1429e+03, 3.0293e+02,\n",
      "         4.0608e+01, 1.3590e+02, 7.8313e+01, 5.3116e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 0.02 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[901.0386,  55.8550,  62.7727,  26.3142, 225.1362, 183.6584,  57.9150,\n",
      "          28.1745,  77.4893,  22.1983]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.02 seconds\n",
      "最优点: [1.3001327514648438, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.370611548423767, 1.370611548423767, 1.370611548423767, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899]\n",
      "tensor([[1.0477e+03, 1.0276e+02, 9.8685e+01, 1.9143e+01, 2.8138e+02, 4.0193e+02,\n",
      "         4.4285e+01, 8.3141e+01, 6.2694e+01, 6.9649e+01],\n",
      "        [3.3544e+02, 8.7918e+00, 1.1059e+02, 3.8653e+01, 4.5654e+02, 5.7986e+02,\n",
      "         4.7938e+01, 5.0211e+01, 1.1085e+02, 2.5496e+01],\n",
      "        [1.1548e+03, 7.4763e+01, 1.1039e+02, 4.8142e+01, 1.5808e+02, 2.0698e+02,\n",
      "         4.6601e+01, 1.0942e+02, 5.9340e+01, 2.3616e+01],\n",
      "        [3.5968e+02, 2.6152e+01, 8.1701e+01, 2.4089e+01, 1.4360e+03, 3.1059e+00,\n",
      "         5.1369e+01, 5.1384e+01, 1.3409e+00, 2.2767e+01],\n",
      "        [9.7731e+02, 3.8286e+01, 3.0578e+01, 1.0762e+01, 1.3673e+03, 1.7356e+02,\n",
      "         4.2212e+01, 1.1171e+02, 1.5604e+02, 4.8352e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 52.4841,  73.2758,  57.2005,  18.5508, 130.5559,  46.9863,  48.4788,\n",
      "          86.4358, 148.7863,  20.8387]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.02 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[  72.7271,   40.6978,   12.5948,   46.7646, 1217.4276,  126.7839,\n",
      "           59.6376,  102.7337,  132.3692,   50.3389]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 0.00 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[1169.7049,  105.8008,   23.3750,   33.5748,  167.3464,  308.3696,\n",
      "           58.7707,   71.4699,   43.1116,   11.0501]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 2 took 0.01 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[ 194.9028,  107.9919,   58.6736,   27.1895, 1056.2441,  545.0952,\n",
      "           41.3699,   95.5964,   75.0997,   15.6957]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 0.02 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[850.3778,  39.9423,  10.8901,   1.7972, 238.4367, 141.8941,  44.1406,\n",
      "         147.1394,  10.1340,  32.5566]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.02 seconds\n",
      "Nr. of optimization run: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New candidates are: tensor([[584.6441,  89.4157,  41.0487,  48.3042, 984.9341, 280.2737,  46.6234,\n",
      "          33.3355, 101.9074,   1.8921]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.01 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[529.8660,  11.9198,   4.5401,  45.1664, 546.6890, 635.4683,  42.0380,\n",
      "          60.6889,  28.1619,   6.3064]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.00 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[ 395.1941,   56.0213,   38.9446,   24.0556, 1336.7481,   71.2302,\n",
      "           41.5003,  126.5332,  120.9649,   57.3811]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 7 took 0.02 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[1166.4233,   68.8221,    6.9464,   35.9425,  488.8623,  155.6820,\n",
      "           41.1541,  105.2949,   33.4966,   79.1427]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 0.03 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[882.1702,  16.1970,  25.8422,  35.3398, 553.8846, 229.2849,  40.8824,\n",
      "         118.6544, 118.1065,  45.0887]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.02 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[594.0749,  73.6266,  61.1858,  27.1097, 894.1318, 166.6680,  42.5763,\n",
      "          24.6157,  80.1103,  59.5951]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.00 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[ 840.5449,   48.6550,   68.4523,   18.5221, 1031.2751,  350.8356,\n",
      "           59.4498,   11.2867,    2.1929,   57.5141]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 0.01 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[775.8570,  34.8212,  68.9729,   5.1385, 773.4146, 738.2565,  40.1354,\n",
      "         111.8087,  36.0926,  27.6851]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.02 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[636.7086,  29.0679,  46.9454,  11.7386, 425.4283, 206.0485,  55.7546,\n",
      "         143.6639,  21.2731,  12.9871]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 0.02 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[958.2529,  38.0748,  65.7232,  44.8071, 101.5445, 797.6568,  55.7436,\n",
      "         158.5618,  47.7123,  32.6445]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.00 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[ 325.2698,   17.1496,  114.3352,   39.9324, 1270.8177,  344.7442,\n",
      "           55.6839,   17.4334,   30.0327,   49.9286]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 0.01 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[704.9163,  29.5202,  14.3356,  28.9129, 814.2138, 539.9977,  53.1265,\n",
      "         136.4733,  83.4755,  42.2563]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 0.02 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[444.2120,  13.6445,   5.1648,  11.2132, 558.8137,  31.9144,  49.9539,\n",
      "         118.8527,  36.2422,  10.5224]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.00 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[189.0121,  13.0035,  59.5125,  40.5879, 127.7241, 118.6423,  49.3487,\n",
      "         103.9003,  97.3796,  37.0906]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.02 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[312.4037,  12.1136,   4.6411,   6.3205, 620.2599, 521.0629,  44.1845,\n",
      "          59.0235, 124.2954,  47.0227]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.01 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[282.7920,  92.3692,  30.6764,  49.6125, 232.5511, 570.7874,  47.8898,\n",
      "          79.7296, 100.1655,  49.5529]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.00 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[1053.0714,   96.0979,   72.5330,   27.5896, 1148.3489,  672.0209,\n",
      "           48.5953,  152.6427,    6.3867,    3.4835]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 0.02 seconds\n",
      "Nr. of optimization run: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New candidates are: tensor([[1082.1278,    3.4985,   22.9597,    3.4987,  983.4605,  309.8914,\n",
      "           56.5905,  103.0934,  138.7514,   23.7681]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 22 took 0.01 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[187.7040,   9.7963,  77.7692,   4.5587, 818.8813, 201.3584,  49.5221,\n",
      "          72.4938,  99.8067,  33.3423]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.02 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[1129.5383,   65.0644,    3.3649,   28.0084,  804.0414,  422.7891,\n",
      "           40.4678,    4.6792,   27.3703,   49.4104]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 24 took 0.00 seconds\n",
      "最优点: [0.9895653128623962, 0.9895653128623962, 0.9895653128623962, 1.2919471263885498, 1.3033850193023682, 1.322786569595337, 1.322786569595337, 1.322786569595337, 1.322786569595337, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3954377174377441, 1.3954377174377441, 1.3954377174377441, 1.3954377174377441]\n",
      "tensor([[6.5417e+02, 4.5062e+01, 7.2948e+01, 1.2145e+01, 1.3197e+03, 2.3310e+01,\n",
      "         4.3512e+01, 3.3130e+01, 3.8106e+01, 1.4550e+01],\n",
      "        [2.2071e+02, 1.3995e+01, 3.2416e+01, 2.8952e+01, 5.5420e+02, 6.3027e+02,\n",
      "         5.8717e+01, 1.0903e+02, 8.5038e+01, 2.4416e-01],\n",
      "        [3.4589e+02, 4.4364e+01, 8.1701e+01, 2.8330e+01, 1.0728e+03, 7.6572e+02,\n",
      "         5.3650e+01, 1.6991e+01, 1.2770e+02, 2.3919e+01],\n",
      "        [9.5245e+02, 5.5016e+01, 5.0517e-01, 4.9695e+01, 1.1746e+03, 2.5010e+02,\n",
      "         4.1631e+01, 1.9245e+01, 1.4036e+02, 6.4667e+01],\n",
      "        [1.4139e+02, 8.4173e+01, 1.1177e+02, 1.6270e+01, 4.2586e+02, 2.7306e+01,\n",
      "         5.4309e+01, 1.3814e+02, 5.1891e+00, 2.3243e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 19.2256,  40.7290,  24.4156,  29.3406, 793.9997, 506.5207,  58.1527,\n",
      "          68.2647, 107.4226,  36.1968]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.00 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[1044.3606,   38.6210,    9.8935,   49.5401,  694.1077,  487.2895,\n",
      "           54.0034,   23.2287,  119.2080,   41.2595]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 0.02 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[749.7621,  51.2532,  50.9759,  40.8044, 656.9415,  65.5803,  59.5118,\n",
      "          54.0206, 106.5555,  41.4638]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.02 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[270.2316,  61.3485,   1.5729,   1.2425, 653.6774, 623.6655,  51.5468,\n",
      "          93.8035,  73.1086,  15.7610]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[ 899.0508,    8.9935,   29.0623,   22.0333, 1116.9654,  510.3201,\n",
      "           42.9143,  105.7790,  117.0874,   75.2451]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 4 took 0.01 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[ 31.0036,  32.3344,  59.1863,  43.1641, 392.1622, 657.7012,  46.9647,\n",
      "         141.9741,  44.4492,  46.4739]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.02 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[699.8015,  50.4432,  87.0562,  14.3081, 179.8127, 733.2791,  48.4192,\n",
      "         159.8535, 149.3228,  65.3292]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.00 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[897.4935,  88.9910,  15.3620,  30.9334, 577.9831, 664.3334,  47.6835,\n",
      "          56.6751, 144.0716,  31.4499]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.01 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[1115.5509,   90.0208,   72.3679,   37.1056,  451.1938,  127.4958,\n",
      "           59.9037,   42.2924,    8.0368,   68.6574]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 0.02 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[812.8429,  96.0816,  82.9750,  16.4653, 856.8434, 481.9322,  46.5587,\n",
      "          31.5969,  17.6913,  50.7702]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.00 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[884.5243,  90.2012, 115.2054,  35.3330, 959.9092, 641.3120,  48.4699,\n",
      "         127.2390, 156.0055,  66.1698]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.02 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[328.6136,  72.4969,  93.2919,  49.1413, 477.4332, 110.5727,  58.6804,\n",
      "           3.4314,  82.4673,  18.4790]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.01 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[ 981.0026,   53.6002,  115.5497,   22.7861, 1304.2476,  771.2086,\n",
      "           53.4542,   14.8773,   62.0806,   48.1041]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 0.02 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[1040.5091,   50.9922,   21.6236,    5.4296,  926.6996,  675.8121,\n",
      "           59.8504,  138.9615,   43.4784,   13.8802]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 0.00 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[545.9782,  10.2069, 111.2353,  30.9442, 415.7521, 132.2041,  42.1082,\n",
      "          13.4385,  49.1493,  28.1598]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New candidates are: tensor([[ 135.7055,  111.8474,  107.5304,   37.3160, 1205.6019,  576.1996,\n",
      "           43.4927,   70.3508,    4.4681,    5.4590]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 0.01 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[8.4259e+02, 2.0557e+01, 2.7699e-01, 1.1589e+01, 9.6399e+02, 1.6233e+02,\n",
      "         4.6573e+01, 4.4584e+01, 5.4979e+01, 3.8788e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.02 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[ 813.9955,   11.4123,  110.5407,    7.7483, 1047.8946,  674.0179,\n",
      "           54.4203,  152.7387,   51.6457,   69.1379]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 0.01 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[ 724.0251,    4.5664,   46.3714,   27.1162, 1234.4288,  650.7005,\n",
      "           58.9600,   77.7625,   12.7726,   28.0989]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 0.00 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[191.0370,  27.8027,   5.4206,  30.3910, 826.2362, 137.6117,  58.9775,\n",
      "          84.4086,  47.8305,  68.4285]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[ 615.8297,   58.9957,   93.4863,   35.6872, 1104.8811,  558.1831,\n",
      "           58.3836,  152.5635,   91.0896,   11.5248]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 0.02 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[ 126.6923,  104.7010,   88.4475,   43.3526, 1180.8214,  389.9813,\n",
      "           41.0950,  109.2951,    2.3814,   12.8271]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 0.00 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[1145.1804,   37.1053,   34.7911,   33.5618, 1272.1653,  231.7072,\n",
      "           49.9981,   12.1159,   34.3190,   63.4523]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 22 took 0.01 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[130.2852,  44.8177, 119.3204,  40.0575, 825.2220, 220.0510,  59.9707,\n",
      "          84.3020,  61.1814,  74.3447]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.02 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[ 87.0005,  30.4776,  33.4732,  14.0936,  35.0734, 526.7924,  54.0781,\n",
      "          17.8039, 132.1153,  19.0764]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.02 seconds\n",
      "最优点: [1.334701418876648, 1.334701418876648, 1.334701418876648, 1.334701418876648, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861]\n",
      "tensor([[ 373.5851,   42.3481,   28.2132,   47.7716,  401.0603,  708.0976,\n",
      "           45.3799,  139.8014,   74.1156,   70.0049],\n",
      "        [ 365.8422,   60.6736,   12.3250,   27.3812,  229.3148,  487.7974,\n",
      "           56.4798,  100.3647,  140.4854,   72.4745],\n",
      "        [ 199.3768,   19.6290,   91.8926,   33.6921,  706.9081,  493.1646,\n",
      "           41.0089,   87.0028,   48.8923,   73.7453],\n",
      "        [ 912.3393,   44.5452,   84.8709,   35.8131,  475.3241,  493.1233,\n",
      "           41.8152,  147.0894,  131.1938,   63.9720],\n",
      "        [ 943.6881,   30.6485,   73.7431,   43.8560, 1003.7825,  326.9272,\n",
      "           42.8058,  100.8544,   36.5746,   53.3754]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[356.8750,   3.8859, 107.9435,  41.8429, 885.6152, 451.5415,  59.8124,\n",
      "          13.6241,  88.5790,   4.5680]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.02 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[1008.9139,  109.1547,   94.8468,   26.6720,  870.0079,  261.4043,\n",
      "           57.5268,   51.5477,    3.4118,   15.4452]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 0.00 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[275.6176,  90.3378, 106.0758,   3.4773, 433.3562, 602.0149,  54.6193,\n",
      "         127.2256,  93.2286,  57.3359]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.01 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[460.3925,  75.4432,  43.4224,  13.4828, 286.0407, 476.6084,  46.3775,\n",
      "          44.8128, 104.5974,  77.1480]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.02 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[159.6419,   3.9513,   9.7572,  19.3013, 298.6027, 514.1487,  46.0739,\n",
      "         107.5270, 147.3943,  65.0993]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.00 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[ 608.6928,  111.8427,   79.0884,   46.2752, 1298.3966,  630.9392,\n",
      "           44.7477,   50.6671,   77.3222,   52.1568]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 0.02 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[ 35.5488,  97.8391,  83.4723,  45.8575, 430.5288, 161.0920,  52.1715,\n",
      "         120.5649, 119.0822,  23.5637]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[1086.7943,   76.8302,   77.3129,    1.5916,  428.7095,  490.7070,\n",
      "           48.2846,   52.5755,  116.2657,   47.0692]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 7 took 0.02 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[ 824.0052,  112.1696,   52.4748,   20.0359, 1185.0488,  516.8709,\n",
      "           54.1139,  133.2822,   79.2071,   79.2389]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 0.02 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[ 439.6671,   19.5915,   88.0446,   38.1007, 1194.2020,  356.9663,\n",
      "           52.4997,   56.0505,  101.2275,   59.9702]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 9 took 0.00 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[973.3023,  89.7441,  32.6959,  49.8566, 817.0017, 434.2860,  57.7368,\n",
      "         136.6063,  21.4027,  29.5029]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.01 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[204.4986,  69.9421,  71.1973,  19.3275,   8.6848, 479.8108,  49.7128,\n",
      "          44.5617,   7.3516,  66.5879]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.02 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[963.5283,  99.3910,  18.8742,  11.8255, 354.8299, 175.0492,  46.4555,\n",
      "          12.7840,  56.8945,  42.5036]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.01 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[ 286.9962,   36.8465,   84.7115,   13.5742, 1298.5117,  571.3059,\n",
      "           47.5183,   97.8439,   90.9431,   14.5500]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 0.00 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[ 985.1179,   65.2248,   62.3399,   49.5201, 1312.1439,  776.0528,\n",
      "           53.6656,  104.3009,   34.2417,   44.4759]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[559.9651, 106.3548,  71.1686,   3.6597, 563.9112, 772.9479,  53.8872,\n",
      "           7.1350,  53.4249,  34.9565]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.02 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[1038.1047,    4.5922,   24.0070,   21.3253,  695.8430,  220.7253,\n",
      "           42.3009,   58.1317,   81.7029,   29.8861]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.01 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[474.7740,  28.8157,   1.1634,  38.4942, 993.9044, 222.9268,  51.7248,\n",
      "          22.4024, 134.4844,  79.6297]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.00 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[631.3730,  41.6012,  20.7896,  47.8453, 336.2652, 698.2779,  55.9620,\n",
      "          25.0212, 116.7398,  11.0487]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.02 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[770.0065,  72.6285, 109.1637,  48.6993, 997.9168, 663.2613,  51.8909,\n",
      "          37.8674, 157.7027,  25.4140]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[481.1319,  10.5645,  81.0973,  42.9225, 494.9202, 157.7693,  58.7850,\n",
      "         139.5295,   7.5158,  44.4637]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.00 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[ 928.3703,   40.6826,   86.2429,   21.1701, 1149.1752,  172.7689,\n",
      "           51.6843,  132.3676,   14.3800,   12.8696]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 0.01 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[661.9718,  93.1545,  20.2932,   9.5123, 215.8330, 248.1232,  57.2180,\n",
      "         158.4105, 154.8603,  75.5608]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.02 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[ 218.4057,   20.8289,   62.4750,   31.6348, 1125.4580,  591.8084,\n",
      "           49.7801,  110.9660,   94.1153,   67.6728]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 0.01 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[624.7152,  19.5378,   1.6664,  30.4184, 566.8075, 297.4033,  50.6137,\n",
      "           6.3461, 121.0259,  22.1092]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.00 seconds\n",
      "最优点: [1.1667718887329102, 1.1667718887329102, 1.1667718887329102, 1.1799306869506836, 1.1799306869506836, 1.1799306869506836, 1.3362276554107666, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3794639110565186, 1.3794639110565186, 1.3794639110565186, 1.3794639110565186]\n",
      "Bayes Best Values Over All Experiments:\n",
      "[[0.8331813812255859, 0.8331813812255859, 1.3528671264648438, 1.3528671264648438, 1.3528671264648438, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.3729591369628906, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002, 1.375084400177002], [0.9912552237510681, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863, 1.3914990425109863], [1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3686450719833374, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995, 1.3872469663619995], [1.3367308378219604, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3462055921554565, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113, 1.3893322944641113], [1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.3735255002975464, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271, 1.375296950340271], [0.7767000198364258, 1.3188371658325195, 1.3188371658325195, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3751254081726074, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741, 1.3837083578109741], [1.3001327514648438, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.3473280668258667, 1.370611548423767, 1.370611548423767, 1.370611548423767, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899, 1.387661099433899], [0.9895653128623962, 0.9895653128623962, 0.9895653128623962, 1.2919471263885498, 1.3033850193023682, 1.322786569595337, 1.322786569595337, 1.322786569595337, 1.322786569595337, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3950504064559937, 1.3954377174377441, 1.3954377174377441, 1.3954377174377441, 1.3954377174377441], [1.334701418876648, 1.334701418876648, 1.334701418876648, 1.334701418876648, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3812850713729858, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861, 1.3911488056182861], [1.1667718887329102, 1.1667718887329102, 1.1667718887329102, 1.1799306869506836, 1.1799306869506836, 1.1799306869506836, 1.3362276554107666, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3766337633132935, 1.3794639110565186, 1.3794639110565186, 1.3794639110565186, 1.3794639110565186]]\n",
      "Bayes Best Values Over All Experiments (Array):\n",
      "[[0.83318138 0.83318138 1.35286713 1.35286713 1.35286713 1.37295914\n",
      "  1.37295914 1.37295914 1.37295914 1.37295914 1.37295914 1.37295914\n",
      "  1.37295914 1.37295914 1.37295914 1.37295914 1.3750844  1.3750844\n",
      "  1.3750844  1.3750844  1.3750844  1.3750844  1.3750844  1.3750844\n",
      "  1.3750844  1.3750844  1.3750844  1.3750844  1.3750844  1.3750844 ]\n",
      " [0.99125522 1.39149904 1.39149904 1.39149904 1.39149904 1.39149904\n",
      "  1.39149904 1.39149904 1.39149904 1.39149904 1.39149904 1.39149904\n",
      "  1.39149904 1.39149904 1.39149904 1.39149904 1.39149904 1.39149904\n",
      "  1.39149904 1.39149904 1.39149904 1.39149904 1.39149904 1.39149904\n",
      "  1.39149904 1.39149904 1.39149904 1.39149904 1.39149904 1.39149904]\n",
      " [1.36864507 1.36864507 1.36864507 1.36864507 1.36864507 1.36864507\n",
      "  1.36864507 1.38724697 1.38724697 1.38724697 1.38724697 1.38724697\n",
      "  1.38724697 1.38724697 1.38724697 1.38724697 1.38724697 1.38724697\n",
      "  1.38724697 1.38724697 1.38724697 1.38724697 1.38724697 1.38724697\n",
      "  1.38724697 1.38724697 1.38724697 1.38724697 1.38724697 1.38724697]\n",
      " [1.33673084 1.34620559 1.34620559 1.34620559 1.34620559 1.34620559\n",
      "  1.38933229 1.38933229 1.38933229 1.38933229 1.38933229 1.38933229\n",
      "  1.38933229 1.38933229 1.38933229 1.38933229 1.38933229 1.38933229\n",
      "  1.38933229 1.38933229 1.38933229 1.38933229 1.38933229 1.38933229\n",
      "  1.38933229 1.38933229 1.38933229 1.38933229 1.38933229 1.38933229]\n",
      " [1.3735255  1.3735255  1.3735255  1.3735255  1.3735255  1.3735255\n",
      "  1.3735255  1.3735255  1.3735255  1.3735255  1.3735255  1.3735255\n",
      "  1.37529695 1.37529695 1.37529695 1.37529695 1.37529695 1.37529695\n",
      "  1.37529695 1.37529695 1.37529695 1.37529695 1.37529695 1.37529695\n",
      "  1.37529695 1.37529695 1.37529695 1.37529695 1.37529695 1.37529695]\n",
      " [0.77670002 1.31883717 1.31883717 1.37512541 1.37512541 1.37512541\n",
      "  1.37512541 1.37512541 1.37512541 1.37512541 1.37512541 1.37512541\n",
      "  1.37512541 1.37512541 1.38370836 1.38370836 1.38370836 1.38370836\n",
      "  1.38370836 1.38370836 1.38370836 1.38370836 1.38370836 1.38370836\n",
      "  1.38370836 1.38370836 1.38370836 1.38370836 1.38370836 1.38370836]\n",
      " [1.30013275 1.34732807 1.34732807 1.34732807 1.34732807 1.34732807\n",
      "  1.34732807 1.34732807 1.34732807 1.34732807 1.34732807 1.37061155\n",
      "  1.37061155 1.37061155 1.3876611  1.3876611  1.3876611  1.3876611\n",
      "  1.3876611  1.3876611  1.3876611  1.3876611  1.3876611  1.3876611\n",
      "  1.3876611  1.3876611  1.3876611  1.3876611  1.3876611  1.3876611 ]\n",
      " [0.98956531 0.98956531 0.98956531 1.29194713 1.30338502 1.32278657\n",
      "  1.32278657 1.32278657 1.32278657 1.39505041 1.39505041 1.39505041\n",
      "  1.39505041 1.39505041 1.39505041 1.39505041 1.39505041 1.39505041\n",
      "  1.39505041 1.39505041 1.39505041 1.39505041 1.39505041 1.39505041\n",
      "  1.39505041 1.39505041 1.39543772 1.39543772 1.39543772 1.39543772]\n",
      " [1.33470142 1.33470142 1.33470142 1.33470142 1.38128507 1.38128507\n",
      "  1.38128507 1.38128507 1.38128507 1.38128507 1.38128507 1.38128507\n",
      "  1.38128507 1.38128507 1.38128507 1.38128507 1.38128507 1.38128507\n",
      "  1.39114881 1.39114881 1.39114881 1.39114881 1.39114881 1.39114881\n",
      "  1.39114881 1.39114881 1.39114881 1.39114881 1.39114881 1.39114881]\n",
      " [1.16677189 1.16677189 1.16677189 1.17993069 1.17993069 1.17993069\n",
      "  1.33622766 1.37663376 1.37663376 1.37663376 1.37663376 1.37663376\n",
      "  1.37663376 1.37663376 1.37663376 1.37663376 1.37663376 1.37663376\n",
      "  1.37663376 1.37663376 1.37663376 1.37663376 1.37663376 1.37663376\n",
      "  1.37663376 1.37663376 1.37946391 1.37946391 1.37946391 1.37946391]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\845368171.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results2 = Hartmannb.bayesian_optimization_experiment(\n",
    "    num_experiments=10,\n",
    "    n=25,\n",
    "    obj_fn1=predict_bi_function_xg,\n",
    "    obj_fn3=predict_bi_function_xg,\n",
    "    initial_points_task1=initial_points_task11,  # 传递生成的初始样本\n",
    "    initial_points_task2=initial_points_task22,  # 传递生成的初始样本\n",
    "    fit_task_fn=fit_gp_model_and_select_next_point2,\n",
    "    device='cuda',\n",
    "    task_type='single'  # 表示运行单任务模型\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13a1e163-485a-458b-abdd-b93d8ef24c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shiyanfangfa(dim_ranges, num_samples=5):\n",
    "    samples = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        point = []\n",
    "        for lower, upper in dim_ranges:\n",
    "            # 将区间四等分\n",
    "            step = (upper - lower) / 4\n",
    "            candidate_values = [lower + i * step for i in range(5)]  # 四等分包含端点\n",
    "            \n",
    "            # 随机选择一个候选值\n",
    "            selected_value = random.choice(candidate_values)\n",
    "            point.append(selected_value)\n",
    "        \n",
    "        samples.append(point)\n",
    "    \n",
    "    # 转换为 Tensor 格式\n",
    "    return torch.tensor(samples, dtype=torch.double)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c3f3713-6500-4a3f-9cd3-0cabcd08bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gp_model_and_select_next_point3(train_x, train_obj, device):\n",
    "        # 生成样本点\n",
    "    initial_samples_np = shiyanfangfa(dim_ranges, num_samples=1)\n",
    "    \n",
    "    # 转换为张量\n",
    "    initial_samples_tensor = torch.tensor(initial_samples_np, dtype=torch.float64)\n",
    "    return initial_samples_tensor.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9d2dba-d443-44e4-8284-0cc7b294dc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c9c4c54-e83d-4a4c-830b-15de4bb07fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "tensor([[ 600.0000,    0.0000,    0.0000,    0.0000,  375.0000,  800.0000,\n",
      "           55.0000,  120.0000,    0.0000,   20.0000],\n",
      "        [ 900.0000,   90.0000,  120.0000,   50.0000,  375.0000,    0.0000,\n",
      "           60.0000,   40.0000,  120.0000,   60.0000],\n",
      "        [1200.0000,   30.0000,   60.0000,   50.0000,  375.0000,  600.0000,\n",
      "           40.0000,  160.0000,  160.0000,    0.0000],\n",
      "        [ 300.0000,    0.0000,  120.0000,   37.5000,  375.0000,  400.0000,\n",
      "           40.0000,  120.0000,  160.0000,   20.0000],\n",
      "        [1200.0000,  120.0000,   30.0000,   37.5000,  375.0000,  400.0000,\n",
      "           40.0000,  160.0000,  120.0000,   40.0000]], dtype=torch.float64)\n",
      "\n",
      "Batch 2:\n",
      "tensor([[ 900.0000,   60.0000,    0.0000,   50.0000,  750.0000,    0.0000,\n",
      "           45.0000,    0.0000,   80.0000,   40.0000],\n",
      "        [   0.0000,   60.0000,    0.0000,   25.0000,    0.0000,  400.0000,\n",
      "           40.0000,   40.0000,    0.0000,   80.0000],\n",
      "        [ 900.0000,    0.0000,    0.0000,    0.0000,    0.0000,  400.0000,\n",
      "           55.0000,    0.0000,   40.0000,   20.0000],\n",
      "        [ 900.0000,  120.0000,  120.0000,   37.5000,  375.0000,  600.0000,\n",
      "           50.0000,  160.0000,    0.0000,   40.0000],\n",
      "        [   0.0000,   90.0000,   90.0000,    0.0000, 1500.0000,  400.0000,\n",
      "           60.0000,  160.0000,  120.0000,   40.0000]], dtype=torch.float64)\n",
      "\n",
      "Batch 3:\n",
      "tensor([[1200.0000,  120.0000,  120.0000,    0.0000, 1500.0000,  800.0000,\n",
      "           55.0000,    0.0000,    0.0000,    0.0000],\n",
      "        [ 600.0000,   30.0000,   30.0000,   37.5000, 1125.0000,  200.0000,\n",
      "           60.0000,  120.0000,   40.0000,    0.0000],\n",
      "        [1200.0000,   30.0000,   60.0000,   50.0000,  375.0000,  600.0000,\n",
      "           50.0000,    0.0000,  120.0000,   60.0000],\n",
      "        [ 300.0000,    0.0000,   90.0000,   37.5000, 1500.0000,  400.0000,\n",
      "           60.0000,    0.0000,   40.0000,    0.0000],\n",
      "        [1200.0000,   60.0000,   60.0000,    0.0000,    0.0000,  200.0000,\n",
      "           50.0000,   80.0000,  120.0000,   40.0000]], dtype=torch.float64)\n",
      "\n",
      "Batch 4:\n",
      "tensor([[   0.0000,    0.0000,    0.0000,   12.5000,  750.0000,  400.0000,\n",
      "           60.0000,   80.0000,  120.0000,   80.0000],\n",
      "        [   0.0000,   30.0000,   60.0000,   25.0000,  750.0000,  400.0000,\n",
      "           40.0000,   80.0000,    0.0000,   60.0000],\n",
      "        [ 300.0000,   30.0000,   60.0000,   25.0000,  375.0000,  800.0000,\n",
      "           40.0000,    0.0000,  120.0000,   20.0000],\n",
      "        [1200.0000,    0.0000,   90.0000,   12.5000,  375.0000,  800.0000,\n",
      "           60.0000,  120.0000,   40.0000,   20.0000],\n",
      "        [   0.0000,   90.0000,   60.0000,   37.5000,  375.0000,  600.0000,\n",
      "           40.0000,   80.0000,   80.0000,   80.0000]], dtype=torch.float64)\n",
      "\n",
      "Batch 5:\n",
      "tensor([[1200.0000,   90.0000,   30.0000,   25.0000, 1125.0000,  400.0000,\n",
      "           60.0000,    0.0000,    0.0000,   40.0000],\n",
      "        [   0.0000,   30.0000,   60.0000,   50.0000,    0.0000,  200.0000,\n",
      "           60.0000,   80.0000,   80.0000,   20.0000],\n",
      "        [   0.0000,    0.0000,  120.0000,   37.5000,  375.0000,    0.0000,\n",
      "           50.0000,  120.0000,  120.0000,   60.0000],\n",
      "        [ 300.0000,   90.0000,  120.0000,    0.0000,    0.0000,  800.0000,\n",
      "           50.0000,    0.0000,    0.0000,   20.0000],\n",
      "        [ 900.0000,   60.0000,    0.0000,   25.0000, 1500.0000,  800.0000,\n",
      "           60.0000,   80.0000,  120.0000,   20.0000]], dtype=torch.float64)\n",
      "\n",
      "Batch 6:\n",
      "tensor([[ 600.0000,  120.0000,   60.0000,   25.0000, 1125.0000,  200.0000,\n",
      "           60.0000,   80.0000,   80.0000,   60.0000],\n",
      "        [ 300.0000,   30.0000,    0.0000,   37.5000,    0.0000,  800.0000,\n",
      "           50.0000,  120.0000,   80.0000,   80.0000],\n",
      "        [   0.0000,  120.0000,  120.0000,   25.0000, 1500.0000,  200.0000,\n",
      "           50.0000,   40.0000,   80.0000,   60.0000],\n",
      "        [1200.0000,    0.0000,   30.0000,   25.0000,  375.0000,  400.0000,\n",
      "           60.0000,   40.0000,    0.0000,   20.0000],\n",
      "        [1200.0000,    0.0000,   30.0000,   25.0000,  750.0000,  200.0000,\n",
      "           50.0000,   40.0000,   40.0000,   40.0000]], dtype=torch.float64)\n",
      "\n",
      "Batch 7:\n",
      "tensor([[ 900.0000,   90.0000,  120.0000,   50.0000, 1500.0000,  200.0000,\n",
      "           55.0000,   40.0000,  120.0000,   40.0000],\n",
      "        [ 600.0000,   60.0000,  120.0000,   37.5000,  375.0000,  600.0000,\n",
      "           55.0000,    0.0000,  120.0000,   60.0000],\n",
      "        [ 600.0000,    0.0000,    0.0000,   12.5000, 1125.0000,  200.0000,\n",
      "           40.0000,   80.0000,    0.0000,   80.0000],\n",
      "        [   0.0000,   90.0000,    0.0000,   37.5000,  375.0000,  200.0000,\n",
      "           55.0000,  160.0000,   80.0000,   60.0000],\n",
      "        [ 900.0000,   90.0000,    0.0000,   37.5000,  375.0000,  600.0000,\n",
      "           50.0000,   80.0000,    0.0000,   40.0000]], dtype=torch.float64)\n",
      "\n",
      "Batch 8:\n",
      "tensor([[ 600.0000,  120.0000,    0.0000,   37.5000, 1500.0000,  800.0000,\n",
      "           55.0000,   80.0000,   80.0000,   40.0000],\n",
      "        [ 900.0000,   60.0000,   30.0000,   12.5000,  750.0000,  800.0000,\n",
      "           45.0000,    0.0000,   40.0000,   60.0000],\n",
      "        [ 900.0000,   30.0000,  120.0000,   50.0000, 1125.0000,  200.0000,\n",
      "           45.0000,  160.0000,  160.0000,    0.0000],\n",
      "        [ 300.0000,   30.0000,   30.0000,   50.0000,  750.0000,  600.0000,\n",
      "           50.0000,    0.0000,  160.0000,   40.0000],\n",
      "        [ 300.0000,   90.0000,   90.0000,   12.5000, 1500.0000,  600.0000,\n",
      "           45.0000,   80.0000,   80.0000,   80.0000]], dtype=torch.float64)\n",
      "\n",
      "Batch 9:\n",
      "tensor([[ 900.0000,   90.0000,   60.0000,   37.5000,  375.0000,    0.0000,\n",
      "           60.0000,  160.0000,  160.0000,   40.0000],\n",
      "        [ 900.0000,    0.0000,    0.0000,   50.0000, 1125.0000,  600.0000,\n",
      "           45.0000,  160.0000,  120.0000,   40.0000],\n",
      "        [ 900.0000,   90.0000,  120.0000,   37.5000,  750.0000,  800.0000,\n",
      "           50.0000,  160.0000,   40.0000,   80.0000],\n",
      "        [ 300.0000,  120.0000,   90.0000,   12.5000, 1125.0000,  800.0000,\n",
      "           60.0000,   80.0000,   40.0000,    0.0000],\n",
      "        [ 300.0000,   90.0000,  120.0000,    0.0000, 1500.0000,  800.0000,\n",
      "           50.0000,    0.0000,  120.0000,   80.0000]], dtype=torch.float64)\n",
      "\n",
      "Batch 10:\n",
      "tensor([[ 900.0000,   90.0000,   30.0000,   25.0000,    0.0000,    0.0000,\n",
      "           45.0000,  120.0000,  160.0000,   40.0000],\n",
      "        [   0.0000,   60.0000,    0.0000,    0.0000,  375.0000,  600.0000,\n",
      "           40.0000,   40.0000,    0.0000,   80.0000],\n",
      "        [ 300.0000,  120.0000,   60.0000,   12.5000,  750.0000,  800.0000,\n",
      "           55.0000,   80.0000,  160.0000,   80.0000],\n",
      "        [1200.0000,    0.0000,    0.0000,   25.0000,    0.0000,  600.0000,\n",
      "           50.0000,    0.0000,    0.0000,   60.0000],\n",
      "        [ 900.0000,  120.0000,   30.0000,   37.5000, 1125.0000,  600.0000,\n",
      "           55.0000,   80.0000,   40.0000,   40.0000]], dtype=torch.float64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_points_task33 = []\n",
    "for _ in range(10):\n",
    "    batch_samples = shiyanfangfa(dim_ranges, num_samples=5)\n",
    "    initial_points_task33.append(batch_samples)\n",
    "\n",
    "# 打印生成的样本\n",
    "for i, batch in enumerate(initial_points_task33):\n",
    "    print(f\"Batch {i + 1}:\\n{batch}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "215d7504-a3e9-406a-9c4b-64e9d805e371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 600.0000,    0.0000,    0.0000,    0.0000,  375.0000,  800.0000,\n",
       "            55.0000,  120.0000,    0.0000,   20.0000],\n",
       "         [ 900.0000,   90.0000,  120.0000,   50.0000,  375.0000,    0.0000,\n",
       "            60.0000,   40.0000,  120.0000,   60.0000],\n",
       "         [1200.0000,   30.0000,   60.0000,   50.0000,  375.0000,  600.0000,\n",
       "            40.0000,  160.0000,  160.0000,    0.0000],\n",
       "         [ 300.0000,    0.0000,  120.0000,   37.5000,  375.0000,  400.0000,\n",
       "            40.0000,  120.0000,  160.0000,   20.0000],\n",
       "         [1200.0000,  120.0000,   30.0000,   37.5000,  375.0000,  400.0000,\n",
       "            40.0000,  160.0000,  120.0000,   40.0000]], dtype=torch.float64),\n",
       " tensor([[ 900.0000,   60.0000,    0.0000,   50.0000,  750.0000,    0.0000,\n",
       "            45.0000,    0.0000,   80.0000,   40.0000],\n",
       "         [   0.0000,   60.0000,    0.0000,   25.0000,    0.0000,  400.0000,\n",
       "            40.0000,   40.0000,    0.0000,   80.0000],\n",
       "         [ 900.0000,    0.0000,    0.0000,    0.0000,    0.0000,  400.0000,\n",
       "            55.0000,    0.0000,   40.0000,   20.0000],\n",
       "         [ 900.0000,  120.0000,  120.0000,   37.5000,  375.0000,  600.0000,\n",
       "            50.0000,  160.0000,    0.0000,   40.0000],\n",
       "         [   0.0000,   90.0000,   90.0000,    0.0000, 1500.0000,  400.0000,\n",
       "            60.0000,  160.0000,  120.0000,   40.0000]], dtype=torch.float64),\n",
       " tensor([[1200.0000,  120.0000,  120.0000,    0.0000, 1500.0000,  800.0000,\n",
       "            55.0000,    0.0000,    0.0000,    0.0000],\n",
       "         [ 600.0000,   30.0000,   30.0000,   37.5000, 1125.0000,  200.0000,\n",
       "            60.0000,  120.0000,   40.0000,    0.0000],\n",
       "         [1200.0000,   30.0000,   60.0000,   50.0000,  375.0000,  600.0000,\n",
       "            50.0000,    0.0000,  120.0000,   60.0000],\n",
       "         [ 300.0000,    0.0000,   90.0000,   37.5000, 1500.0000,  400.0000,\n",
       "            60.0000,    0.0000,   40.0000,    0.0000],\n",
       "         [1200.0000,   60.0000,   60.0000,    0.0000,    0.0000,  200.0000,\n",
       "            50.0000,   80.0000,  120.0000,   40.0000]], dtype=torch.float64),\n",
       " tensor([[   0.0000,    0.0000,    0.0000,   12.5000,  750.0000,  400.0000,\n",
       "            60.0000,   80.0000,  120.0000,   80.0000],\n",
       "         [   0.0000,   30.0000,   60.0000,   25.0000,  750.0000,  400.0000,\n",
       "            40.0000,   80.0000,    0.0000,   60.0000],\n",
       "         [ 300.0000,   30.0000,   60.0000,   25.0000,  375.0000,  800.0000,\n",
       "            40.0000,    0.0000,  120.0000,   20.0000],\n",
       "         [1200.0000,    0.0000,   90.0000,   12.5000,  375.0000,  800.0000,\n",
       "            60.0000,  120.0000,   40.0000,   20.0000],\n",
       "         [   0.0000,   90.0000,   60.0000,   37.5000,  375.0000,  600.0000,\n",
       "            40.0000,   80.0000,   80.0000,   80.0000]], dtype=torch.float64),\n",
       " tensor([[1200.0000,   90.0000,   30.0000,   25.0000, 1125.0000,  400.0000,\n",
       "            60.0000,    0.0000,    0.0000,   40.0000],\n",
       "         [   0.0000,   30.0000,   60.0000,   50.0000,    0.0000,  200.0000,\n",
       "            60.0000,   80.0000,   80.0000,   20.0000],\n",
       "         [   0.0000,    0.0000,  120.0000,   37.5000,  375.0000,    0.0000,\n",
       "            50.0000,  120.0000,  120.0000,   60.0000],\n",
       "         [ 300.0000,   90.0000,  120.0000,    0.0000,    0.0000,  800.0000,\n",
       "            50.0000,    0.0000,    0.0000,   20.0000],\n",
       "         [ 900.0000,   60.0000,    0.0000,   25.0000, 1500.0000,  800.0000,\n",
       "            60.0000,   80.0000,  120.0000,   20.0000]], dtype=torch.float64),\n",
       " tensor([[ 600.0000,  120.0000,   60.0000,   25.0000, 1125.0000,  200.0000,\n",
       "            60.0000,   80.0000,   80.0000,   60.0000],\n",
       "         [ 300.0000,   30.0000,    0.0000,   37.5000,    0.0000,  800.0000,\n",
       "            50.0000,  120.0000,   80.0000,   80.0000],\n",
       "         [   0.0000,  120.0000,  120.0000,   25.0000, 1500.0000,  200.0000,\n",
       "            50.0000,   40.0000,   80.0000,   60.0000],\n",
       "         [1200.0000,    0.0000,   30.0000,   25.0000,  375.0000,  400.0000,\n",
       "            60.0000,   40.0000,    0.0000,   20.0000],\n",
       "         [1200.0000,    0.0000,   30.0000,   25.0000,  750.0000,  200.0000,\n",
       "            50.0000,   40.0000,   40.0000,   40.0000]], dtype=torch.float64),\n",
       " tensor([[ 900.0000,   90.0000,  120.0000,   50.0000, 1500.0000,  200.0000,\n",
       "            55.0000,   40.0000,  120.0000,   40.0000],\n",
       "         [ 600.0000,   60.0000,  120.0000,   37.5000,  375.0000,  600.0000,\n",
       "            55.0000,    0.0000,  120.0000,   60.0000],\n",
       "         [ 600.0000,    0.0000,    0.0000,   12.5000, 1125.0000,  200.0000,\n",
       "            40.0000,   80.0000,    0.0000,   80.0000],\n",
       "         [   0.0000,   90.0000,    0.0000,   37.5000,  375.0000,  200.0000,\n",
       "            55.0000,  160.0000,   80.0000,   60.0000],\n",
       "         [ 900.0000,   90.0000,    0.0000,   37.5000,  375.0000,  600.0000,\n",
       "            50.0000,   80.0000,    0.0000,   40.0000]], dtype=torch.float64),\n",
       " tensor([[ 600.0000,  120.0000,    0.0000,   37.5000, 1500.0000,  800.0000,\n",
       "            55.0000,   80.0000,   80.0000,   40.0000],\n",
       "         [ 900.0000,   60.0000,   30.0000,   12.5000,  750.0000,  800.0000,\n",
       "            45.0000,    0.0000,   40.0000,   60.0000],\n",
       "         [ 900.0000,   30.0000,  120.0000,   50.0000, 1125.0000,  200.0000,\n",
       "            45.0000,  160.0000,  160.0000,    0.0000],\n",
       "         [ 300.0000,   30.0000,   30.0000,   50.0000,  750.0000,  600.0000,\n",
       "            50.0000,    0.0000,  160.0000,   40.0000],\n",
       "         [ 300.0000,   90.0000,   90.0000,   12.5000, 1500.0000,  600.0000,\n",
       "            45.0000,   80.0000,   80.0000,   80.0000]], dtype=torch.float64),\n",
       " tensor([[ 900.0000,   90.0000,   60.0000,   37.5000,  375.0000,    0.0000,\n",
       "            60.0000,  160.0000,  160.0000,   40.0000],\n",
       "         [ 900.0000,    0.0000,    0.0000,   50.0000, 1125.0000,  600.0000,\n",
       "            45.0000,  160.0000,  120.0000,   40.0000],\n",
       "         [ 900.0000,   90.0000,  120.0000,   37.5000,  750.0000,  800.0000,\n",
       "            50.0000,  160.0000,   40.0000,   80.0000],\n",
       "         [ 300.0000,  120.0000,   90.0000,   12.5000, 1125.0000,  800.0000,\n",
       "            60.0000,   80.0000,   40.0000,    0.0000],\n",
       "         [ 300.0000,   90.0000,  120.0000,    0.0000, 1500.0000,  800.0000,\n",
       "            50.0000,    0.0000,  120.0000,   80.0000]], dtype=torch.float64),\n",
       " tensor([[ 900.0000,   90.0000,   30.0000,   25.0000,    0.0000,    0.0000,\n",
       "            45.0000,  120.0000,  160.0000,   40.0000],\n",
       "         [   0.0000,   60.0000,    0.0000,    0.0000,  375.0000,  600.0000,\n",
       "            40.0000,   40.0000,    0.0000,   80.0000],\n",
       "         [ 300.0000,  120.0000,   60.0000,   12.5000,  750.0000,  800.0000,\n",
       "            55.0000,   80.0000,  160.0000,   80.0000],\n",
       "         [1200.0000,    0.0000,    0.0000,   25.0000,    0.0000,  600.0000,\n",
       "            50.0000,    0.0000,    0.0000,   60.0000],\n",
       "         [ 900.0000,  120.0000,   30.0000,   37.5000, 1125.0000,  600.0000,\n",
       "            55.0000,   80.0000,   40.0000,   40.0000]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_points_task33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b6ccff-d7b1-4f3f-b16c-ac5dd33e4b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09ba2a15-9a30-4114-a6cf-7146738114e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 600.0000,    0.0000,    0.0000,    0.0000,  375.0000,  800.0000,\n",
      "           55.0000,  120.0000,    0.0000,   20.0000],\n",
      "        [ 900.0000,   90.0000,  120.0000,   50.0000,  375.0000,    0.0000,\n",
      "           60.0000,   40.0000,  120.0000,   60.0000],\n",
      "        [1200.0000,   30.0000,   60.0000,   50.0000,  375.0000,  600.0000,\n",
      "           40.0000,  160.0000,  160.0000,    0.0000],\n",
      "        [ 300.0000,    0.0000,  120.0000,   37.5000,  375.0000,  400.0000,\n",
      "           40.0000,  120.0000,  160.0000,   20.0000],\n",
      "        [1200.0000,  120.0000,   30.0000,   37.5000,  375.0000,  400.0000,\n",
      "           40.0000,  160.0000,  120.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 300.,   30.,   60.,   25., 1500.,  400.,   40.,  120.,  120.,   60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.00 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[300.,  30.,   0.,  50., 375.,   0.,  40.,  40., 160.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.02 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[1200.,   90.,   90.,   25.,    0.,  800.,   40.,  120.,  160.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.02 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[600.,  30.,  60.,  25., 750.,   0.,  45.,  40., 160.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[ 300.0000,   30.0000,   90.0000,   37.5000, 1500.0000,  400.0000,\n",
      "           40.0000,  160.0000,   40.0000,   20.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 4 took 0.01 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[1200.0000,   30.0000,    0.0000,   37.5000,  375.0000,    0.0000,\n",
      "           45.0000,   80.0000,    0.0000,   60.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 0.02 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[  0.,   0.,  30.,  25., 750., 800.,  55.,   0., 120.,  20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.00 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[1200.,   30.,  120.,    0.,  750.,  800.,   50.,   40.,   40.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.02 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[1200.0000,  120.0000,    0.0000,   12.5000,    0.0000,    0.0000,\n",
      "           60.0000,    0.0000,  120.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 0.00 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[900.,  30.,  30.,  25., 375.,   0.,  55.,   0., 120.,   0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.01 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[ 600.0000,    0.0000,   90.0000,   37.5000, 1125.0000,  200.0000,\n",
      "           45.0000,    0.0000,    0.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 0.02 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[ 900.,   90.,   90.,    0., 1500.,  200.,   50.,   40.,  160.,    0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.00 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[ 600.,  120.,   30.,    0., 1500.,  600.,   45.,   80.,   80.,   80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.01 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[ 900.0000,  120.0000,    0.0000,   37.5000, 1500.0000,  200.0000,\n",
      "           50.0000,   40.0000,   40.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 0.02 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[ 300.,    0.,   30.,   25., 1500.,    0.,   50.,   80.,  120.,   20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[ 300.0000,   90.0000,    0.0000,   37.5000, 1125.0000,    0.0000,\n",
      "           60.0000,   40.0000,   80.0000,   60.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 0.00 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[1200.,   30.,    0.,   50.,  750.,    0.,   40.,  120.,  160.,    0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 0.01 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[600.0000, 120.0000,  30.0000,  37.5000,   0.0000,   0.0000,  55.0000,\n",
      "          40.0000,  40.0000,   0.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.02 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[1200.,   90.,    0.,   50., 1125.,    0.,   60.,    0.,   80.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.00 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[ 900.0000,   30.0000,   90.0000,   37.5000, 1500.0000,  600.0000,\n",
      "           45.0000,  160.0000,   80.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[ 600.0000,   60.0000,   60.0000,   12.5000, 1500.0000,  600.0000,\n",
      "           40.0000,   80.0000,    0.0000,   60.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 0.01 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[1200.0000,  120.0000,   60.0000,   37.5000,  375.0000,  600.0000,\n",
      "           50.0000,  160.0000,    0.0000,   60.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 0.00 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[  0.0000,  30.0000,  90.0000,  12.5000, 750.0000, 200.0000,  45.0000,\n",
      "         160.0000, 160.0000,  60.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.02 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[ 600.,   30.,   60.,   50., 1125.,  800.,   40.,  120.,  160.,   60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.00 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[ 300.0000,   90.0000,   30.0000,   37.5000, 1500.0000,    0.0000,\n",
      "           45.0000,    0.0000,  120.0000,    0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 24 took 0.01 seconds\n",
      "最优点: [1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428]\n",
      "tensor([[ 900.0000,   60.0000,    0.0000,   50.0000,  750.0000,    0.0000,\n",
      "           45.0000,    0.0000,   80.0000,   40.0000],\n",
      "        [   0.0000,   60.0000,    0.0000,   25.0000,    0.0000,  400.0000,\n",
      "           40.0000,   40.0000,    0.0000,   80.0000],\n",
      "        [ 900.0000,    0.0000,    0.0000,    0.0000,    0.0000,  400.0000,\n",
      "           55.0000,    0.0000,   40.0000,   20.0000],\n",
      "        [ 900.0000,  120.0000,  120.0000,   37.5000,  375.0000,  600.0000,\n",
      "           50.0000,  160.0000,    0.0000,   40.0000],\n",
      "        [   0.0000,   90.0000,   90.0000,    0.0000, 1500.0000,  400.0000,\n",
      "           60.0000,  160.0000,  120.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 300.,   30.,   30.,    0., 1125.,    0.,   55.,   80.,   80.,   20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.01 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[1200.,   90.,   30.,    0., 1125.,  600.,   40.,   80.,  120.,   80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.00 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[900.0000,   0.0000,  30.0000,  37.5000,   0.0000, 200.0000,  60.0000,\n",
      "           0.0000, 160.0000,   0.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.02 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[900.,   0.,  30.,   0., 750.,   0.,  45., 120., 120.,   0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[ 600.0000,  120.0000,   60.0000,   37.5000, 1500.0000,  200.0000,\n",
      "           60.0000,   40.0000,   80.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 4 took 0.02 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[600.0000, 120.0000,   0.0000,  12.5000, 750.0000,   0.0000,  60.0000,\n",
      "         120.0000,  80.0000,  40.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.01 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[900., 120.,  60.,   0., 750., 200.,  60., 160.,   0.,  20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.02 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[900.,  30., 120.,   0., 750.,   0.,  50.,  40.,   0.,  40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.00 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[900.,  90.,  60.,  50., 375., 600.,  50.,  80.,  40.,  20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.01 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[  0.0000,  60.0000,  90.0000,  37.5000,   0.0000, 600.0000,  60.0000,\n",
      "         120.0000, 160.0000,  80.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.00 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[  0.0000,  60.0000,  90.0000,  12.5000,   0.0000, 600.0000,  50.0000,\n",
      "         120.0000,  80.0000,  80.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.02 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[ 900.0000,   60.0000,  120.0000,   12.5000, 1500.0000,    0.0000,\n",
      "           45.0000,  120.0000,   40.0000,   60.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 0.02 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[ 600.0000,  120.0000,  120.0000,   12.5000, 1125.0000,  800.0000,\n",
      "           60.0000,  160.0000,  160.0000,    0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 0.00 seconds\n",
      "Nr. of optimization run: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New candidates are: tensor([[ 600.,   90.,  120.,   50., 1125.,    0.,   40.,   40.,  120.,   60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 0.01 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[ 600.,   60.,   90.,    0., 1500.,  200.,   55.,   40.,    0.,   80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[1200.0000,   30.0000,   60.0000,   12.5000,  750.0000,  600.0000,\n",
      "           40.0000,  160.0000,  160.0000,   20.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 0.02 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[ 900.0000,   90.0000,   60.0000,   37.5000, 1500.0000,    0.0000,\n",
      "           40.0000,  160.0000,   40.0000,    0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.00 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[ 900.0000,  120.0000,    0.0000,   12.5000, 1500.0000,  600.0000,\n",
      "           45.0000,   40.0000,    0.0000,   20.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 0.01 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[300.0000,  60.0000, 120.0000,  37.5000, 750.0000, 400.0000,  40.0000,\n",
      "         160.0000,  40.0000,  20.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.00 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[1200.0000,  120.0000,  120.0000,   12.5000,    0.0000,  400.0000,\n",
      "           55.0000,   40.0000,    0.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[300., 120.,  60.,  50., 750., 800.,  45., 120.,   0.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.01 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[600.,   0.,  90.,  50.,   0., 200.,  60.,  40.,   0.,  40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.02 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[  0.0000,  30.0000,  30.0000,  12.5000, 375.0000,   0.0000,  60.0000,\n",
      "         160.0000,   0.0000,  80.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.00 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[300.0000,   0.0000, 120.0000,  12.5000, 375.0000, 200.0000,  50.0000,\n",
      "           0.0000, 120.0000,   0.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.02 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[900.,  90.,  30.,   0., 375., 400.,  50.,   0.,   0.,  60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.00 seconds\n",
      "最优点: [0.43853989243507385, 0.9590399265289307, 1.3403159379959106, 1.3403159379959106, 1.3403159379959106, 1.3403159379959106, 1.3403159379959106, 1.3403159379959106, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649]\n",
      "tensor([[1200.0000,  120.0000,  120.0000,    0.0000, 1500.0000,  800.0000,\n",
      "           55.0000,    0.0000,    0.0000,    0.0000],\n",
      "        [ 600.0000,   30.0000,   30.0000,   37.5000, 1125.0000,  200.0000,\n",
      "           60.0000,  120.0000,   40.0000,    0.0000],\n",
      "        [1200.0000,   30.0000,   60.0000,   50.0000,  375.0000,  600.0000,\n",
      "           50.0000,    0.0000,  120.0000,   60.0000],\n",
      "        [ 300.0000,    0.0000,   90.0000,   37.5000, 1500.0000,  400.0000,\n",
      "           60.0000,    0.0000,   40.0000,    0.0000],\n",
      "        [1200.0000,   60.0000,   60.0000,    0.0000,    0.0000,  200.0000,\n",
      "           50.0000,   80.0000,  120.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[   0.,  120.,   60.,   50., 1500.,  600.,   60.,    0.,   40.,   80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.00 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[  0.0000,   0.0000,  30.0000,  12.5000, 750.0000, 800.0000,  55.0000,\n",
      "         160.0000, 120.0000,  40.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.02 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[600.,   0.,  30.,  25., 750., 200.,  50., 120., 120.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.01 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[600.0000, 120.0000,  90.0000,  37.5000, 750.0000, 200.0000,  60.0000,\n",
      "         120.0000, 120.0000,  20.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[1200.0000,  120.0000,  120.0000,   37.5000,    0.0000,  800.0000,\n",
      "           55.0000,   80.0000,   80.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 4 took 0.02 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[   0.0000,  120.0000,    0.0000,   37.5000, 1125.0000,  400.0000,\n",
      "           60.0000,    0.0000,  120.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 0.00 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[ 300.0000,   60.0000,    0.0000,   37.5000, 1125.0000,    0.0000,\n",
      "           60.0000,    0.0000,  120.0000,   60.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 0.01 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[  0.,  60., 120.,  50.,   0., 400.,  40.,   0., 120.,  20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[1200.0000,   90.0000,   90.0000,   12.5000,  750.0000,  600.0000,\n",
      "           60.0000,   40.0000,  160.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 0.00 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[   0.0000,   60.0000,   60.0000,   12.5000, 1125.0000,  200.0000,\n",
      "           50.0000,    0.0000,  120.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 9 took 0.02 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[900.0000,  60.0000,  60.0000,  37.5000, 750.0000, 400.0000,  60.0000,\n",
      "          80.0000, 160.0000,  40.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.00 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[   0.,   30.,  120.,    0., 1500.,    0.,   55.,   80.,    0.,    0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.01 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[600.,  90.,  30.,   0., 375., 800.,  55., 120., 160.,  60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.02 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[ 300.,   90.,    0.,   25., 1500.,  400.,   40.,  120.,  120.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 0.00 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[ 600.,    0.,    0.,   25., 1125.,  600.,   40.,    0.,  120.,    0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[1200.0000,   90.0000,   60.0000,   12.5000,  750.0000,    0.0000,\n",
      "           40.0000,   80.0000,   40.0000,   20.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 0.01 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[1200.0000,    0.0000,    0.0000,   37.5000,  375.0000,  600.0000,\n",
      "           60.0000,    0.0000,   40.0000,   20.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.00 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[900.0000,   0.0000,  30.0000,  12.5000,   0.0000, 600.0000,  50.0000,\n",
      "          40.0000, 160.0000,  20.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.02 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[1200.0000,   60.0000,   60.0000,   37.5000,    0.0000,  200.0000,\n",
      "           60.0000,   40.0000,  160.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 0.01 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[1200.,   30.,    0.,    0.,  375.,  600.,   40.,    0.,  120.,   60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.00 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[900.,   0.,  30.,   0., 750., 200.,  60.,  40., 120.,  60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.02 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[ 600.,    0.,   90.,   25., 1500.,  200.,   50.,  120.,  160.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.02 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[ 300.,    0.,   60.,   25., 1500.,  200.,   45.,  160.,  120.,    0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.01 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[ 900.0000,   30.0000,   60.0000,   12.5000, 1500.0000,  200.0000,\n",
      "           50.0000,    0.0000,  160.0000,   60.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 0.00 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[   0.,  120.,  120.,   50., 1125.,  800.,   55.,    0.,  160.,    0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.02 seconds\n",
      "最优点: [1.3227059841156006, 1.3227059841156006, 1.3227059841156006, 1.3227059841156006, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3383337259292603, 1.3383337259292603, 1.3383337259292603, 1.3383337259292603, 1.3383337259292603, 1.3383337259292603, 1.3383337259292603, 1.3383337259292603, 1.3670228719711304, 1.3670228719711304, 1.3670228719711304, 1.3670228719711304]\n",
      "tensor([[   0.0000,    0.0000,    0.0000,   12.5000,  750.0000,  400.0000,\n",
      "           60.0000,   80.0000,  120.0000,   80.0000],\n",
      "        [   0.0000,   30.0000,   60.0000,   25.0000,  750.0000,  400.0000,\n",
      "           40.0000,   80.0000,    0.0000,   60.0000],\n",
      "        [ 300.0000,   30.0000,   60.0000,   25.0000,  375.0000,  800.0000,\n",
      "           40.0000,    0.0000,  120.0000,   20.0000],\n",
      "        [1200.0000,    0.0000,   90.0000,   12.5000,  375.0000,  800.0000,\n",
      "           60.0000,  120.0000,   40.0000,   20.0000],\n",
      "        [   0.0000,   90.0000,   60.0000,   37.5000,  375.0000,  600.0000,\n",
      "           40.0000,   80.0000,   80.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[  0.,  60., 120.,  50., 375., 200.,  45.,  40.,  40.,   0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.01 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[ 600.,  120.,   60.,   50., 1500.,    0.,   45.,    0.,  160.,    0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.00 seconds\n",
      "Nr. of optimization run: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New candidates are: tensor([[ 300.,   60.,   90.,    0., 1125.,  400.,   50.,  160.,  120.,   80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.02 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[ 900.,   90.,   30.,   50., 1500.,  200.,   55.,  160.,   40.,   20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[600.,  30.,  90.,   0.,   0., 800.,  40.,   0.,  40.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.01 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[600.0000, 120.0000,  60.0000,  12.5000, 750.0000, 200.0000,  60.0000,\n",
      "         160.0000,   0.0000,  80.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.02 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[ 900.,   90.,   30.,    0., 1125.,  200.,   40.,   40.,  120.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.00 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[  0.,   0.,  60.,   0.,   0., 600.,  45.,  80., 120.,   0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.02 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[300.,  30.,  90.,  25., 750.,   0.,  55.,  40., 160.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.00 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[300., 120.,  30.,  25., 375., 800.,  60., 160.,  40.,  40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.01 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[1200.,    0.,   90.,   50., 1125.,  400.,   60.,   80.,    0.,    0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.02 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[600.,  90.,  30.,  25.,   0., 400.,  45.,  40.,   0.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.00 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[  0.,  60.,  60.,  25.,   0., 200.,  55.,  80.,   0.,  20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.02 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[300.,  30.,  60.,  25.,   0., 800.,  60.,  80., 160.,  60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 0.01 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[600.,  90.,  60.,   0., 375., 800.,  50., 160.,  40.,  40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[  0.0000, 120.0000,  60.0000,  12.5000, 750.0000, 200.0000,  60.0000,\n",
      "         160.0000, 160.0000,  40.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.00 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[300.0000,  30.0000,  60.0000,  37.5000,   0.0000, 600.0000,  55.0000,\n",
      "          80.0000, 120.0000,  80.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 0.01 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[   0.0000,   60.0000,   60.0000,   12.5000, 1125.0000,  800.0000,\n",
      "           55.0000,    0.0000,  120.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 0.02 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[   0.,  120.,   60.,    0., 1125.,  600.,   60.,  160.,    0.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.00 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[300.0000, 120.0000,  60.0000,  12.5000, 750.0000, 800.0000,  45.0000,\n",
      "          80.0000,  40.0000,  80.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[  0., 120.,  30.,  50.,   0., 600.,  50., 160., 160.,  40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.00 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[900.,  90.,   0.,   0., 375., 200.,  45., 160., 120.,  20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.01 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[  0.0000,  60.0000, 120.0000,  37.5000, 750.0000,   0.0000,  45.0000,\n",
      "          40.0000, 120.0000,   0.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.02 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[600.,  90.,  60.,   0.,   0., 200.,  55.,   0.,  40.,  40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[1200.,   30.,   90.,   25.,  750.,  400.,   60.,  120.,   40.,   80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.02 seconds\n",
      "最优点: [0.9867502450942993, 0.9867502450942993, 1.2765836715698242, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965]\n",
      "tensor([[1200.0000,   90.0000,   30.0000,   25.0000, 1125.0000,  400.0000,\n",
      "           60.0000,    0.0000,    0.0000,   40.0000],\n",
      "        [   0.0000,   30.0000,   60.0000,   50.0000,    0.0000,  200.0000,\n",
      "           60.0000,   80.0000,   80.0000,   20.0000],\n",
      "        [   0.0000,    0.0000,  120.0000,   37.5000,  375.0000,    0.0000,\n",
      "           50.0000,  120.0000,  120.0000,   60.0000],\n",
      "        [ 300.0000,   90.0000,  120.0000,    0.0000,    0.0000,  800.0000,\n",
      "           50.0000,    0.0000,    0.0000,   20.0000],\n",
      "        [ 900.0000,   60.0000,    0.0000,   25.0000, 1500.0000,  800.0000,\n",
      "           60.0000,   80.0000,  120.0000,   20.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[600.,  60.,  60.,  50., 750., 600.,  50.,  80., 160.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.00 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[ 900.0000,  120.0000,   90.0000,   37.5000, 1500.0000,  400.0000,\n",
      "           40.0000,  160.0000,   40.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 0.01 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[  0.,   0.,  30.,   0., 375., 200.,  45.,  80.,   0.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.00 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[900.,  60.,   0.,  25., 375., 600.,  40.,  40., 120.,   0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.02 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[900.,   0.,  60.,  25., 375., 600.,  50., 160., 160.,  40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.02 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[1200.0000,  120.0000,   90.0000,   12.5000, 1500.0000,    0.0000,\n",
      "           55.0000,  120.0000,   80.0000,    0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 0.00 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[600., 120.,   0.,  25., 375., 200.,  40.,  40., 120.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.01 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[900.0000,   0.0000,  30.0000,  12.5000, 375.0000, 200.0000,  50.0000,\n",
      "         120.0000,  40.0000,  20.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.00 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[  0.,   0.,  90.,  50., 750., 600.,  55., 160.,  40.,   0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.02 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[   0.,   90.,   30.,   25., 1500.,  400.,   50.,  120.,  120.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.02 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[ 300.,   30.,  120.,   50., 1125.,  600.,   50.,  160.,  160.,   60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.01 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[1200.,   30.,  120.,   25.,    0.,  200.,   60.,   40.,  160.,   60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.02 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[ 600.,   60.,   60.,    0., 1500.,    0.,   60.,  120.,   40.,   80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.00 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[300.0000,  60.0000,  60.0000,  37.5000,   0.0000, 400.0000,  40.0000,\n",
      "           0.0000,  80.0000,  80.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 0.01 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[  0.0000,  30.0000,  60.0000,  37.5000, 750.0000, 200.0000,  50.0000,\n",
      "           0.0000, 120.0000,  60.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[600.0000,  60.0000,  60.0000,  12.5000, 750.0000,   0.0000,  50.0000,\n",
      "          80.0000,  80.0000,  80.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.00 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[   0.,   60.,  120.,   25., 1500.,  400.,   45.,   40.,  160.,   80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 0.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[ 300.0000,  120.0000,    0.0000,   12.5000, 1125.0000,  600.0000,\n",
      "           40.0000,   80.0000,   40.0000,   20.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 0.01 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[1200.0000,   60.0000,   30.0000,   12.5000, 1125.0000,    0.0000,\n",
      "           50.0000,  160.0000,   80.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 0.00 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[1200.0000,   30.0000,   30.0000,   12.5000,    0.0000,  600.0000,\n",
      "           60.0000,    0.0000,   40.0000,    0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[ 900.,   30.,    0.,    0., 1500.,  200.,   60.,   40.,    0.,   60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.02 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[1200.0000,   30.0000,   60.0000,   12.5000,  375.0000,  600.0000,\n",
      "           60.0000,   40.0000,   80.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 0.01 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[1200.,  120.,  120.,   50.,  750.,  600.,   60.,   80.,  120.,   20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.00 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[1200.,   90.,    0.,   50.,  375.,  200.,   55.,  120.,   80.,   20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.02 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[ 900.,    0.,   30.,   50., 1125.,  200.,   60.,  120.,   80.,   20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.01 seconds\n",
      "最优点: [1.319503903388977, 1.319503903388977, 1.319503903388977, 1.319503903388977, 1.3229302167892456, 1.3229302167892456, 1.3229302167892456, 1.3229302167892456, 1.3229302167892456, 1.3229302167892456, 1.3643288612365723, 1.3643288612365723, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063]\n",
      "tensor([[ 600.0000,  120.0000,   60.0000,   25.0000, 1125.0000,  200.0000,\n",
      "           60.0000,   80.0000,   80.0000,   60.0000],\n",
      "        [ 300.0000,   30.0000,    0.0000,   37.5000,    0.0000,  800.0000,\n",
      "           50.0000,  120.0000,   80.0000,   80.0000],\n",
      "        [   0.0000,  120.0000,  120.0000,   25.0000, 1500.0000,  200.0000,\n",
      "           50.0000,   40.0000,   80.0000,   60.0000],\n",
      "        [1200.0000,    0.0000,   30.0000,   25.0000,  375.0000,  400.0000,\n",
      "           60.0000,   40.0000,    0.0000,   20.0000],\n",
      "        [1200.0000,    0.0000,   30.0000,   25.0000,  750.0000,  200.0000,\n",
      "           50.0000,   40.0000,   40.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 600.,   90.,   60.,    0., 1125.,  200.,   55.,  160.,  160.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.02 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[600.,  30.,  60.,  50.,   0., 200.,  55., 160.,  40.,  60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.00 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[  0.0000, 120.0000,  30.0000,  37.5000, 750.0000, 400.0000,  50.0000,\n",
      "         160.0000, 160.0000,   0.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.01 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[600.,  30., 120.,  25.,   0., 200.,  60.,  40., 160.,  40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.02 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[ 600.,  120.,   30.,   25., 1500.,  400.,   50.,   80.,  160.,   80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.00 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[600.,  90.,  30.,  50., 750., 400.,  40., 160.,  40.,  40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.02 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[900.,  30.,  60.,  50., 750., 800.,  45., 120., 160.,  60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.01 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[ 300.,   60.,    0.,    0., 1500.,    0.,   50.,  120.,    0.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.00 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[ 900.0000,  120.0000,  120.0000,   37.5000, 1500.0000,  600.0000,\n",
      "           45.0000,  160.0000,  120.0000,   20.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 0.02 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[300., 120.,  90.,  25.,   0., 800.,  50.,   0.,   0.,  60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.01 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[1200.,   30.,    0.,   50.,  750.,  800.,   45.,   40.,   40.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[  0., 120.,   0.,  25., 375., 400.,  40.,  80., 160.,  20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.02 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[ 600.,   90.,  120.,    0., 1500.,  400.,   50.,   40.,  160.,    0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.02 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[1200.0000,   60.0000,    0.0000,   12.5000,  750.0000,    0.0000,\n",
      "           50.0000,  160.0000,   80.0000,   20.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 0.01 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[  0.,  60., 120.,   0.,   0.,   0.,  60.,   0.,  80.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.00 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[   0.,   30.,   30.,   50., 1500.,  800.,   45.,   40.,  120.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.02 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[ 900.0000,   30.0000,   90.0000,   12.5000, 1125.0000,    0.0000,\n",
      "           50.0000,    0.0000,    0.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.00 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[  0.,  60., 120.,  50., 375., 600.,  40., 160., 160.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.02 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[  0.0000,   0.0000, 120.0000,  37.5000, 750.0000, 800.0000,  55.0000,\n",
      "         120.0000,  40.0000,  80.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.00 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[600.,  30.,  90.,  25., 375., 600.,  55.,  80., 120.,   0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.01 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[ 900.,   30.,  120.,    0., 1125.,  800.,   55.,   40.,   80.,    0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.02 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[   0.,   90.,   30.,    0., 1500.,  200.,   50.,  120.,    0.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.00 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[   0.0000,    0.0000,   90.0000,   37.5000, 1500.0000,  600.0000,\n",
      "           45.0000,  120.0000,    0.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 22 took 0.01 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[  0.,  60.,  60.,   0.,   0.,   0.,  60.,  80., 120.,   0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.00 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[900.0000,  60.0000,  30.0000,  37.5000, 375.0000, 200.0000,  55.0000,\n",
      "         160.0000, 160.0000,  80.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.02 seconds\n",
      "最优点: [0.9847676157951355, 1.1715800762176514, 1.1715800762176514, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.360791802406311, 1.360791802406311, 1.360791802406311, 1.360791802406311]\n",
      "tensor([[ 900.0000,   90.0000,  120.0000,   50.0000, 1500.0000,  200.0000,\n",
      "           55.0000,   40.0000,  120.0000,   40.0000],\n",
      "        [ 600.0000,   60.0000,  120.0000,   37.5000,  375.0000,  600.0000,\n",
      "           55.0000,    0.0000,  120.0000,   60.0000],\n",
      "        [ 600.0000,    0.0000,    0.0000,   12.5000, 1125.0000,  200.0000,\n",
      "           40.0000,   80.0000,    0.0000,   80.0000],\n",
      "        [   0.0000,   90.0000,    0.0000,   37.5000,  375.0000,  200.0000,\n",
      "           55.0000,  160.0000,   80.0000,   60.0000],\n",
      "        [ 900.0000,   90.0000,    0.0000,   37.5000,  375.0000,  600.0000,\n",
      "           50.0000,   80.0000,    0.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[900.0000,   0.0000,   0.0000,  12.5000, 375.0000, 400.0000,  50.0000,\n",
      "         120.0000,  80.0000,  20.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.02 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[ 900.0000,   60.0000,   30.0000,   37.5000, 1125.0000,    0.0000,\n",
      "           50.0000,   40.0000,   40.0000,   60.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 0.00 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[900.,  30.,   0.,   0., 750., 200.,  60., 160., 120.,   0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.02 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[1200.,   60.,    0.,   50.,    0.,  800.,   60.,   80.,  120.,   60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[300.0000,  60.0000,  60.0000,  37.5000,   0.0000, 200.0000,  40.0000,\n",
      "         160.0000,  40.0000,   0.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.01 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[ 300.0000,   60.0000,  120.0000,   12.5000, 1125.0000,  400.0000,\n",
      "           55.0000,  160.0000,  160.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[  0., 120.,   0.,   0.,   0., 800.,  45.,  40.,   0.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.02 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[   0.0000,   60.0000,   60.0000,   37.5000, 1500.0000,  400.0000,\n",
      "           55.0000,  120.0000,  120.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 7 took 0.01 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[  0.0000,  90.0000,   0.0000,  37.5000, 750.0000,   0.0000,  40.0000,\n",
      "          80.0000,  40.0000,  80.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.00 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[ 300.,   30.,    0.,   50., 1125.,  800.,   40.,  120.,    0.,   60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.02 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[   0.0000,    0.0000,    0.0000,   12.5000, 1125.0000,  200.0000,\n",
      "           60.0000,   80.0000,   40.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 0.02 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[300.,  90.,  60.,   0., 375., 400.,  40.,  80.,  40.,  20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.00 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[1200.,   90.,  120.,    0.,  750.,  800.,   50.,   40.,  120.,    0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.01 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[  0.0000, 120.0000,  30.0000,  37.5000, 375.0000,   0.0000,  40.0000,\n",
      "         120.0000,  40.0000,  80.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 0.00 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[1200.0000,   90.0000,    0.0000,   37.5000,    0.0000,    0.0000,\n",
      "           60.0000,   40.0000,   40.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[1200.0000,   60.0000,    0.0000,   37.5000,  750.0000,  600.0000,\n",
      "           45.0000,  160.0000,    0.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 0.00 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[300.,  90.,  90.,  50.,   0.,   0.,  60.,   0., 160.,  40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 0.02 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[600., 120., 120.,  50., 750.,   0.,  45.,   0., 160.,  40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.01 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[ 900.,   90.,   90.,    0., 1125.,    0.,   40.,   80.,   80.,   80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.00 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[ 300.0000,   60.0000,  120.0000,   12.5000, 1500.0000,  600.0000,\n",
      "           50.0000,  120.0000,  120.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[900.,  60.,  90.,  25.,   0.,   0.,  45.,  80.,  40.,   0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.01 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[300.0000,  30.0000,  90.0000,  37.5000, 375.0000,   0.0000,  40.0000,\n",
      "         120.0000, 160.0000,   0.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.00 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[  0.,  60.,  90.,  25.,   0., 800.,  60., 160., 120.,  40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.02 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[ 900.0000,   30.0000,    0.0000,   37.5000, 1500.0000,    0.0000,\n",
      "           45.0000,  160.0000,   40.0000,   20.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 0.00 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[  0.0000, 120.0000,  30.0000,  37.5000, 375.0000, 200.0000,  45.0000,\n",
      "         120.0000,  80.0000,  60.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.02 seconds\n",
      "最优点: [0.7735124230384827, 0.7735124230384827, 0.9845160841941833, 1.0426825284957886, 1.0426825284957886, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162]\n",
      "tensor([[ 600.0000,  120.0000,    0.0000,   37.5000, 1500.0000,  800.0000,\n",
      "           55.0000,   80.0000,   80.0000,   40.0000],\n",
      "        [ 900.0000,   60.0000,   30.0000,   12.5000,  750.0000,  800.0000,\n",
      "           45.0000,    0.0000,   40.0000,   60.0000],\n",
      "        [ 900.0000,   30.0000,  120.0000,   50.0000, 1125.0000,  200.0000,\n",
      "           45.0000,  160.0000,  160.0000,    0.0000],\n",
      "        [ 300.0000,   30.0000,   30.0000,   50.0000,  750.0000,  600.0000,\n",
      "           50.0000,    0.0000,  160.0000,   40.0000],\n",
      "        [ 300.0000,   90.0000,   90.0000,   12.5000, 1500.0000,  600.0000,\n",
      "           45.0000,   80.0000,   80.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[1200.,   60.,    0.,    0., 1125.,  800.,   60.,   80.,    0.,    0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.02 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[   0.0000,    0.0000,    0.0000,   37.5000, 1125.0000,    0.0000,\n",
      "           45.0000,   40.0000,  160.0000,    0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 0.00 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[1200.0000,   90.0000,  120.0000,   12.5000,  375.0000,    0.0000,\n",
      "           45.0000,   80.0000,   80.0000,   20.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 2 took 0.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[ 600.0000,  120.0000,  120.0000,   12.5000, 1125.0000,  800.0000,\n",
      "           45.0000,  160.0000,  160.0000,   20.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 0.01 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[ 300.,  120.,   90.,    0., 1125.,    0.,   40.,  120.,  160.,   20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.00 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[ 600.,   30.,   60.,   50., 1500.,  200.,   50.,    0.,    0.,   60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.02 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[  0., 120.,   0.,  25., 750.,   0.,  40.,   0., 160.,  60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.01 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[1200.,  120.,    0.,    0., 1125.,  600.,   50.,  120.,  120.,   20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.00 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[1200.0000,    0.0000,    0.0000,   37.5000, 1125.0000,  600.0000,\n",
      "           45.0000,   40.0000,  120.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 0.02 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[300.,  90.,  30.,   0., 750., 600.,  50.,   0.,   0.,  40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.02 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[1200.0000,  120.0000,  120.0000,   12.5000, 1500.0000,    0.0000,\n",
      "           60.0000,    0.0000,  120.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 0.00 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[ 300.0000,   30.0000,   30.0000,   37.5000, 1125.0000,  200.0000,\n",
      "           60.0000,    0.0000,    0.0000,   60.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 0.01 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[1200.,    0.,   30.,   50.,  750.,  800.,   45.,  160.,    0.,   60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.02 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[300.,  90., 120.,  25., 750., 800.,  55.,  80.,  80.,  60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 0.00 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[600.0000,  60.0000,  30.0000,  37.5000, 375.0000,   0.0000,  45.0000,\n",
      "         120.0000, 160.0000,  60.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[300.,  60.,  90.,   0., 750., 200.,  55., 120., 160.,  20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.01 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[900.,  30.,   0.,   0., 750., 200.,  40., 160.,   0.,   0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 0.00 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[   0.,   60.,  120.,    0., 1125.,  200.,   40.,   80.,    0.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.02 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[900.,  60.,  30.,   0., 750., 400.,  45., 160.,  80.,   0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.01 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[ 600.,   30.,   90.,    0., 1500.,  800.,   55.,    0.,   80.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.00 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[900.,  30.,  60.,   0.,   0., 600.,  55., 120.,  40.,   0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.02 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[300.0000,   0.0000,  30.0000,  37.5000,   0.0000,   0.0000,  55.0000,\n",
      "         120.0000,  80.0000,  80.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.00 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[900.,  60.,  60.,   0., 750.,   0.,  60., 120.,  80.,  20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.02 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[1200.,   30.,   30.,   50.,  750.,  200.,   45.,  160.,   40.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[300.,  30., 120.,   0., 375., 800.,  45.,   0., 160.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.00 seconds\n",
      "最优点: [0.9464483261108398, 0.9556806683540344, 1.0271196365356445, 1.0271196365356445, 1.0271196365356445, 1.3149700164794922, 1.3149700164794922, 1.3691112995147705, 1.3691112995147705, 1.3691112995147705, 1.3691112995147705, 1.3691112995147705, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.379567265510559, 1.379567265510559, 1.379567265510559, 1.379567265510559, 1.379567265510559]\n",
      "tensor([[ 900.0000,   90.0000,   60.0000,   37.5000,  375.0000,    0.0000,\n",
      "           60.0000,  160.0000,  160.0000,   40.0000],\n",
      "        [ 900.0000,    0.0000,    0.0000,   50.0000, 1125.0000,  600.0000,\n",
      "           45.0000,  160.0000,  120.0000,   40.0000],\n",
      "        [ 900.0000,   90.0000,  120.0000,   37.5000,  750.0000,  800.0000,\n",
      "           50.0000,  160.0000,   40.0000,   80.0000],\n",
      "        [ 300.0000,  120.0000,   90.0000,   12.5000, 1125.0000,  800.0000,\n",
      "           60.0000,   80.0000,   40.0000,    0.0000],\n",
      "        [ 300.0000,   90.0000,  120.0000,    0.0000, 1500.0000,  800.0000,\n",
      "           50.0000,    0.0000,  120.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[300.,   0.,  60.,  25., 750.,   0.,  45., 160.,  80.,  60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.00 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[1200.,   60.,  120.,    0., 1500.,  400.,   45.,    0.,  120.,   60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.01 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[   0.,   30.,  120.,    0., 1125.,  200.,   40.,  160.,  120.,   40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.02 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[900.,  60.,  60.,  25., 750., 400.,  55.,  40.,  40.,  20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[600.,  30.,   0.,  25., 750.,   0.,  40., 160., 120.,  60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.01 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[  0.,  30.,   0.,  25., 750., 400.,  50., 160.,  40.,   0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.02 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[1200.0000,   90.0000,   30.0000,   37.5000,  375.0000,  400.0000,\n",
      "           60.0000,  120.0000,   80.0000,   60.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 0.00 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[ 300.,   30.,   30.,   50., 1500.,  400.,   45.,   80.,  160.,   20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.02 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[ 900.,    0.,    0.,   25., 1500.,  400.,   60.,  120.,  120.,   20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.00 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[ 600.,   90.,   30.,    0., 1500.,  200.,   45.,   40.,  160.,   80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.01 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[600.0000,  60.0000,  30.0000,  37.5000, 375.0000, 400.0000,  45.0000,\n",
      "          80.0000,   0.0000,  80.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.02 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[1200.0000,   90.0000,   60.0000,   37.5000,  375.0000,  400.0000,\n",
      "           60.0000,  120.0000,  160.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 0.02 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[300.0000, 120.0000,   0.0000,  37.5000, 375.0000, 800.0000,  60.0000,\n",
      "          80.0000,  80.0000,  60.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.00 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[ 600.,   30.,   60.,   25., 1125.,    0.,   45.,  160.,   40.,    0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 0.01 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[600., 120.,  90.,  50., 750., 600.,  45.,   0.,   0.,  60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[900.,  90.,  30.,  50., 750., 600.,  60.,  40., 160.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.01 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[  0., 120., 120.,  25.,   0.,   0.,  50., 160., 120.,  60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 0.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[1200.,   90.,   30.,    0., 1125.,  600.,   50.,    0.,   40.,   20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.00 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[   0.0000,   60.0000,  120.0000,   12.5000, 1500.0000,  400.0000,\n",
      "           60.0000,    0.0000,    0.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 0.02 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[1200.0000,   60.0000,    0.0000,   12.5000, 1500.0000,  400.0000,\n",
      "           45.0000,  120.0000,   40.0000,   60.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 0.01 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[1200.,    0.,   30.,   50.,  750.,    0.,   55.,   80.,   80.,   20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.02 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[  0.0000, 120.0000,  60.0000,  37.5000, 750.0000, 200.0000,  60.0000,\n",
      "          40.0000,  80.0000,  60.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.00 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[  0.0000,  30.0000,  30.0000,  37.5000, 375.0000, 600.0000,  50.0000,\n",
      "         120.0000, 120.0000,   0.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.02 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[ 900.0000,    0.0000,   60.0000,   37.5000, 1500.0000,    0.0000,\n",
      "           40.0000,  160.0000,   40.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 0.01 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[  0., 120.,  60.,  25.,   0., 600.,  55.,  40.,   0.,  60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.00 seconds\n",
      "最优点: [1.0283737182617188, 1.0283737182617188, 1.0283737182617188, 1.2928533554077148, 1.2928533554077148, 1.2928533554077148, 1.2928533554077148, 1.2928533554077148, 1.3374898433685303, 1.3374898433685303, 1.3374898433685303, 1.3374898433685303, 1.3374898433685303, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168]\n",
      "tensor([[ 900.0000,   90.0000,   30.0000,   25.0000,    0.0000,    0.0000,\n",
      "           45.0000,  120.0000,  160.0000,   40.0000],\n",
      "        [   0.0000,   60.0000,    0.0000,    0.0000,  375.0000,  600.0000,\n",
      "           40.0000,   40.0000,    0.0000,   80.0000],\n",
      "        [ 300.0000,  120.0000,   60.0000,   12.5000,  750.0000,  800.0000,\n",
      "           55.0000,   80.0000,  160.0000,   80.0000],\n",
      "        [1200.0000,    0.0000,    0.0000,   25.0000,    0.0000,  600.0000,\n",
      "           50.0000,    0.0000,    0.0000,   60.0000],\n",
      "        [ 900.0000,  120.0000,   30.0000,   37.5000, 1125.0000,  600.0000,\n",
      "           55.0000,   80.0000,   40.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 300.,   90.,   60.,   25., 1125.,  800.,   45.,  160.,    0.,   60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.01 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[300.0000,   0.0000,  60.0000,  37.5000,   0.0000, 200.0000,  40.0000,\n",
      "         120.0000,  40.0000,   0.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.02 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[300.,   0.,  60.,  25.,   0., 400.,  45.,  80., 160.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.02 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[300.0000,  60.0000,   0.0000,  37.5000,   0.0000, 600.0000,  50.0000,\n",
      "          40.0000,  80.0000,  60.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[ 900.,  120.,    0.,    0., 1125.,  800.,   55.,    0.,  120.,   20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.01 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[  0.0000,  60.0000,   0.0000,  37.5000, 750.0000, 200.0000,  55.0000,\n",
      "         160.0000,  40.0000,  40.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.02 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[900.,  30.,  60.,   0.,   0., 600.,  50., 160.,  80.,  80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.00 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[ 300.,  120.,    0.,   50., 1500.,  800.,   55.,  120.,    0.,   80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.02 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[  0.,  90.,  30.,  25., 375., 200.,  60., 120.,  40.,  40.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.00 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[1200.,  120.,    0.,    0.,    0.,  400.,   55.,   80.,  120.,    0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.01 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[300.0000,  30.0000,  90.0000,  12.5000,   0.0000,   0.0000,  50.0000,\n",
      "         160.0000, 120.0000,   0.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.00 seconds\n",
      "Nr. of optimization run: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New candidates are: tensor([[  0.0000,  30.0000, 120.0000,  37.5000, 750.0000, 400.0000,  60.0000,\n",
      "           0.0000,  40.0000,  80.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.02 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[ 900.,   30.,   30.,   50., 1125.,  200.,   50.,   40.,   40.,   60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.01 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[   0.0000,    0.0000,   30.0000,   12.5000, 1500.0000,  800.0000,\n",
      "           60.0000,    0.0000,  120.0000,   40.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 0.00 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[300.0000,   0.0000,  60.0000,  37.5000, 750.0000, 800.0000,  60.0000,\n",
      "          80.0000, 160.0000,   0.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[ 900.,  120.,   90.,    0., 1500.,  600.,   50.,  120.,  120.,   80.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.02 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[1200.0000,  120.0000,  120.0000,   12.5000, 1500.0000,    0.0000,\n",
      "           60.0000,   80.0000,   80.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.01 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[1200.0000,  120.0000,   30.0000,   12.5000,    0.0000,  600.0000,\n",
      "           40.0000,   80.0000,   40.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 0.02 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[600.,  30.,  90.,  50., 375., 800.,  45., 160.,  40.,  20.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.00 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[1200.0000,   90.0000,  120.0000,   12.5000, 1125.0000,  800.0000,\n",
      "           55.0000,  120.0000,   40.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[600.0000,  90.0000,  60.0000,  12.5000, 750.0000, 600.0000,  45.0000,\n",
      "         160.0000,  40.0000,   0.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.00 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[1200.0000,    0.0000,    0.0000,   37.5000, 1500.0000,  200.0000,\n",
      "           50.0000,  120.0000,  120.0000,    0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 0.01 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[1200.,   30.,   60.,   50.,    0.,  200.,   60.,  160.,    0.,   60.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.02 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[1200.0000,   90.0000,   30.0000,   37.5000, 1500.0000,    0.0000,\n",
      "           40.0000,  160.0000,    0.0000,   20.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 0.00 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[ 600.0000,   30.0000,   60.0000,   37.5000, 1125.0000,  800.0000,\n",
      "           50.0000,  160.0000,   40.0000,   80.0000]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 24 took 0.01 seconds\n",
      "最优点: [1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623]\n",
      "Bayes Best Values Over All Experiments:\n",
      "[[1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428, 1.3763844966888428], [0.43853989243507385, 0.9590399265289307, 1.3403159379959106, 1.3403159379959106, 1.3403159379959106, 1.3403159379959106, 1.3403159379959106, 1.3403159379959106, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649, 1.388088345527649], [1.3227059841156006, 1.3227059841156006, 1.3227059841156006, 1.3227059841156006, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3317538499832153, 1.3383337259292603, 1.3383337259292603, 1.3383337259292603, 1.3383337259292603, 1.3383337259292603, 1.3383337259292603, 1.3383337259292603, 1.3383337259292603, 1.3670228719711304, 1.3670228719711304, 1.3670228719711304, 1.3670228719711304], [0.9867502450942993, 0.9867502450942993, 1.2765836715698242, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965, 1.3569769859313965], [1.319503903388977, 1.319503903388977, 1.319503903388977, 1.319503903388977, 1.3229302167892456, 1.3229302167892456, 1.3229302167892456, 1.3229302167892456, 1.3229302167892456, 1.3229302167892456, 1.3643288612365723, 1.3643288612365723, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063, 1.391088604927063], [0.9847676157951355, 1.1715800762176514, 1.1715800762176514, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.3550238609313965, 1.360791802406311, 1.360791802406311, 1.360791802406311, 1.360791802406311], [0.7735124230384827, 0.7735124230384827, 0.9845160841941833, 1.0426825284957886, 1.0426825284957886, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162, 1.392991542816162], [0.9464483261108398, 0.9556806683540344, 1.0271196365356445, 1.0271196365356445, 1.0271196365356445, 1.3149700164794922, 1.3149700164794922, 1.3691112995147705, 1.3691112995147705, 1.3691112995147705, 1.3691112995147705, 1.3691112995147705, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.376320242881775, 1.379567265510559, 1.379567265510559, 1.379567265510559, 1.379567265510559, 1.379567265510559], [1.0283737182617188, 1.0283737182617188, 1.0283737182617188, 1.2928533554077148, 1.2928533554077148, 1.2928533554077148, 1.2928533554077148, 1.2928533554077148, 1.3374898433685303, 1.3374898433685303, 1.3374898433685303, 1.3374898433685303, 1.3374898433685303, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168, 1.3872981071472168], [1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.3441522121429443, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623, 1.354072093963623]]\n",
      "Bayes Best Values Over All Experiments (Array):\n",
      "[[1.3763845  1.3763845  1.3763845  1.3763845  1.3763845  1.3763845\n",
      "  1.3763845  1.3763845  1.3763845  1.3763845  1.3763845  1.3763845\n",
      "  1.3763845  1.3763845  1.3763845  1.3763845  1.3763845  1.3763845\n",
      "  1.3763845  1.3763845  1.3763845  1.3763845  1.3763845  1.3763845\n",
      "  1.3763845  1.3763845  1.3763845  1.3763845  1.3763845  1.3763845 ]\n",
      " [0.43853989 0.95903993 1.34031594 1.34031594 1.34031594 1.34031594\n",
      "  1.34031594 1.34031594 1.38808835 1.38808835 1.38808835 1.38808835\n",
      "  1.38808835 1.38808835 1.38808835 1.38808835 1.38808835 1.38808835\n",
      "  1.38808835 1.38808835 1.38808835 1.38808835 1.38808835 1.38808835\n",
      "  1.38808835 1.38808835 1.38808835 1.38808835 1.38808835 1.38808835]\n",
      " [1.32270598 1.32270598 1.32270598 1.32270598 1.33175385 1.33175385\n",
      "  1.33175385 1.33175385 1.33175385 1.33175385 1.33175385 1.33175385\n",
      "  1.33175385 1.33175385 1.33175385 1.33175385 1.33175385 1.33175385\n",
      "  1.33833373 1.33833373 1.33833373 1.33833373 1.33833373 1.33833373\n",
      "  1.33833373 1.33833373 1.36702287 1.36702287 1.36702287 1.36702287]\n",
      " [0.98675025 0.98675025 1.27658367 1.35697699 1.35697699 1.35697699\n",
      "  1.35697699 1.35697699 1.35697699 1.35697699 1.35697699 1.35697699\n",
      "  1.35697699 1.35697699 1.35697699 1.35697699 1.35697699 1.35697699\n",
      "  1.35697699 1.35697699 1.35697699 1.35697699 1.35697699 1.35697699\n",
      "  1.35697699 1.35697699 1.35697699 1.35697699 1.35697699 1.35697699]\n",
      " [1.3195039  1.3195039  1.3195039  1.3195039  1.32293022 1.32293022\n",
      "  1.32293022 1.32293022 1.32293022 1.32293022 1.36432886 1.36432886\n",
      "  1.3910886  1.3910886  1.3910886  1.3910886  1.3910886  1.3910886\n",
      "  1.3910886  1.3910886  1.3910886  1.3910886  1.3910886  1.3910886\n",
      "  1.3910886  1.3910886  1.3910886  1.3910886  1.3910886  1.3910886 ]\n",
      " [0.98476762 1.17158008 1.17158008 1.35502386 1.35502386 1.35502386\n",
      "  1.35502386 1.35502386 1.35502386 1.35502386 1.35502386 1.35502386\n",
      "  1.35502386 1.35502386 1.35502386 1.35502386 1.35502386 1.35502386\n",
      "  1.35502386 1.35502386 1.35502386 1.35502386 1.35502386 1.35502386\n",
      "  1.35502386 1.35502386 1.3607918  1.3607918  1.3607918  1.3607918 ]\n",
      " [0.77351242 0.77351242 0.98451608 1.04268253 1.04268253 1.39299154\n",
      "  1.39299154 1.39299154 1.39299154 1.39299154 1.39299154 1.39299154\n",
      "  1.39299154 1.39299154 1.39299154 1.39299154 1.39299154 1.39299154\n",
      "  1.39299154 1.39299154 1.39299154 1.39299154 1.39299154 1.39299154\n",
      "  1.39299154 1.39299154 1.39299154 1.39299154 1.39299154 1.39299154]\n",
      " [0.94644833 0.95568067 1.02711964 1.02711964 1.02711964 1.31497002\n",
      "  1.31497002 1.3691113  1.3691113  1.3691113  1.3691113  1.3691113\n",
      "  1.37632024 1.37632024 1.37632024 1.37632024 1.37632024 1.37632024\n",
      "  1.37632024 1.37632024 1.37632024 1.37632024 1.37632024 1.37632024\n",
      "  1.37632024 1.37956727 1.37956727 1.37956727 1.37956727 1.37956727]\n",
      " [1.02837372 1.02837372 1.02837372 1.29285336 1.29285336 1.29285336\n",
      "  1.29285336 1.29285336 1.33748984 1.33748984 1.33748984 1.33748984\n",
      "  1.33748984 1.38729811 1.38729811 1.38729811 1.38729811 1.38729811\n",
      "  1.38729811 1.38729811 1.38729811 1.38729811 1.38729811 1.38729811\n",
      "  1.38729811 1.38729811 1.38729811 1.38729811 1.38729811 1.38729811]\n",
      " [1.34415221 1.34415221 1.34415221 1.34415221 1.34415221 1.34415221\n",
      "  1.34415221 1.34415221 1.34415221 1.34415221 1.34415221 1.34415221\n",
      "  1.34415221 1.35407209 1.35407209 1.35407209 1.35407209 1.35407209\n",
      "  1.35407209 1.35407209 1.35407209 1.35407209 1.35407209 1.35407209\n",
      "  1.35407209 1.35407209 1.35407209 1.35407209 1.35407209 1.35407209]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\10925\\AppData\\Local\\Temp\\ipykernel_14960\\2546885363.py:6: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results3 = Hartmannb.bayesian_optimization_experiment(\n",
    "    num_experiments=10,\n",
    "    n=25,\n",
    "    obj_fn1=predict_bi_function_xg,\n",
    "    obj_fn3=predict_bi_function_xg,\n",
    "    initial_points_task1=initial_points_task33,  # 传递生成的初始样本\n",
    "    initial_points_task2=initial_points_task22,  # 传递生成的初始样本\n",
    "    fit_task_fn=fit_gp_model_and_select_next_point3,\n",
    "    device='cuda',\n",
    "    task_type='single'  # 表示运行单任务模型\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a3fae18-6999-4858-979e-9b887da2438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDOE2 import lhs\n",
    "from scipy.stats import qmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4857164-8473-4f3a-88ed-e2a1cdca4ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成 LHS 样本并缩放到指定上下界\n",
    "def generate_lhs_samples(num_features, num_samples, dim_ranges):\n",
    "    # 生成 LHS 样本\n",
    "    lhs_sampler = qmc.LatinHypercube(d=num_features)\n",
    "    samples = lhs_sampler.random(n=num_samples)\n",
    "    \n",
    "    # 获取每个维度的上下界\n",
    "    lower_bounds = [lower for lower, upper in dim_ranges]\n",
    "    upper_bounds = [upper for lower, upper in dim_ranges]\n",
    "    \n",
    "    # 缩放样本到指定的上下界\n",
    "    scaled_samples = qmc.scale(samples, lower_bounds, upper_bounds)\n",
    "    \n",
    "    return scaled_samples\n",
    "\n",
    "# 管理 LHS 样本并按顺序检索它们的类\n",
    "class SampleProvider:\n",
    "    def __init__(self, num_features, batch_size, dim_ranges):\n",
    "        self.num_features = num_features\n",
    "        self.batch_size = batch_size\n",
    "        self.dim_ranges = dim_ranges\n",
    "\n",
    "    def get_batch_samples(self, num_samples=None):\n",
    "        # 默认生成一批次的样本数量，若提供 num_samples 参数则生成指定数量的样本\n",
    "        if num_samples is None:\n",
    "            num_samples = self.batch_size\n",
    "        samples_np = generate_lhs_samples(self.num_features, num_samples, self.dim_ranges)\n",
    "        return torch.tensor(samples_np, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e79a6b8f-534a-4d6a-aad0-0a0fe2cafcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "tensor([[ 281.9714,   27.6710,   11.0640,    9.3759, 1302.1571,  272.4051,\n",
      "           44.4216,    4.6336,  103.1668,   78.1789],\n",
      "        [ 605.6957,  118.4077,   48.0094,   43.6833, 1103.9655,  646.9623,\n",
      "           53.3639,   43.5809,   67.8361,   52.1371],\n",
      "        [ 864.3659,   53.9718,   82.9741,   15.7448,  215.2910,  575.2879,\n",
      "           42.7079,  119.9232,   14.3924,   19.1747],\n",
      "        [1019.0118,   81.9473,   41.7316,   28.3621,  348.8506,  459.9968,\n",
      "           51.7189,   64.2551,   44.2446,   43.8256],\n",
      "        [ 230.1448,    3.1390,  112.9295,   35.6862,  723.1549,   74.5717,\n",
      "           59.2120,  135.3875,  146.4450,    5.8486]], dtype=torch.float64)\n",
      "\n",
      "Batch 2:\n",
      "tensor([[ 537.1142,  105.6255,   84.7419,   20.6958, 1140.3436,  347.1929,\n",
      "           50.9915,   27.6977,  138.4464,   19.4820],\n",
      "        [  80.1174,   70.5982,   57.8137,   40.3265,  147.3151,  537.6865,\n",
      "           57.4184,  119.6910,   56.7795,    3.5362],\n",
      "        [ 430.3364,   75.2046,   25.3341,   38.6104,  831.2621,  200.9939,\n",
      "           47.4601,  153.8680,   21.7235,   51.9747],\n",
      "        [ 962.9085,   34.3716,    9.5843,    2.9682, 1210.0056,   95.4208,\n",
      "           41.0551,   60.9960,   95.1485,   73.4308],\n",
      "        [ 774.4196,   20.6318,  116.8973,   18.3989,  576.3596,  722.6947,\n",
      "           52.2022,   88.4366,  116.4657,   42.1443]], dtype=torch.float64)\n",
      "\n",
      "Batch 3:\n",
      "tensor([[1140.7906,   18.2061,   34.0670,   35.3624,  537.8270,  776.0083,\n",
      "           40.7907,   66.6696,   95.5324,   13.0781],\n",
      "        [ 686.4184,   25.2158,   56.8334,   44.6798, 1148.8527,  590.7627,\n",
      "           49.5083,  155.7515,  132.0544,   62.4593],\n",
      "        [ 354.9264,  117.5240,   20.7188,   28.3390,  678.3283,  174.8224,\n",
      "           58.9894,    6.8256,   30.7388,   30.7984],\n",
      "        [ 921.0133,   71.4106,   91.7889,   13.4123,  146.0325,   63.4293,\n",
      "           54.3961,   43.7026,   97.3708,   75.4084],\n",
      "        [ 180.1098,   88.4184,  106.0110,    8.3331, 1293.0729,  330.9028,\n",
      "           46.8144,  122.5108,   56.3029,   33.7105]], dtype=torch.float64)\n",
      "\n",
      "Batch 4:\n",
      "tensor([[ 547.3569,   38.0727,   60.1823,   37.9726, 1040.6443,  454.3831,\n",
      "           45.9063,   47.0072,  155.1902,    6.0158],\n",
      "        [1163.5620,   85.9983,   10.9697,    6.3130,  208.3722,  252.0922,\n",
      "           52.7241,  119.9556,   69.3667,   31.0125],\n",
      "        [ 389.2540,   54.6448,   81.5249,   10.0315,  304.4839,   13.5940,\n",
      "           49.5706,  143.4570,   56.3740,   33.7693],\n",
      "        [ 889.4371,    2.0476,   46.4158,   45.2090, 1289.6214,  782.3115,\n",
      "           43.2765,    8.4146,   27.4706,   55.5637],\n",
      "        [   3.6169,  103.0557,  112.6425,   26.9236,  620.0339,  626.7435,\n",
      "           58.3072,   83.7438,  113.7085,   66.7706]], dtype=torch.float64)\n",
      "\n",
      "Batch 5:\n",
      "tensor([[ 914.7043,   82.1421,   61.8879,    9.9604, 1346.2526,  567.2145,\n",
      "           48.6582,  108.1504,  158.4852,    7.5322],\n",
      "        [ 979.9479,  110.2786,   13.2338,   27.5651,  368.4147,  703.9019,\n",
      "           58.0294,   19.0276,   87.2698,   75.8688],\n",
      "        [ 709.0247,   16.8244,  118.3119,   36.2862, 1094.6749,  332.5568,\n",
      "           44.3375,   33.1154,   32.9056,   38.3932],\n",
      "        [ 424.7162,   55.8630,   41.0722,   49.2777,  785.5033,  192.1765,\n",
      "           52.2540,   70.4142,   12.3291,   48.2776],\n",
      "        [   6.0071,   41.5809,   91.8022,   16.6113,   34.2355,   16.8910,\n",
      "           43.8782,  159.1980,  102.4770,   18.0643]], dtype=torch.float64)\n",
      "\n",
      "Batch 6:\n",
      "tensor([[9.4750e+02, 7.7545e-01, 6.0536e+01, 3.8217e+01, 7.2452e+01, 7.9341e+02,\n",
      "         4.2729e+01, 1.0026e+01, 9.5903e+01, 7.9397e+01],\n",
      "        [1.0088e+03, 1.1533e+02, 1.1120e+02, 2.5541e+01, 1.4547e+03, 6.3394e+01,\n",
      "         5.6142e+01, 5.7252e+01, 1.3649e+02, 4.2252e+00],\n",
      "        [4.2717e+02, 6.0320e+01, 7.8267e+01, 4.9506e+01, 1.1166e+03, 2.0277e+02,\n",
      "         4.8581e+01, 1.4641e+02, 4.7327e+01, 5.5236e+01],\n",
      "        [2.4937e+01, 7.9235e+01, 1.2676e+01, 1.0531e+01, 5.1092e+02, 5.9960e+02,\n",
      "         5.5288e+01, 1.0209e+02, 3.7308e+00, 4.0807e+01],\n",
      "        [6.8607e+02, 3.4026e+01, 2.9664e+01, 9.8885e-01, 8.9639e+02, 3.2133e+02,\n",
      "         4.4546e+01, 6.7681e+01, 1.0311e+02, 2.3994e+01]], dtype=torch.float64)\n",
      "\n",
      "Batch 7:\n",
      "tensor([[ 625.5411,   91.9332,  102.5055,   24.0934,  637.7751,  369.6839,\n",
      "           42.4580,   62.8682,   89.4630,   62.8593],\n",
      "        [ 371.0605,  105.8830,   53.4186,   41.1224, 1099.1133,  270.9374,\n",
      "           47.5623,  110.9463,   20.5058,   77.9982],\n",
      "        [1194.9187,   54.6129,   13.8380,   14.5143,   77.2897,   92.7323,\n",
      "           53.5033,  155.9066,  114.9364,   17.9023],\n",
      "        [ 105.1807,   21.0701,   25.6617,   38.7647,  342.3012,  609.7560,\n",
      "           59.4881,   86.8070,   53.1951,   38.3035],\n",
      "        [ 742.5605,   42.4066,   93.9557,    6.4974, 1378.0241,  744.8134,\n",
      "           49.6293,    2.3166,  141.8182,   12.5931]], dtype=torch.float64)\n",
      "\n",
      "Batch 8:\n",
      "tensor([[ 987.6512,   41.8686,  113.4154,   20.3207,  182.7922,  502.8077,\n",
      "           46.5494,  121.8106,  102.6978,   17.2765],\n",
      "        [ 226.9345,   50.3267,   56.4120,   10.6238, 1485.6732,  176.5448,\n",
      "           55.9277,  138.0489,   51.5601,    6.2047],\n",
      "        [ 622.8346,    2.0265,   29.9018,   38.9040,  796.9768,  734.7319,\n",
      "           50.1252,   18.9593,   70.0085,   59.6884],\n",
      "        [ 846.3444,   76.5192,   85.5081,   43.8281, 1041.5834,  450.8475,\n",
      "           41.7476,   71.3654,   28.4840,   47.9377],\n",
      "        [ 261.4053,   96.1098,    9.6583,    8.6725,  301.5117,  119.3752,\n",
      "           56.9518,   38.8579,  140.4444,   75.1685]], dtype=torch.float64)\n",
      "\n",
      "Batch 9:\n",
      "tensor([[4.5691e+02, 3.1639e+01, 3.2027e+01, 2.7663e+01, 1.3458e+03, 5.2273e-01,\n",
      "         4.6678e+01, 5.5192e+01, 5.3158e+01, 6.8727e+01],\n",
      "        [1.1021e+03, 1.0023e+02, 5.8323e+01, 5.4869e+00, 7.8374e+02, 5.4001e+02,\n",
      "         4.8450e+01, 1.3725e+02, 1.5299e+02, 5.3882e+01],\n",
      "        [6.2608e+02, 2.2179e+01, 1.1657e+02, 4.9718e+01, 6.5677e+01, 4.0855e+02,\n",
      "         4.3344e+01, 2.3831e+01, 6.4922e+01, 9.0752e+00],\n",
      "        [2.2337e+02, 5.1176e+01, 1.2982e+01, 1.0105e+01, 5.6733e+02, 3.1208e+02,\n",
      "         5.8630e+01, 1.2568e+02, 1.0763e+02, 3.5898e+01],\n",
      "        [9.5454e+02, 8.7524e+01, 7.5685e+01, 3.2301e+01, 1.1763e+03, 7.8687e+02,\n",
      "         5.4795e+01, 6.6771e+01, 1.4040e+01, 1.9904e+01]], dtype=torch.float64)\n",
      "\n",
      "Batch 10:\n",
      "tensor([[1170.6131,   64.3107,  102.5111,   40.5598,  115.2125,  795.9924,\n",
      "           53.3099,  106.8716,   48.8236,   55.6144],\n",
      "        [ 410.3579,  104.4301,   78.5938,   32.4418, 1088.9482,  227.2145,\n",
      "           46.9380,   53.1690,  131.5680,    4.2844],\n",
      "        [ 826.7605,   19.5947,   67.9008,   12.6549,  875.4526,  464.8777,\n",
      "           57.9519,    6.2239,   11.9639,   43.6254],\n",
      "        [ 235.0614,   72.3651,   26.2975,   25.4826, 1302.7555,   27.2999,\n",
      "           49.3820,  141.7767,   74.7923,   74.5037],\n",
      "        [ 602.1662,   31.7005,    8.6152,    9.0585,  473.4931,  611.7447,\n",
      "           43.5309,   68.6333,   98.4403,   28.6432]], dtype=torch.float64)\n",
      "\n",
      "Single Sample:\n",
      " tensor([[1163.0484,  119.6404,   76.5307,   31.3435, 1454.8197,   79.9949,\n",
      "           47.8349,   29.5526,   62.5740,   54.4139]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 使用示例\n",
    "num_features = len(dim_ranges)\n",
    "batch_size = 5      # 每次生成的样本数量\n",
    "num_batches = 10    # 总共生成的批次数量\n",
    "provider = SampleProvider(num_features, batch_size, dim_ranges)\n",
    "\n",
    "# 连续生成十次，每次五个数据，保存到 initial_points_task1\n",
    "initial_points_task1 = []\n",
    "for _ in range(num_batches):\n",
    "    batch_samples = provider.get_batch_samples()\n",
    "    initial_points_task1.append(batch_samples)\n",
    "\n",
    "# 生成一个单独的数据样本\n",
    "single_sample = provider.get_batch_samples(num_samples=1)\n",
    "\n",
    "# 将结果打印出来\n",
    "for i, batch in enumerate(initial_points_task1):\n",
    "    print(f\"Batch {i + 1}:\\n{batch}\\n\")\n",
    "print(\"Single Sample:\\n\", single_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "033334a9-deec-42b4-98f9-4f197abb4507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1097.6808,   91.5249,   84.3260,   14.0472,  910.6464,  119.5805,\n",
       "           59.4897,   66.2187,   78.0780,    5.5999]], dtype=torch.float64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provider.get_batch_samples(num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c9207b-b617-472b-ba49-2263eeb84f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc9079fa-aa52-4d09-ad57-2a36d934d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类似你提供的函数\n",
    "def zj(train_x, train_obj, device):\n",
    "    return provider.get_batch_samples(num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb71ab1f-13ba-4dc1-b695-19764e46a88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 281.9714,   27.6710,   11.0640,    9.3759, 1302.1571,  272.4051,\n",
      "           44.4216,    4.6336,  103.1668,   78.1789],\n",
      "        [ 605.6957,  118.4077,   48.0094,   43.6833, 1103.9655,  646.9623,\n",
      "           53.3639,   43.5809,   67.8361,   52.1371],\n",
      "        [ 864.3659,   53.9718,   82.9741,   15.7448,  215.2910,  575.2879,\n",
      "           42.7079,  119.9232,   14.3924,   19.1747],\n",
      "        [1019.0118,   81.9473,   41.7316,   28.3621,  348.8506,  459.9968,\n",
      "           51.7189,   64.2551,   44.2446,   43.8256],\n",
      "        [ 230.1448,    3.1390,  112.9295,   35.6862,  723.1549,   74.5717,\n",
      "           59.2120,  135.3875,  146.4450,    5.8486]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 951.2857,   49.1856,   69.2017,   12.3459, 1416.7464,  450.0634,\n",
      "           54.9214,   82.9794,  115.3339,   47.8999]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 0 took 0.00 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[546.8643,  11.6805, 104.0175,  22.2706, 988.7317, 772.1402,  40.1339,\n",
      "         148.6447,  26.9499,  54.8395]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.02 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[ 52.6628, 103.5136,  83.5158,  39.0894, 701.6038, 193.7580,  53.0702,\n",
      "          48.7557,  61.2639,   8.3374]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.02 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[1071.6900,   98.1623,   36.4085,   33.6375,  942.1606,  523.0601,\n",
      "           54.2898,  131.8311,   98.0427,   38.0001]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[409.7954,  61.7508, 112.4884,   4.3337, 248.3270, 277.8585,  54.3893,\n",
      "          86.4035,   1.7170,  59.6772]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.01 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[ 121.2852,    1.5276,   51.2411,   45.3868, 1102.4106,  350.7491,\n",
      "           40.9146,   98.5243,   87.1977,   70.3940]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 0.00 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[703.8909,  65.7688, 118.5807,   8.2248, 468.3486,  78.6427,  57.1127,\n",
      "          50.7328, 128.0632,  55.0552]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.02 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[ 652.3698,   77.9648,  110.2785,   22.9742, 1191.0169,  751.8927,\n",
      "           45.6203,   35.9575,   92.4361,   34.0374]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 7 took 0.00 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[904.5812,  81.9126,  91.9026,  15.7735, 455.5063, 380.4643,  53.3612,\n",
      "         155.5866, 113.3784,  58.8446]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.02 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[876.2363,  27.4907, 107.1583,  29.1993, 324.8532, 416.6544,  49.4454,\n",
      "          91.9095, 127.2954,  37.6659]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.01 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[897.7553,  34.8453, 111.5142,  46.8708, 265.7674, 646.1319,  47.9286,\n",
      "         106.3171, 137.4646,   7.5863]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.00 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[ 940.4359,   85.6488,   47.0462,    1.9835, 1396.0811,  397.7168,\n",
      "           59.7677,  136.1132,  159.5068,   11.5533]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 0.02 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[ 540.3795,   31.1182,   57.2520,    9.1775, 1302.9818,  526.1050,\n",
      "           40.2627,   86.5156,  154.5968,   35.5022]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 0.01 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[407.5764, 115.9848,  22.0823,  32.8519, 793.0148, 635.5823,  40.2647,\n",
      "         102.4101, 105.7330,  60.5138]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 0.00 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[549.5487,  14.5763, 118.7951,  42.0255, 211.3763, 114.1673,  52.6998,\n",
      "         131.7673,  72.0452,  44.2550]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[401.9705,  16.9669, 106.2574,  13.7640, 841.0372, 160.3434,  54.9914,\n",
      "          72.6215, 103.4636,  38.5418]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.00 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[1173.6940,   19.6132,  108.3726,   46.2633, 1093.2852,  139.8845,\n",
      "           47.0267,  123.3265,   62.2758,   49.3933]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.02 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[312.7607,  79.4302, 106.0422,  25.7332, 415.9882, 618.6118,  46.1809,\n",
      "          52.2768, 158.2137,  67.1059]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.01 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[146.4055,  70.2550,  95.6856,  45.1639, 536.8092, 591.7961,  57.9271,\n",
      "          56.5566, 108.7988,  49.7615]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.00 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[104.1107,  61.9605,  28.6814,  34.6023, 169.4612, 317.9792,  52.1585,\n",
      "         100.9523,  74.8764,  28.2490]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[ 355.3613,   64.3166,   76.1442,    2.9226, 1485.7504,  511.9424,\n",
      "           48.1988,   63.1913,  145.6811,   79.4967]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 0.00 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[954.9104, 109.1942,  40.3207,  36.3535,  84.5365, 667.6994,  53.9244,\n",
      "         106.9747, 121.4560,  31.0172]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.02 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[887.4127, 102.8153,  54.3122,  48.0484, 706.2729,  50.2960,  40.0264,\n",
      "         118.7130,  94.1653,  13.9874]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.01 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[588.9774,   0.9717,  78.7322,  27.6288,  12.8762, 324.0145,  42.2450,\n",
      "          23.9576,  82.4024,  79.8734]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.00 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[5.8431e+02, 4.6078e+01, 1.0293e+01, 1.3896e+01, 1.3766e+03, 1.1286e+00,\n",
      "         5.2793e+01, 1.6796e+01, 4.1201e+01, 1.0128e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 24 took 0.02 seconds\n",
      "最优点: [0.9725248217582703, 0.9725248217582703, 1.3512645959854126, 1.3512645959854126, 1.3512645959854126, 1.3512645959854126, 1.360853910446167, 1.360853910446167, 1.360853910446167, 1.360853910446167, 1.360853910446167, 1.360853910446167, 1.360853910446167, 1.3672524690628052, 1.3672524690628052, 1.3672524690628052, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862]\n",
      "tensor([[ 537.1142,  105.6255,   84.7419,   20.6958, 1140.3436,  347.1929,\n",
      "           50.9915,   27.6977,  138.4464,   19.4820],\n",
      "        [  80.1174,   70.5982,   57.8137,   40.3265,  147.3151,  537.6865,\n",
      "           57.4184,  119.6910,   56.7795,    3.5362],\n",
      "        [ 430.3364,   75.2046,   25.3341,   38.6104,  831.2621,  200.9939,\n",
      "           47.4601,  153.8680,   21.7235,   51.9747],\n",
      "        [ 962.9085,   34.3716,    9.5843,    2.9682, 1210.0056,   95.4208,\n",
      "           41.0551,   60.9960,   95.1485,   73.4308],\n",
      "        [ 774.4196,   20.6318,  116.8973,   18.3989,  576.3596,  722.6947,\n",
      "           52.2022,   88.4366,  116.4657,   42.1443]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[700.1590, 116.8988,  96.2689,   1.7821, 877.8073, 220.9573,  48.3501,\n",
      "          66.4118, 101.3517,  65.0985]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.00 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[ 657.9478,   33.7040,   35.0757,   36.0683, 1303.8286,  120.5980,\n",
      "           44.2548,   96.6689,   77.1566,   66.9630]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 0.02 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[118.2569, 118.8156,  75.0552,  35.4692,   7.7149, 731.2596,  53.0647,\n",
      "          31.9838,  91.4812,  21.3044]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.00 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[908.3178, 110.5766, 104.1761,  13.7692, 963.2242, 603.2008,  50.4964,\n",
      "          42.0680,  72.8413,  77.4852]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.02 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[411.4695, 116.4995,   1.9994,  27.5434, 442.5882, 696.2451,  47.3934,\n",
      "         150.0959, 117.5159,  64.3906]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.01 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[1125.6406,   57.3881,   19.8478,    4.5750,  350.1997,  298.8850,\n",
      "           44.0107,   47.3359,    8.2131,   18.7775]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 0.00 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[ 219.0740,   80.3964,   95.3208,   44.0795, 1490.4706,  544.5799,\n",
      "           46.8949,   52.3330,   75.3598,   60.5576]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 0.02 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[1020.2429,   17.3488,   84.2306,   15.5496,  452.0268,  345.1365,\n",
      "           40.5719,   20.4081,   53.5566,   54.4384]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 7 took 0.02 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[410.0371,  51.7753,  74.4529,  43.7469, 655.2196, 265.5223,  40.4161,\n",
      "         139.0145,  78.7680,  58.9976]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.00 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[272.8439,  59.2012,  69.0658,  16.3059, 585.2382, 747.1902,  42.7326,\n",
      "          46.7518, 146.4326,  40.9421]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.01 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[249.5386,  90.6796,  98.4454,  28.4064, 341.3629, 483.1600,  40.3805,\n",
      "          65.0001, 156.9016,  62.6180]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.00 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[9.2316e+02, 9.9381e+01, 9.2886e+01, 1.5844e+01, 1.1179e+03, 6.6986e+02,\n",
      "         5.9437e+01, 6.1208e+01, 1.1173e+02, 1.0732e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 0.02 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[255.6029,  66.4909,  70.3156,   0.5812, 548.1095, 500.7458,  40.6659,\n",
      "         121.9278, 104.6164,  49.0266]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.01 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[  4.7022,  33.4361,  60.4709,   3.0575, 513.8295, 390.1213,  53.7567,\n",
      "          68.8422,  77.7634,  50.3365]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 0.00 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[351.2875,  87.9205,  34.3477,  40.7859, 288.4387, 795.7464,  47.4356,\n",
      "          84.8452, 111.9843,  36.0002]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[973.2497,  11.0736,  14.8373,  27.7378, 251.9569, 273.1148,  59.7039,\n",
      "         140.4304, 143.3931,  43.4356]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.00 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[ 433.5408,   55.8569,   80.2271,   44.4624, 1157.2393,  787.9184,\n",
      "           47.5130,   82.1828,  102.7867,   61.8741]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.02 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[1062.3946,   89.9862,  108.0506,   19.4529, 1444.1669,  168.0662,\n",
      "           57.5876,   37.5204,   53.7549,   10.7946]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 0.01 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[876.5235,  73.2427,  50.0102,  25.9986, 765.9555, 502.2329,  48.0895,\n",
      "          95.5191,  87.5445,   5.4265]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.00 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[327.0167,  99.9161,  17.9795,  27.4385, 395.5909, 776.7536,  59.6419,\n",
      "         101.8714,  54.0125,   7.8137]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[197.9936, 107.8314,  72.5253,  36.7531, 748.1103, 530.1386,  48.1741,\n",
      "          75.3400, 146.6324,  38.2789]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.02 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[ 700.2418,  117.9411,   58.0180,    4.1180, 1307.8785,  234.7531,\n",
      "           40.7566,  129.7141,    7.1536,    7.5631]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 0.00 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[975.7354,  88.0241,  67.3200,  26.0812, 851.5657, 244.8003,  57.2010,\n",
      "          11.4240, 129.6348,  39.9947]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.01 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[  14.1572,   39.1722,   88.9214,   36.8178, 1286.5021,  107.6625,\n",
      "           49.4924,    7.0851,    6.8644,   51.5393]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 0.00 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[299.9416, 103.7862, 117.6970,  14.0800, 562.6292, 228.8918,  51.0470,\n",
      "          85.8521,  69.9770,  36.0918]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.02 seconds\n",
      "最优点: [1.3315730094909668, 1.3315730094909668, 1.3315730094909668, 1.3315730094909668, 1.3332024812698364, 1.3332024812698364, 1.3332024812698364, 1.3332024812698364, 1.3332024812698364, 1.3332024812698364, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676]\n",
      "tensor([[1140.7906,   18.2061,   34.0670,   35.3624,  537.8270,  776.0083,\n",
      "           40.7907,   66.6696,   95.5324,   13.0781],\n",
      "        [ 686.4184,   25.2158,   56.8334,   44.6798, 1148.8527,  590.7627,\n",
      "           49.5083,  155.7515,  132.0544,   62.4593],\n",
      "        [ 354.9264,  117.5240,   20.7188,   28.3390,  678.3283,  174.8224,\n",
      "           58.9894,    6.8256,   30.7388,   30.7984],\n",
      "        [ 921.0133,   71.4106,   91.7889,   13.4123,  146.0325,   63.4293,\n",
      "           54.3961,   43.7026,   97.3708,   75.4084],\n",
      "        [ 180.1098,   88.4184,  106.0110,    8.3331, 1293.0729,  330.9028,\n",
      "           46.8144,  122.5108,   56.3029,   33.7105]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[1179.5545,   35.6425,   39.8907,    3.7217, 1392.5037,  336.0565,\n",
      "           50.5453,  136.2200,   80.4546,   54.7552]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 0 took 0.02 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[6.5776e+02, 6.2416e+01, 9.4084e+01, 3.9374e+00, 8.1509e+02, 3.7782e-01,\n",
      "         5.9126e+01, 1.3130e+02, 8.1770e+01, 5.3260e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 0.00 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[1088.3514,   86.0298,   76.6298,   17.4418, 1155.9377,  333.3203,\n",
      "           55.6272,  129.7906,   33.9615,   25.3206]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 2 took 0.02 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[1000.5441,   92.3604,   10.9920,   33.6668,  269.6988,  695.7400,\n",
      "           58.2469,    4.3539,   68.3393,   58.2291]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[ 430.7070,   92.9638,  105.0647,   34.3616, 1115.0752,    3.7396,\n",
      "           51.9954,   18.4186,   99.2041,   49.4924]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 4 took 0.01 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[548.6564,  53.0201,  65.3554,  13.4977, 283.9781, 484.3034,  59.0342,\n",
      "           8.9242,  95.3626,  37.8820]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.00 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[326.8545,  23.4858,  67.4727,   2.2819, 289.7393,   6.3933,  44.5763,\n",
      "         111.2270,  83.7308,  37.3721]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.02 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[654.9431, 102.1159,   7.3708,  37.9969, 911.7274, 380.1206,  48.8893,\n",
      "          24.7174, 150.5925,  55.3860]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.02 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[ 433.6385,   90.9690,   53.1354,   31.3014, 1489.8130,  261.4900,\n",
      "           53.9616,   71.6357,  157.6141,   34.9460]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 0.00 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[ 534.8168,   89.8412,  109.6420,   29.3177, 1384.3111,  755.8697,\n",
      "           45.7674,  140.6128,  120.1452,   79.5351]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 9 took 0.01 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[642.1647, 117.8510,  60.5108,  27.0524,  81.8231, 272.9195,  57.2862,\n",
      "         118.9017,  94.4505,  58.1111]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.02 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[ 51.4727, 104.0890,  19.9795,  24.5945, 228.3897, 242.4464,  47.2759,\n",
      "          60.2920, 126.1807,  53.5719]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.00 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[925.4459, 106.1162, 114.7619,  48.1666, 115.4879, 157.9025,  56.9102,\n",
      "         126.5760,  28.2624,  59.5658]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.01 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[1084.1899,   94.5290,   76.5478,   31.8710,  921.2177,  483.2435,\n",
      "           53.5425,   42.8656,  138.5729,   26.3867]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 0.00 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[922.5600,  53.2117,  89.5681,  27.8003, 757.0172, 564.5598,  43.6113,\n",
      "          48.4009, 136.3895,  37.8051]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[ 125.9572,  105.6076,   85.4234,   35.2927, 1032.1971,  154.3583,\n",
      "           52.0181,   95.8389,  111.0843,   59.5205]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 0.02 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[9.4112e+02, 8.4828e+01, 7.2603e+01, 6.3746e-01, 1.4655e+03, 7.2867e+02,\n",
      "         4.8650e+01, 5.4333e+01, 1.5083e+02, 8.0346e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.00 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[ 597.2991,   40.6160,   71.0190,   34.0231, 1244.4862,   50.2993,\n",
      "           59.5470,   54.2421,  148.0471,   59.1004]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 17 took 0.01 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[144.9302,  49.0043,  26.4808,   8.1046,  37.6491, 254.9402,  40.2938,\n",
      "          48.9365, 151.6625,  20.9599]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.02 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[553.7500,  63.4179, 115.9668,   6.5627, 543.0676, 501.0984,  58.7230,\n",
      "          33.9196,   4.1353,  13.0277]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.00 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[635.9476,  89.1330,  11.5477,  14.5110, 492.4699, 340.9259,  42.2238,\n",
      "         154.1854, 125.6935,  21.0569]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.02 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[5.5702e+02, 2.9884e+01, 2.3862e+01, 1.0657e-01, 9.3922e+02, 7.4082e+02,\n",
      "         4.0119e+01, 7.5546e+01, 6.7189e+01, 4.9439e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 0.00 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[ 32.2772,  76.7213,  40.5721,  27.0046, 284.2666, 721.6550,  55.8402,\n",
      "          16.2429,  42.8726,  49.8288]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.01 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[ 724.5995,   41.2089,   29.4418,   17.5773, 1280.3213,  685.8799,\n",
      "           40.9914,   50.4457,   60.7686,    3.6540]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 0.00 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[872.0343,  26.4598,  44.1873,  44.8508, 956.0580,  67.2209,  44.7507,\n",
      "          13.1943,  57.9091,  60.4116]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.02 seconds\n",
      "最优点: [0.5482812523841858, 1.1647224426269531, 1.3018571138381958, 1.3018571138381958, 1.373915672302246, 1.3752014636993408, 1.3752014636993408, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.396803617477417, 1.396803617477417, 1.396803617477417, 1.396803617477417, 1.396803617477417]\n",
      "tensor([[ 547.3569,   38.0727,   60.1823,   37.9726, 1040.6443,  454.3831,\n",
      "           45.9063,   47.0072,  155.1902,    6.0158],\n",
      "        [1163.5620,   85.9983,   10.9697,    6.3130,  208.3722,  252.0922,\n",
      "           52.7241,  119.9556,   69.3667,   31.0125],\n",
      "        [ 389.2540,   54.6448,   81.5249,   10.0315,  304.4839,   13.5940,\n",
      "           49.5706,  143.4570,   56.3740,   33.7693],\n",
      "        [ 889.4371,    2.0476,   46.4158,   45.2090, 1289.6214,  782.3115,\n",
      "           43.2765,    8.4146,   27.4706,   55.5637],\n",
      "        [   3.6169,  103.0557,  112.6425,   26.9236,  620.0339,  626.7435,\n",
      "           58.3072,   83.7438,  113.7085,   66.7706]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 736.9933,   11.8233,  108.0107,   19.8456, 1030.8085,  672.0145,\n",
      "           56.3802,   48.6215,  105.0072,    7.6896]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 0 took 0.02 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[601.9323, 100.9468,  10.1529,  19.0172, 623.1869, 645.2479,  47.8289,\n",
      "          11.9689, 128.1998,  65.4097]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.02 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[873.6989,  55.1458,  46.7813,  32.3838, 903.7235, 417.4050,  58.8631,\n",
      "         155.8961,  22.0397,  51.7346]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.00 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[1028.1321,    5.3147,    8.1620,    8.6128,  307.8336,  350.3634,\n",
      "           55.4290,   26.3500,   67.4824,   30.7178]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 0.01 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[711.0530, 107.4576,  49.0122,   7.5241, 275.4042, 391.1569,  42.1034,\n",
      "          93.4751,  35.3014,  29.8509]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.00 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[950.1451,  80.5429,  72.6743,  42.9771,  38.6677, 444.7338,  52.9176,\n",
      "         121.7947,  85.6848,  27.7361]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.02 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[ 114.1780,  103.3798,   55.5275,   23.3643, 1410.4257,  494.8582,\n",
      "           53.1266,  121.3359,   99.6144,   39.0462]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 0.02 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[ 576.7860,    5.1925,  119.2972,    9.5094, 1021.8797,  698.4348,\n",
      "           59.0475,  115.1664,   71.4197,   70.1773]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 7 took 0.00 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[352.4722,  12.4657,   3.6578,  11.2443, 259.4912, 487.5044,  42.0314,\n",
      "          84.6000,  60.5234,   6.0780]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.01 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[379.7321,  40.6334,  13.9515,  19.0838, 729.1847, 465.8025,  46.6352,\n",
      "          55.2449, 130.7881,  71.6092]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.02 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[545.2547,  92.8733,  79.4198,  24.0484, 418.4666, 318.6073,  44.1250,\n",
      "         137.6301, 120.4759,  55.1209]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.00 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[501.3343,  50.1098, 119.9515,  36.8623, 907.6036, 131.5145,  53.4930,\n",
      "          46.8081, 155.9160,  47.8125]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 11 took 0.01 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[ 193.2126,   35.5641,   62.8982,   25.4569, 1264.5486,  616.6213,\n",
      "           49.9204,   95.8297,  147.6649,   55.0651]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 0.02 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[577.0931,  51.3761,  52.0732,  37.2268, 682.2049, 315.9814,  59.7880,\n",
      "          78.8412, 154.1108,  29.4111]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 0.00 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[ 579.6537,   47.5892,   39.8096,   24.7349, 1032.9338,  222.1050,\n",
      "           55.0387,   26.9421,  132.9633,   48.8503]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[188.3213,  69.6836,  60.7555,  40.0652, 565.4458, 507.2755,  48.9580,\n",
      "         143.1527, 154.0639,  41.1809]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.00 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[506.3131,  53.5862, 114.2370,  32.1270, 110.2887, 687.7129,  53.4694,\n",
      "         151.6381, 145.5459,  49.6325]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 0.01 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[317.6438,  51.1734,  71.1819,  12.5869, 998.9707, 361.5858,  55.9187,\n",
      "          84.3022,  65.2755,  51.8309]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.02 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[627.8323,  68.1067,   2.5117,  28.9037, 741.5182, 294.9521,  59.7680,\n",
      "           6.0097,  95.5616,  64.4629]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.00 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[871.8394,  11.3162, 110.0631,   2.3520, 995.0975, 653.6594,  46.7792,\n",
      "          21.9440,  75.9268,  10.8301]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[1084.6688,  115.2035,  118.1047,   19.9412,  214.4622,  233.6812,\n",
      "           40.4242,   83.5967,   50.5759,   16.0656]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 0.00 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[1133.6904,   57.4786,   30.4659,   40.1196,  259.9927,  380.4367,\n",
      "           47.6434,  109.8162,    3.9434,   44.4007]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 0.01 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[ 939.5044,   11.8396,  110.0822,   31.3640, 1266.1275,  427.4620,\n",
      "           59.7983,    4.5540,   50.5904,   79.8063]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 22 took 0.00 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[1022.3893,   74.0659,   75.0184,   49.7251, 1006.7970,  409.4617,\n",
      "           40.1391,  120.4670,  126.4967,   21.7227]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 0.02 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[651.9386, 116.5815,  38.4869,  45.9843, 929.4530, 735.9825,  46.0600,\n",
      "         154.7014,  43.6506,  51.3640]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.01 seconds\n",
      "最优点: [0.8368469476699829, 1.3429807424545288, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635]\n",
      "tensor([[ 914.7043,   82.1421,   61.8879,    9.9604, 1346.2526,  567.2145,\n",
      "           48.6582,  108.1504,  158.4852,    7.5322],\n",
      "        [ 979.9479,  110.2786,   13.2338,   27.5651,  368.4147,  703.9019,\n",
      "           58.0294,   19.0276,   87.2698,   75.8688],\n",
      "        [ 709.0247,   16.8244,  118.3119,   36.2862, 1094.6749,  332.5568,\n",
      "           44.3375,   33.1154,   32.9056,   38.3932],\n",
      "        [ 424.7162,   55.8630,   41.0722,   49.2777,  785.5033,  192.1765,\n",
      "           52.2540,   70.4142,   12.3291,   48.2776],\n",
      "        [   6.0071,   41.5809,   91.8022,   16.6113,   34.2355,   16.8910,\n",
      "           43.8782,  159.1980,  102.4770,   18.0643]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[1102.9686,   54.6360,   25.0634,    1.3180,  582.4663,  262.5365,\n",
      "           51.8987,   74.3968,   47.0016,   69.9793]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 0 took 0.02 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[656.2391,  26.8615,  10.3045,  48.3160, 854.8778, 280.3201,  51.6173,\n",
      "          99.2193,  51.2041,  26.9998]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.00 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[1151.4809,   82.7855,   22.2010,   41.6237, 1140.7360,  791.1349,\n",
      "           57.5368,  152.0796,  124.7163,   62.0270]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 2 took 0.01 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[1150.3028,   12.4098,   65.0043,   39.6581,  723.3881,  313.6524,\n",
      "           52.5961,   86.9684,  140.3220,    2.0198]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[1.2646e+01, 1.4878e+01, 5.5746e+01, 9.2425e-01, 1.3763e+03, 1.8261e+02,\n",
      "         5.6214e+01, 1.7242e+01, 6.3927e+01, 3.8852e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 4 took 0.02 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[7.0510e+02, 6.8561e+01, 7.5871e+01, 8.5015e+00, 6.1005e-01, 1.0823e+02,\n",
      "         4.3164e+01, 4.1998e+01, 1.1065e+02, 3.8626e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 0.02 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[1.1755e+03, 5.8352e+01, 1.0553e+01, 5.5469e-01, 1.3914e+03, 5.4223e+02,\n",
      "         4.3819e+01, 1.0197e+02, 5.9607e+01, 4.1136e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 0.00 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[901.4640,  35.2483, 103.1913,  27.2988, 316.0617, 259.8896,  52.4025,\n",
      "          28.7303,  51.5171,   7.1824]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.01 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[754.5493, 116.7651,  62.6582,  25.4534, 243.7699, 688.9240,  47.1991,\n",
      "          62.2536,  76.2068,  53.9005]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.02 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[169.5654, 115.2162,  92.2009,  13.2597, 440.7521, 130.2023,  50.9485,\n",
      "          67.4478, 128.6270,  24.9096]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.00 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[1060.8919,   13.7940,   65.4060,   20.5541,  804.7095,   59.9654,\n",
      "           45.9916,   22.2168,   72.1408,   26.1706]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 0.01 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[ 193.6510,   60.7527,  101.6289,   19.3262, 1141.2350,  445.8661,\n",
      "           49.8156,   69.3642,  124.8434,   45.1936]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 0.00 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[909.9792, 111.7003,  44.8105,  17.9874, 227.0883, 665.7414,  46.2172,\n",
      "         152.1995, 125.6209,  73.0205]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.02 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[203.0077,  44.0784,  55.3809,  46.4231, 885.7774, 345.3131,  42.2613,\n",
      "          85.4218,  70.8415,  67.9316]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 0.02 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[9.1491e+02, 1.1158e+00, 6.0297e+01, 7.2054e-01, 1.1317e+03, 7.7432e+02,\n",
      "         5.1670e+01, 5.9551e+01, 1.0570e+02, 1.8783e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 14 took 0.00 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[ 615.8869,   55.2050,    9.8352,   13.0946, 1077.5973,  177.7398,\n",
      "           44.9053,    7.7608,   82.3018,   59.0047]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 0.01 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[ 196.9445,   24.5438,   79.2959,    2.0870, 1226.4818,   94.0852,\n",
      "           58.3533,   97.0124,   64.3924,   17.6207]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.00 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[686.8752,  45.2747,   9.7511,  27.9092, 573.0774, 251.2799,  42.2846,\n",
      "         112.3797,  58.4845,  67.0691]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.02 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[525.0152,  70.8915,  11.5202,  30.4306, 932.7781, 262.5586,  52.7894,\n",
      "          35.1931,  58.0830,  39.4247]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.02 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[ 337.5355,   94.5094,   15.9097,   39.0327, 1059.6847,  212.3270,\n",
      "           40.2776,   13.5337,    3.5425,    1.9029]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 0.00 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[960.3165,  96.3134,  14.8605,  31.9473, 498.0674, 388.1983,  45.6279,\n",
      "          84.0373,  77.3584,   8.8628]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.01 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[143.4538,  30.8341, 116.6701,  42.0449,  95.2545, 632.8270,  52.2530,\n",
      "         101.9795, 139.5666,   4.6994]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.00 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[588.5034,  49.3036,  50.7660,  35.7424, 629.0212,  25.3717,  45.4498,\n",
      "         148.0689,  49.7277,   3.1997]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.02 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[967.9341, 110.7798,   5.7046,  35.9492, 843.0752, 523.1684,  43.9463,\n",
      "          16.1545,  36.5549,  74.3727]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.00 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[795.9630, 105.1980,  43.9787,  33.9015, 458.1150, 539.9382,  57.9826,\n",
      "          15.1652,  34.3249,  27.9166]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.01 seconds\n",
      "最优点: [1.334948182106018, 1.334948182106018, 1.334948182106018, 1.334948182106018, 1.36324942111969, 1.36324942111969, 1.36324942111969, 1.36324942111969, 1.36324942111969, 1.36324942111969, 1.36324942111969, 1.36324942111969, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601]\n",
      "tensor([[9.4750e+02, 7.7545e-01, 6.0536e+01, 3.8217e+01, 7.2452e+01, 7.9341e+02,\n",
      "         4.2729e+01, 1.0026e+01, 9.5903e+01, 7.9397e+01],\n",
      "        [1.0088e+03, 1.1533e+02, 1.1120e+02, 2.5541e+01, 1.4547e+03, 6.3394e+01,\n",
      "         5.6142e+01, 5.7252e+01, 1.3649e+02, 4.2252e+00],\n",
      "        [4.2717e+02, 6.0320e+01, 7.8267e+01, 4.9506e+01, 1.1166e+03, 2.0277e+02,\n",
      "         4.8581e+01, 1.4641e+02, 4.7327e+01, 5.5236e+01],\n",
      "        [2.4937e+01, 7.9235e+01, 1.2676e+01, 1.0531e+01, 5.1092e+02, 5.9960e+02,\n",
      "         5.5288e+01, 1.0209e+02, 3.7308e+00, 4.0807e+01],\n",
      "        [6.8607e+02, 3.4026e+01, 2.9664e+01, 9.8885e-01, 8.9639e+02, 3.2133e+02,\n",
      "         4.4546e+01, 6.7681e+01, 1.0311e+02, 2.3994e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[525.1571,  99.1222,  22.2820,  11.6909, 293.5096, 660.3402,  41.8242,\n",
      "          38.5289,  26.2208,  34.9537]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.02 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[650.8326,  10.7019,  92.8240,  39.5928, 269.0079, 102.7755,  51.8311,\n",
      "         115.4611,  81.8731,   4.0764]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.01 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[ 92.1847, 118.1991,  64.9587,  24.4462, 836.3676,  36.8465,  54.8529,\n",
      "          56.9635,  36.1568,  36.1515]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.02 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[232.5819,  88.2126,  90.7586,  28.1897, 420.3350, 431.8238,  41.2701,\n",
      "          62.0208,  78.1808,  40.3465]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[929.7552, 109.0542,  52.7134,  30.0854, 505.0817, 164.2075,  58.2331,\n",
      "         134.5724,  17.1320,   3.1736]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.02 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[1081.0990,  101.6024,   95.8375,    4.2203,  677.6818,  137.3655,\n",
      "           45.7529,  135.6304,   50.0370,   36.0489]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 0.01 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[393.0575,  76.6710,  50.3484,  19.4277, 462.2232, 579.9884,  52.3908,\n",
      "         112.0548,  28.9441,  19.9343]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.00 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[223.1145,  68.1303,  46.0892,   6.0263, 272.1182, 644.1433,  58.8272,\n",
      "         147.2184,  27.7937,  20.4600]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.02 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[415.2364,  46.8963,  69.2351,   3.6713, 138.2685, 671.6555,  40.8929,\n",
      "          37.3991,  31.2104,   3.9591]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.01 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[1175.4365,    3.6001,   89.6224,   24.1705,  891.4970,  194.1920,\n",
      "           42.9499,   16.1659,   95.8129,   15.1494]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 9 took 0.00 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[867.5855,  70.2033,  55.0042,  46.3188, 917.4599, 364.0702,  40.7797,\n",
      "         119.2816,  87.2747,  40.7346]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.02 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[1007.9722,  108.7478,  110.3996,   19.6816,  577.4314,   21.5604,\n",
      "           42.4473,  100.6709,   96.6511,    3.4177]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 0.00 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[9.9315e+02, 1.1713e+01, 2.3703e-01, 3.5210e+01, 1.7406e+02, 4.8304e+02,\n",
      "         4.4633e+01, 1.3209e+02, 5.6905e+01, 4.4162e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 0.02 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[713.1559,  12.5389,  57.2494,  41.4020, 573.4791, 710.4218,  57.3372,\n",
      "         135.3408, 121.1644,  72.0323]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 0.01 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[802.4503,  97.0071,  23.3212,  46.7157,  15.9259, 284.0398,  46.8489,\n",
      "          20.7746, 102.4165,  55.2602]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[1064.1213,   95.4668,   76.1986,   44.3938,    1.9820,    4.5000,\n",
      "           46.1460,   29.4182,  153.4125,   28.5803]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 0.00 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[1112.5626,   48.0048,   27.7407,   33.0865, 1310.7873,   33.4467,\n",
      "           56.7076,  105.5224,   77.4524,   35.9894]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.02 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[725.5963,  56.2820,  10.4190,   5.9210, 947.2273, 498.3094,  56.7957,\n",
      "          37.7017,  32.4180,   3.0236]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.01 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[ 691.4308,   40.7719,   68.2864,   39.3558, 1396.9439,  719.3621,\n",
      "           41.0590,  154.9243,  145.5485,   22.4757]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 0.00 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[1045.8304,   88.8487,   76.5327,   23.2967,  290.9541,  745.1588,\n",
      "           49.7291,  137.4945,  111.2864,   12.5276]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[ 622.3651,   44.7644,  100.8295,   40.0619, 1099.0079,  371.0413,\n",
      "           56.4146,   24.4091,  149.6734,   59.0952]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 0.01 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[ 443.7284,  114.6941,  119.7353,   14.5548, 1467.7053,  285.5998,\n",
      "           55.6361,  137.2978,   92.0139,   13.6466]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 0.00 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[1052.1929,   43.7634,   58.1608,   17.5592,  579.9827,  681.1453,\n",
      "           53.5562,   96.7340,   31.0804,   73.7138]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 22 took 0.02 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[378.8916,  94.6626,  75.1377,  29.5190, 394.8921, 380.8274,  40.5971,\n",
      "         130.7776,  34.7136,  70.8317]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.02 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[821.6357,  39.7838,  31.7482,  47.0298,  53.7627,  22.5859,  44.3685,\n",
      "         102.0649, 115.4372,  29.3788]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.00 seconds\n",
      "最优点: [0.7983927726745605, 1.316449761390686, 1.316449761390686, 1.316449761390686, 1.3588625192642212, 1.3588625192642212, 1.3588625192642212, 1.3588625192642212, 1.3588625192642212, 1.3588625192642212, 1.3689944744110107, 1.3689944744110107, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3786884546279907, 1.3786884546279907, 1.3786884546279907, 1.3786884546279907, 1.3786884546279907, 1.3786884546279907]\n",
      "tensor([[ 625.5411,   91.9332,  102.5055,   24.0934,  637.7751,  369.6839,\n",
      "           42.4580,   62.8682,   89.4630,   62.8593],\n",
      "        [ 371.0605,  105.8830,   53.4186,   41.1224, 1099.1133,  270.9374,\n",
      "           47.5623,  110.9463,   20.5058,   77.9982],\n",
      "        [1194.9187,   54.6129,   13.8380,   14.5143,   77.2897,   92.7323,\n",
      "           53.5033,  155.9066,  114.9364,   17.9023],\n",
      "        [ 105.1807,   21.0701,   25.6617,   38.7647,  342.3012,  609.7560,\n",
      "           59.4881,   86.8070,   53.1951,   38.3035],\n",
      "        [ 742.5605,   42.4066,   93.9557,    6.4974, 1378.0241,  744.8134,\n",
      "           49.6293,    2.3166,  141.8182,   12.5931]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[713.4606,  48.0692, 109.8128,   3.5656, 694.6517, 240.4590,  47.6119,\n",
      "         156.4416, 149.8484,  34.5981]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.02 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[1101.6510,   87.8377,   82.6626,   11.3544,  415.1027,  260.2652,\n",
      "           41.1133,   92.6952,   58.2462,   10.2103]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 0.00 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[267.9612,  26.8900,   5.3141,   2.5665,  49.4834, 652.8659,  42.3902,\n",
      "         105.1247, 101.8403,  77.7248]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.01 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[1039.3671,  107.1716,  101.7767,   21.2588,  489.5848,  381.8382,\n",
      "           42.6536,   90.0502,   63.6264,   72.2562]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 0.02 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[778.1617,  99.7897, 113.9531,  42.5760, 378.3880, 197.6447,  41.4510,\n",
      "          82.4781,  16.8473,  21.7426]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.00 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[6.5367e+02, 2.8805e+01, 1.1576e+02, 2.9740e+00, 4.6909e+02, 6.5681e+02,\n",
      "         5.5965e+01, 3.5979e+01, 5.6956e-01, 8.4786e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 5 took 0.01 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[  54.1708,  100.0002,    9.5249,   20.9801, 1016.9155,  190.7843,\n",
      "           45.1211,   16.2553,   88.1704,   52.9545]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 0.00 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[ 205.1994,   59.6362,   30.5908,   21.4264, 1210.8934,  721.8082,\n",
      "           54.4815,  128.8846,  153.0797,    5.5392]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 7 took 0.02 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[ 344.0591,   22.5594,   28.3955,   26.0740, 1464.0617,  286.8555,\n",
      "           47.8334,   32.8717,   31.1002,   27.1097]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 0.02 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[  70.3271,   93.5623,  113.4671,   24.7525, 1418.4121,  690.2508,\n",
      "           55.6761,  133.8022,   43.1989,   65.1603]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 9 took 0.00 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[6.6800e+02, 7.0306e+01, 4.5182e+01, 1.1432e-01, 1.0367e+03, 4.2407e+02,\n",
      "         5.6862e+01, 1.1927e+02, 1.1562e+02, 1.3283e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 0.01 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[ 669.3143,   22.8518,   87.7584,   15.6718, 1333.8695,  690.6419,\n",
      "           40.3660,  158.1613,   45.1255,   13.8908]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 0.02 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[551.1933,  24.3652,  27.7830,  33.4456, 861.3632, 281.1955,  41.5543,\n",
      "          85.7609,  34.1114,  18.4435]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 12 took 0.00 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[ 124.7783,  100.4327,   77.1964,   28.8632, 1337.9212,  113.2412,\n",
      "           45.7761,   71.9553,  118.6260,   73.9332]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 0.02 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[242.4516,  97.4898,  51.3199,  21.6445, 304.6794, 349.1471,  49.4068,\n",
      "         105.5102, 110.8685,  58.2353]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.01 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[113.0739, 109.3695,  47.3154,  46.8067, 264.7457, 616.6981,  43.2230,\n",
      "         153.8296, 121.6520,   9.4418]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.02 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[ 728.4919,  103.0588,   77.2254,   28.1275, 1494.3576,  509.3707,\n",
      "           59.0662,  151.9608,   88.4215,   44.6512]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 16 took 0.00 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[999.7451,  28.6491,  24.1296,  25.0378, 387.0525, 630.2533,  47.6697,\n",
      "         140.1637, 105.9303,  67.3966]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.01 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[ 771.2858,   42.7409,    4.1881,   48.8747, 1265.5826,  797.0075,\n",
      "           59.6575,   30.3021,   25.2452,   34.9155]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 0.00 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[ 208.7526,  106.5103,   11.1022,   30.4541, 1086.3256,  749.6250,\n",
      "           43.7538,  148.0422,   37.4795,   77.9593]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[524.9800,  46.3505,  47.6608,  21.6618, 751.8838, 180.2324,  46.7392,\n",
      "          19.6012,  35.8451,  44.2576]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.02 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[  6.5571,  55.6534, 112.3068,  26.2093, 886.7086, 220.3335,  53.1155,\n",
      "          24.5631,  62.5460,  78.7342]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.00 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[ 400.0231,   13.3420,   28.3343,   29.6740, 1039.2063,  673.6171,\n",
      "           43.8417,   11.4146,  129.7289,   44.5072]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 22 took 0.01 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[  51.2528,    7.0078,   61.0185,    1.8219, 1040.4989,  253.0279,\n",
      "           59.0500,  137.1490,   24.3267,   64.6730]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 0.02 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[ 22.9211,   8.2816,  88.2047,  23.6774, 774.2072,  67.8683,  57.3703,\n",
      "         108.7488, 129.2066,  41.1037]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.00 seconds\n",
      "最优点: [1.0059646368026733, 1.0059646368026733, 1.3668502569198608, 1.3668502569198608, 1.3668502569198608, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422]\n",
      "tensor([[ 987.6512,   41.8686,  113.4154,   20.3207,  182.7922,  502.8077,\n",
      "           46.5494,  121.8106,  102.6978,   17.2765],\n",
      "        [ 226.9345,   50.3267,   56.4120,   10.6238, 1485.6732,  176.5448,\n",
      "           55.9277,  138.0489,   51.5601,    6.2047],\n",
      "        [ 622.8346,    2.0265,   29.9018,   38.9040,  796.9768,  734.7319,\n",
      "           50.1252,   18.9593,   70.0085,   59.6884],\n",
      "        [ 846.3444,   76.5192,   85.5081,   43.8281, 1041.5834,  450.8475,\n",
      "           41.7476,   71.3654,   28.4840,   47.9377],\n",
      "        [ 261.4053,   96.1098,    9.6583,    8.6725,  301.5117,  119.3752,\n",
      "           56.9518,   38.8579,  140.4444,   75.1685]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[ 988.9112,   58.2251,   38.8096,   22.6624, 1376.2027,   19.3782,\n",
      "           42.0247,  103.5575,   51.1900,    8.0499]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 0 took 0.01 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[1064.1002,  116.0043,   33.9515,   43.5421, 1166.5497,  263.2853,\n",
      "           49.9788,  106.5484,   76.4268,    4.8319]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 1 took 0.02 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[ 454.2251,   86.2164,   13.3600,   26.7702, 1046.7326,  474.6396,\n",
      "           51.5454,  134.2529,  123.2430,   65.5244]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 2 took 0.01 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[ 495.7459,   45.7896,   33.7818,   31.9434, 1076.2445,  493.9657,\n",
      "           54.0590,   82.6831,  158.7334,   29.6626]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 0.00 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[  82.4252,    7.7034,   73.3114,    3.2384, 1179.7559,  559.7336,\n",
      "           42.9625,   92.4917,   74.8686,   65.2662]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 4 took 0.02 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[895.3822,  26.9228,  73.1689,  46.1601, 511.5157,  89.7484,  40.3439,\n",
      "         126.0333,  38.0333,  16.9310]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.02 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[473.4607,  51.8050,   4.2507,  25.3488, 315.8526, 647.7244,  56.4530,\n",
      "          74.7143,  36.3520,  64.0671]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 6 took 0.00 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[ 251.6562,   44.6419,   79.3764,   14.4784, 1297.0489,  275.7475,\n",
      "           46.2729,   19.1452,   33.7843,   74.1433]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 7 took 0.01 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[  79.5867,   72.3579,  104.1329,   37.3342, 1246.8140,  777.9911,\n",
      "           43.5002,   12.4196,  108.0653,   67.9982]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 8 took 0.06 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[954.4529,  26.0812,  44.7222,   6.6307, 359.9953, 419.1913,  56.6603,\n",
      "         151.0185, 140.3632,  34.6360]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.03 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[750.9415,   3.3487,  75.5194,  37.3080, 100.8768,  34.7148,  45.0962,\n",
      "         102.1463, 104.4204,  55.6911]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.02 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[1057.9211,    6.0371,   61.4801,   21.1062,  910.2559,  613.9753,\n",
      "           59.3373,   66.3721,  107.6220,   73.1985]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 0.00 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[1146.8688,   19.7859,   54.0003,   37.0977,  899.1286,  158.1230,\n",
      "           44.5432,   63.4551,   45.9229,   52.8399]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 0.01 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[ 446.5149,   19.7806,   92.5168,   20.6637, 1048.7996,  196.2598,\n",
      "           58.1445,  117.7130,   49.4757,   22.0849]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 0.00 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[171.0949,  31.1274,  55.3302,  13.9039, 311.0379, 600.8050,  40.4469,\n",
      "          49.8112,  47.1247,   7.6618]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 14 took 0.02 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[8.9252e+01, 2.2234e+01, 8.9220e+01, 1.8865e+01, 2.8177e+02, 7.7988e+02,\n",
      "         4.5105e+01, 1.0966e+01, 6.5761e-02, 4.0361e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 15 took 0.02 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[440.9293,  68.4003,  11.9241,  33.0465, 585.4787, 355.1027,  42.7042,\n",
      "          77.1530,  28.6163,   5.5656]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 0.00 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[ 38.4179, 111.8200,  98.3387,  17.1476,  35.5781, 434.6447,  43.0837,\n",
      "         107.8006, 121.9283,  25.2327]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.01 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[ 643.0703,   10.5189,   84.2366,   39.1075, 1139.6170,  519.8239,\n",
      "           45.4366,  134.2141,   43.6505,   47.4140]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 0.02 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[ 760.9490,   27.5784,   83.8915,   15.8522, 1251.8216,   54.0529,\n",
      "           52.1772,  105.6885,   28.3293,   72.9468]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 19 took 0.00 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[374.8336,  63.4958,  27.9294,  24.9649, 714.5779,  26.9632,  44.7320,\n",
      "         108.8954,  32.4376,  48.4777]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.01 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[331.9345,  66.3347,  95.3584,  33.7645, 794.0910, 443.1300,  40.3139,\n",
      "          60.1967, 101.4125,  63.8068]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.02 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[125.2021,  66.0254,  23.9840,  32.7667, 947.3266, 586.0051,  43.7580,\n",
      "          72.3010,   7.0952,   1.9902]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.02 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[568.7906,  17.4699,  93.3913,   2.3803, 426.2390, 501.9934,  55.9658,\n",
      "          95.2798,  34.9542,  28.5053]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 23 took 0.00 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[ 86.7049,  47.8231,  33.2257,   8.7800,  35.0774,  53.1284,  54.6954,\n",
      "          17.2759, 101.5543,  42.0301]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.01 seconds\n",
      "最优点: [1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481]\n",
      "tensor([[4.5691e+02, 3.1639e+01, 3.2027e+01, 2.7663e+01, 1.3458e+03, 5.2273e-01,\n",
      "         4.6678e+01, 5.5192e+01, 5.3158e+01, 6.8727e+01],\n",
      "        [1.1021e+03, 1.0023e+02, 5.8323e+01, 5.4869e+00, 7.8374e+02, 5.4001e+02,\n",
      "         4.8450e+01, 1.3725e+02, 1.5299e+02, 5.3882e+01],\n",
      "        [6.2608e+02, 2.2179e+01, 1.1657e+02, 4.9718e+01, 6.5677e+01, 4.0855e+02,\n",
      "         4.3344e+01, 2.3831e+01, 6.4922e+01, 9.0752e+00],\n",
      "        [2.2337e+02, 5.1176e+01, 1.2982e+01, 1.0105e+01, 5.6733e+02, 3.1208e+02,\n",
      "         5.8630e+01, 1.2568e+02, 1.0763e+02, 3.5898e+01],\n",
      "        [9.5454e+02, 8.7524e+01, 7.5685e+01, 3.2301e+01, 1.1763e+03, 7.8687e+02,\n",
      "         5.4795e+01, 6.6771e+01, 1.4040e+01, 1.9904e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[285.1363,  13.8685,  65.4959,  41.2931, 775.9734,  49.9401,  59.7450,\n",
      "          94.2362, 113.4296,  29.2654]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 0 took 0.02 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[597.6195,  16.4342,  68.3613,  36.2164, 672.0722, 651.5199,  53.0523,\n",
      "         107.9027, 135.8533,  69.3719]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.00 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[1146.6370,   66.0539,   37.7382,   45.4306,  282.2134,  446.9752,\n",
      "           50.5374,  138.2215,   92.0201,   33.4344]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 2 took 0.01 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[796.3279, 101.6577,  72.6435,   6.1881, 389.2404, 559.5450,  42.9198,\n",
      "         100.1313,  74.4074,   8.9542]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 3 took 0.02 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[620.3691,  45.4112,  33.6455,  22.3463, 727.7056, 333.7928,  56.6230,\n",
      "           2.1913, 156.5835,  59.0627]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.01 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[247.2282,  41.8701,  64.8733,  23.3557, 922.6267, 474.7238,  45.9856,\n",
      "          72.2978, 135.1149,  17.1377]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.00 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[ 924.9797,   39.2102,   65.6700,   14.9736, 1302.9315,  262.8271,\n",
      "           44.0911,    7.4837,  122.3931,   57.6560]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 0.02 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[1162.9113,  113.5518,   28.9142,   44.4170,  147.3081,  557.5388,\n",
      "           42.4555,   40.6418,  110.3234,   34.7498]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 7 took 0.00 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[661.1228,  29.7051,  93.2293,  13.6426, 442.9404, 614.3051,  46.0911,\n",
      "          64.7243,  81.4169,  50.6296]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.02 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[272.3583,  87.2313, 111.7345,   4.7884, 685.2201, 631.2460,  43.9374,\n",
      "          62.3690, 154.3721,  58.9215]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 9 took 0.01 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[ 249.1705,   13.9187,   64.1164,   20.7285, 1092.4478,  660.1270,\n",
      "           59.3037,   57.9417,   71.9885,   64.7206]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 10 took 0.00 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[1015.5836,   80.9003,   50.5779,   41.0997, 1005.9026,  418.9828,\n",
      "           46.7071,  132.1739,  104.2378,   14.9573]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 0.02 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[ 727.4899,   62.9523,   51.8356,   23.4369, 1163.6231,  153.3672,\n",
      "           51.7976,   66.6712,   52.8981,   65.9899]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 0.00 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[ 596.1558,   79.8166,   70.9757,   10.0965, 1419.1053,   15.3035,\n",
      "           43.1245,   68.2443,  127.6807,   34.9100]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 13 took 0.02 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[ 927.8534,   10.2547,    7.4594,    5.8774, 1362.9309,  768.5584,\n",
      "           41.3776,   51.1404,   98.2415,   10.9714]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 14 took 0.01 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[333.9801, 113.9237,  31.9195,  34.8049, 969.5843, 119.1827,  46.9245,\n",
      "           7.7591, 154.0610,  78.1735]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.00 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[677.3799,  98.9827,  17.2739,  19.8157, 167.3613, 496.9491,  54.7815,\n",
      "         135.0122, 153.0156,  24.2474]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 0.02 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[498.7656,  18.4667,  30.3283,  35.6498, 509.7889, 473.0927,  56.5155,\n",
      "          33.1625,  34.6624,  15.0490]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.00 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[ 344.7048,  100.1813,   45.3306,   40.2198, 1312.0875,  332.2582,\n",
      "           50.7320,   66.2913,   69.0208,   72.0983]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 18 took 0.01 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[592.1358,  14.0498,  62.8719,  46.2911, 431.0775, 697.9644,  46.4144,\n",
      "          77.0815,  10.8863,  37.3657]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.02 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[ 525.6241,   84.4001,   75.2308,   39.1565, 1128.3104,  531.2492,\n",
      "           40.1219,  140.2335,  113.6041,   16.1859]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 20 took 0.00 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[241.3127,  46.2616,  82.0476,  44.3822,  53.3009,  73.7357,  45.2268,\n",
      "          48.8274,   8.9064,  63.1229]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 21 took 0.02 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[164.6454,  31.9877,  26.0467,   8.9649, 280.3483, 431.3512,  50.1040,\n",
      "         157.1761,   7.8819,  45.2732]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 22 took 0.01 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[1008.4108,   42.1411,   77.4344,   22.6032, 1022.1088,   57.5151,\n",
      "           40.9006,  117.3700,  100.2737,    5.8622]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 0.00 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[8.5853e+02, 6.1448e-01, 1.1521e+01, 1.4790e+01, 1.1493e+03, 5.7637e+02,\n",
      "         5.3570e+01, 1.1308e+02, 1.2887e+02, 4.0946e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 24 took 0.02 seconds\n",
      "最优点: [0.9835666418075562, 1.362736463546753, 1.362736463546753, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.3772218227386475, 1.3772218227386475, 1.3772218227386475, 1.3772218227386475, 1.3772218227386475, 1.3772218227386475, 1.3772218227386475, 1.3772218227386475, 1.3772218227386475]\n",
      "tensor([[1170.6131,   64.3107,  102.5111,   40.5598,  115.2125,  795.9924,\n",
      "           53.3099,  106.8716,   48.8236,   55.6144],\n",
      "        [ 410.3579,  104.4301,   78.5938,   32.4418, 1088.9482,  227.2145,\n",
      "           46.9380,   53.1690,  131.5680,    4.2844],\n",
      "        [ 826.7605,   19.5947,   67.9008,   12.6549,  875.4526,  464.8777,\n",
      "           57.9519,    6.2239,   11.9639,   43.6254],\n",
      "        [ 235.0614,   72.3651,   26.2975,   25.4826, 1302.7555,   27.2999,\n",
      "           49.3820,  141.7767,   74.7923,   74.5037],\n",
      "        [ 602.1662,   31.7005,    8.6152,    9.0585,  473.4931,  611.7447,\n",
      "           43.5309,   68.6333,   98.4403,   28.6432]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Nr. of optimization run: 0\n",
      "New candidates are: tensor([[1032.2208,   84.0258,   42.7333,   34.2628, 1395.9599,  680.3525,\n",
      "           56.9651,   64.6439,   20.8132,   39.4790]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 0 took 0.01 seconds\n",
      "Nr. of optimization run: 1\n",
      "New candidates are: tensor([[841.2031,  83.4594,  86.2882,  24.6168, 581.2028, 543.6934,  52.0485,\n",
      "         117.9022,  79.8221,  33.1818]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 1 took 0.02 seconds\n",
      "Nr. of optimization run: 2\n",
      "New candidates are: tensor([[550.1479,  82.1016,  89.0073,  42.5434,  54.5005, 481.8664,  59.9128,\n",
      "          20.2026,  19.9569,  55.8710]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 2 took 0.00 seconds\n",
      "Nr. of optimization run: 3\n",
      "New candidates are: tensor([[1127.4479,   47.0910,   98.7080,   32.6548,  981.8167,  591.5713,\n",
      "           42.3977,   20.9589,   21.4392,   30.9081]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 3 took 0.01 seconds\n",
      "Nr. of optimization run: 4\n",
      "New candidates are: tensor([[790.0020,  63.2107,  66.4759,  36.0236, 613.5641, 574.0616,  52.0739,\n",
      "         153.6284,  33.8429,  74.1114]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 4 took 0.00 seconds\n",
      "Nr. of optimization run: 5\n",
      "New candidates are: tensor([[537.1905,  16.1760,  41.6338,  48.2899, 969.8865, 533.0501,  58.3764,\n",
      "          80.9434, 153.0245,  40.7847]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 5 took 0.02 seconds\n",
      "Nr. of optimization run: 6\n",
      "New candidates are: tensor([[ 934.6845,   21.0990,   60.1761,    8.5532, 1340.7978,  118.6443,\n",
      "           55.9649,   60.9308,   36.7596,   65.2187]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 6 took 0.00 seconds\n",
      "Nr. of optimization run: 7\n",
      "New candidates are: tensor([[402.9382,  15.0201,  49.6969,  45.7111, 785.7160, 712.4369,  52.3489,\n",
      "         139.2941,  54.0375,  52.8010]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 7 took 0.02 seconds\n",
      "Nr. of optimization run: 8\n",
      "New candidates are: tensor([[ 55.6628, 100.7219,  59.4332,   2.5509,  28.9354, 782.4547,  43.6378,\n",
      "          77.1350, 118.2997,  75.0561]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 8 took 0.01 seconds\n",
      "Nr. of optimization run: 9\n",
      "New candidates are: tensor([[1.0044e+03, 6.7311e+01, 3.4551e+01, 5.5358e+00, 6.9752e+02, 5.1513e+02,\n",
      "         4.3476e+01, 1.0555e+02, 3.8542e+01, 6.1491e-01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 9 took 0.00 seconds\n",
      "Nr. of optimization run: 10\n",
      "New candidates are: tensor([[774.4733,  76.5565,  76.0042,   9.6259,  29.6125, 382.8914,  51.8957,\n",
      "         132.7770, 154.6865,  35.4715]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 10 took 0.02 seconds\n",
      "Nr. of optimization run: 11\n",
      "New candidates are: tensor([[ 876.5370,   40.8679,   47.1686,    3.5078, 1241.1619,  339.7995,\n",
      "           52.6064,  135.3766,   93.7367,    3.9203]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 11 took 0.02 seconds\n",
      "Nr. of optimization run: 12\n",
      "New candidates are: tensor([[ 803.9513,   32.8265,   29.5090,   17.2981, 1091.6169,  184.2638,\n",
      "           52.8726,   96.1913,   67.4929,   14.5257]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 12 took 0.00 seconds\n",
      "Nr. of optimization run: 13\n",
      "New candidates are: tensor([[662.9752,  41.3240,  13.7511,  11.2543, 661.6741, 674.3104,  41.2201,\n",
      "         127.1703, 142.6053,  67.1034]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 13 took 0.01 seconds\n",
      "Nr. of optimization run: 14\n",
      "New candidates are: tensor([[ 672.0310,   79.2225,  104.9636,   29.0312, 1288.2596,   15.3273,\n",
      "           58.0660,  149.5087,  113.2808,   15.1356]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 14 took 0.00 seconds\n",
      "Nr. of optimization run: 15\n",
      "New candidates are: tensor([[474.7784, 115.5840,  38.2028,  19.7088, 310.1244,  61.6487,  40.5309,\n",
      "          51.9139, 109.3677,  34.1751]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 15 took 0.02 seconds\n",
      "Nr. of optimization run: 16\n",
      "New candidates are: tensor([[532.1821, 114.7534,  51.9624,  25.7398,   1.8881, 191.9931,  45.5321,\n",
      "         152.2358, 129.0790,   6.6192]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 16 took 0.00 seconds\n",
      "Nr. of optimization run: 17\n",
      "New candidates are: tensor([[661.6377,  57.4251,  41.4897,  21.7442, 415.4651, 448.8624,  51.4271,\n",
      "           4.4758,  10.2044,  23.3064]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 17 took 0.01 seconds\n",
      "Nr. of optimization run: 18\n",
      "New candidates are: tensor([[981.5352,  64.6093,  35.2956,  11.1962, 494.6677, 519.9883,  54.1333,\n",
      "          50.3788, 128.0168,   9.4976]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 18 took 0.02 seconds\n",
      "Nr. of optimization run: 19\n",
      "New candidates are: tensor([[541.4683,  65.0407,  67.1761,  19.1773, 161.8986, 595.5035,  59.7539,\n",
      "          95.4017, 120.2045,  37.0302]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 19 took 0.00 seconds\n",
      "Nr. of optimization run: 20\n",
      "New candidates are: tensor([[304.2264,  32.0603,  77.2629,  29.0889, 894.6045, 334.3836,  56.1554,\n",
      "          45.6248, 124.8972,  73.1434]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 20 took 0.02 seconds\n",
      "Nr. of optimization run: 21\n",
      "New candidates are: tensor([[1157.3786,   85.1563,   53.9494,   31.4655,  518.2446,  793.4018,\n",
      "           50.5681,   39.3145,  143.8421,   24.1276]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 21 took 0.01 seconds\n",
      "Nr. of optimization run: 22\n",
      "New candidates are: tensor([[ 311.0165,   16.9452,  117.8527,   29.0399, 1467.1705,  372.5969,\n",
      "           42.0080,   84.5596,   54.6180,    6.8744]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 22 took 0.00 seconds\n",
      "Nr. of optimization run: 23\n",
      "New candidates are: tensor([[1087.4564,   60.0305,  115.0405,    7.8881, 1422.2297,  419.3839,\n",
      "           50.9628,   55.7275,   30.8148,   30.6987]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "Iteration 23 took 0.02 seconds\n",
      "Nr. of optimization run: 24\n",
      "New candidates are: tensor([[421.8875,  22.8428,  70.9927,  17.0358, 510.9085, 586.4144,  45.4054,\n",
      "          94.5896,   5.7578,  52.8887]], device='cuda:0', dtype=torch.float64)\n",
      "Iteration 24 took 0.00 seconds\n",
      "最优点: [0.94355708360672, 0.94355708360672, 1.3169982433319092, 1.3169982433319092, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3758662939071655, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809]\n",
      "Bayes Best Values Over All Experiments:\n",
      "[[0.9725248217582703, 0.9725248217582703, 1.3512645959854126, 1.3512645959854126, 1.3512645959854126, 1.3512645959854126, 1.360853910446167, 1.360853910446167, 1.360853910446167, 1.360853910446167, 1.360853910446167, 1.360853910446167, 1.360853910446167, 1.3672524690628052, 1.3672524690628052, 1.3672524690628052, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862, 1.3779572248458862], [1.3315730094909668, 1.3315730094909668, 1.3315730094909668, 1.3315730094909668, 1.3332024812698364, 1.3332024812698364, 1.3332024812698364, 1.3332024812698364, 1.3332024812698364, 1.3332024812698364, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676, 1.3731350898742676], [0.5482812523841858, 1.1647224426269531, 1.3018571138381958, 1.3018571138381958, 1.373915672302246, 1.3752014636993408, 1.3752014636993408, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.3954086303710938, 1.396803617477417, 1.396803617477417, 1.396803617477417, 1.396803617477417, 1.396803617477417], [0.8368469476699829, 1.3429807424545288, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635, 1.3883631229400635], [1.334948182106018, 1.334948182106018, 1.334948182106018, 1.334948182106018, 1.36324942111969, 1.36324942111969, 1.36324942111969, 1.36324942111969, 1.36324942111969, 1.36324942111969, 1.36324942111969, 1.36324942111969, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601, 1.364169955253601], [0.7983927726745605, 1.316449761390686, 1.316449761390686, 1.316449761390686, 1.3588625192642212, 1.3588625192642212, 1.3588625192642212, 1.3588625192642212, 1.3588625192642212, 1.3588625192642212, 1.3689944744110107, 1.3689944744110107, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3732097148895264, 1.3786884546279907, 1.3786884546279907, 1.3786884546279907, 1.3786884546279907, 1.3786884546279907, 1.3786884546279907], [1.0059646368026733, 1.0059646368026733, 1.3668502569198608, 1.3668502569198608, 1.3668502569198608, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422, 1.4008464813232422], [1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3885661363601685, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481, 1.3949881792068481], [0.9835666418075562, 1.362736463546753, 1.362736463546753, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.373355746269226, 1.3772218227386475, 1.3772218227386475, 1.3772218227386475, 1.3772218227386475, 1.3772218227386475, 1.3772218227386475, 1.3772218227386475, 1.3772218227386475, 1.3772218227386475], [0.94355708360672, 0.94355708360672, 1.3169982433319092, 1.3169982433319092, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3639470338821411, 1.3758662939071655, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809, 1.3841338157653809]]\n",
      "Bayes Best Values Over All Experiments (Array):\n",
      "[[0.97252482 0.97252482 1.3512646  1.3512646  1.3512646  1.3512646\n",
      "  1.36085391 1.36085391 1.36085391 1.36085391 1.36085391 1.36085391\n",
      "  1.36085391 1.36725247 1.36725247 1.36725247 1.37795722 1.37795722\n",
      "  1.37795722 1.37795722 1.37795722 1.37795722 1.37795722 1.37795722\n",
      "  1.37795722 1.37795722 1.37795722 1.37795722 1.37795722 1.37795722]\n",
      " [1.33157301 1.33157301 1.33157301 1.33157301 1.33320248 1.33320248\n",
      "  1.33320248 1.33320248 1.33320248 1.33320248 1.37313509 1.37313509\n",
      "  1.37313509 1.37313509 1.37313509 1.37313509 1.37313509 1.37313509\n",
      "  1.37313509 1.37313509 1.37313509 1.37313509 1.37313509 1.37313509\n",
      "  1.37313509 1.37313509 1.37313509 1.37313509 1.37313509 1.37313509]\n",
      " [0.54828125 1.16472244 1.30185711 1.30185711 1.37391567 1.37520146\n",
      "  1.37520146 1.39540863 1.39540863 1.39540863 1.39540863 1.39540863\n",
      "  1.39540863 1.39540863 1.39540863 1.39540863 1.39540863 1.39540863\n",
      "  1.39540863 1.39540863 1.39540863 1.39540863 1.39540863 1.39540863\n",
      "  1.39540863 1.39680362 1.39680362 1.39680362 1.39680362 1.39680362]\n",
      " [0.83684695 1.34298074 1.38836312 1.38836312 1.38836312 1.38836312\n",
      "  1.38836312 1.38836312 1.38836312 1.38836312 1.38836312 1.38836312\n",
      "  1.38836312 1.38836312 1.38836312 1.38836312 1.38836312 1.38836312\n",
      "  1.38836312 1.38836312 1.38836312 1.38836312 1.38836312 1.38836312\n",
      "  1.38836312 1.38836312 1.38836312 1.38836312 1.38836312 1.38836312]\n",
      " [1.33494818 1.33494818 1.33494818 1.33494818 1.36324942 1.36324942\n",
      "  1.36324942 1.36324942 1.36324942 1.36324942 1.36324942 1.36324942\n",
      "  1.36416996 1.36416996 1.36416996 1.36416996 1.36416996 1.36416996\n",
      "  1.36416996 1.36416996 1.36416996 1.36416996 1.36416996 1.36416996\n",
      "  1.36416996 1.36416996 1.36416996 1.36416996 1.36416996 1.36416996]\n",
      " [0.79839277 1.31644976 1.31644976 1.31644976 1.35886252 1.35886252\n",
      "  1.35886252 1.35886252 1.35886252 1.35886252 1.36899447 1.36899447\n",
      "  1.37320971 1.37320971 1.37320971 1.37320971 1.37320971 1.37320971\n",
      "  1.37320971 1.37320971 1.37320971 1.37320971 1.37320971 1.37320971\n",
      "  1.37868845 1.37868845 1.37868845 1.37868845 1.37868845 1.37868845]\n",
      " [1.00596464 1.00596464 1.36685026 1.36685026 1.36685026 1.40084648\n",
      "  1.40084648 1.40084648 1.40084648 1.40084648 1.40084648 1.40084648\n",
      "  1.40084648 1.40084648 1.40084648 1.40084648 1.40084648 1.40084648\n",
      "  1.40084648 1.40084648 1.40084648 1.40084648 1.40084648 1.40084648\n",
      "  1.40084648 1.40084648 1.40084648 1.40084648 1.40084648 1.40084648]\n",
      " [1.38856614 1.38856614 1.38856614 1.38856614 1.38856614 1.38856614\n",
      "  1.38856614 1.38856614 1.38856614 1.38856614 1.38856614 1.38856614\n",
      "  1.38856614 1.38856614 1.39498818 1.39498818 1.39498818 1.39498818\n",
      "  1.39498818 1.39498818 1.39498818 1.39498818 1.39498818 1.39498818\n",
      "  1.39498818 1.39498818 1.39498818 1.39498818 1.39498818 1.39498818]\n",
      " [0.98356664 1.36273646 1.36273646 1.37335575 1.37335575 1.37335575\n",
      "  1.37335575 1.37335575 1.37335575 1.37335575 1.37335575 1.37335575\n",
      "  1.37335575 1.37335575 1.37335575 1.37335575 1.37335575 1.37335575\n",
      "  1.37335575 1.37335575 1.37335575 1.37722182 1.37722182 1.37722182\n",
      "  1.37722182 1.37722182 1.37722182 1.37722182 1.37722182 1.37722182]\n",
      " [0.94355708 0.94355708 1.31699824 1.31699824 1.36394703 1.36394703\n",
      "  1.36394703 1.36394703 1.36394703 1.36394703 1.36394703 1.36394703\n",
      "  1.36394703 1.36394703 1.36394703 1.37586629 1.38413382 1.38413382\n",
      "  1.38413382 1.38413382 1.38413382 1.38413382 1.38413382 1.38413382\n",
      "  1.38413382 1.38413382 1.38413382 1.38413382 1.38413382 1.38413382]]\n"
     ]
    }
   ],
   "source": [
    "results4 = Hartmannb.bayesian_optimization_experiment(\n",
    "    num_experiments=10,\n",
    "    n=25,\n",
    "    obj_fn1=predict_bi_function_xg,\n",
    "    obj_fn3=predict_bi_function_xg,\n",
    "    initial_points_task1=initial_points_task1,  # 传递生成的初始样本\n",
    "    initial_points_task2=initial_points_task22,  # 传递生成的初始样本\n",
    "    fit_task_fn=zj,\n",
    "    device='cuda',\n",
    "    task_type='single'  # 表示运行单任务模型\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c04182c1-dc73-4f0b-9889-a6c3b2264488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3763845 , 1.3763845 , 1.3763845 , 1.3763845 , 1.3763845 ,\n",
       "        1.3763845 , 1.3763845 , 1.3763845 , 1.3763845 , 1.3763845 ,\n",
       "        1.3763845 , 1.3763845 , 1.3763845 , 1.3763845 , 1.3763845 ,\n",
       "        1.3763845 , 1.3763845 , 1.3763845 , 1.3763845 , 1.3763845 ,\n",
       "        1.3763845 , 1.3763845 , 1.3763845 , 1.3763845 , 1.3763845 ,\n",
       "        1.3763845 , 1.3763845 , 1.3763845 , 1.3763845 , 1.3763845 ],\n",
       "       [0.43853989, 0.95903993, 1.34031594, 1.34031594, 1.34031594,\n",
       "        1.34031594, 1.34031594, 1.34031594, 1.38808835, 1.38808835,\n",
       "        1.38808835, 1.38808835, 1.38808835, 1.38808835, 1.38808835,\n",
       "        1.38808835, 1.38808835, 1.38808835, 1.38808835, 1.38808835,\n",
       "        1.38808835, 1.38808835, 1.38808835, 1.38808835, 1.38808835,\n",
       "        1.38808835, 1.38808835, 1.38808835, 1.38808835, 1.38808835],\n",
       "       [1.32270598, 1.32270598, 1.32270598, 1.32270598, 1.33175385,\n",
       "        1.33175385, 1.33175385, 1.33175385, 1.33175385, 1.33175385,\n",
       "        1.33175385, 1.33175385, 1.33175385, 1.33175385, 1.33175385,\n",
       "        1.33175385, 1.33175385, 1.33175385, 1.33833373, 1.33833373,\n",
       "        1.33833373, 1.33833373, 1.33833373, 1.33833373, 1.33833373,\n",
       "        1.33833373, 1.36702287, 1.36702287, 1.36702287, 1.36702287],\n",
       "       [0.98675025, 0.98675025, 1.27658367, 1.35697699, 1.35697699,\n",
       "        1.35697699, 1.35697699, 1.35697699, 1.35697699, 1.35697699,\n",
       "        1.35697699, 1.35697699, 1.35697699, 1.35697699, 1.35697699,\n",
       "        1.35697699, 1.35697699, 1.35697699, 1.35697699, 1.35697699,\n",
       "        1.35697699, 1.35697699, 1.35697699, 1.35697699, 1.35697699,\n",
       "        1.35697699, 1.35697699, 1.35697699, 1.35697699, 1.35697699],\n",
       "       [1.3195039 , 1.3195039 , 1.3195039 , 1.3195039 , 1.32293022,\n",
       "        1.32293022, 1.32293022, 1.32293022, 1.32293022, 1.32293022,\n",
       "        1.36432886, 1.36432886, 1.3910886 , 1.3910886 , 1.3910886 ,\n",
       "        1.3910886 , 1.3910886 , 1.3910886 , 1.3910886 , 1.3910886 ,\n",
       "        1.3910886 , 1.3910886 , 1.3910886 , 1.3910886 , 1.3910886 ,\n",
       "        1.3910886 , 1.3910886 , 1.3910886 , 1.3910886 , 1.3910886 ],\n",
       "       [0.98476762, 1.17158008, 1.17158008, 1.35502386, 1.35502386,\n",
       "        1.35502386, 1.35502386, 1.35502386, 1.35502386, 1.35502386,\n",
       "        1.35502386, 1.35502386, 1.35502386, 1.35502386, 1.35502386,\n",
       "        1.35502386, 1.35502386, 1.35502386, 1.35502386, 1.35502386,\n",
       "        1.35502386, 1.35502386, 1.35502386, 1.35502386, 1.35502386,\n",
       "        1.35502386, 1.3607918 , 1.3607918 , 1.3607918 , 1.3607918 ],\n",
       "       [0.77351242, 0.77351242, 0.98451608, 1.04268253, 1.04268253,\n",
       "        1.39299154, 1.39299154, 1.39299154, 1.39299154, 1.39299154,\n",
       "        1.39299154, 1.39299154, 1.39299154, 1.39299154, 1.39299154,\n",
       "        1.39299154, 1.39299154, 1.39299154, 1.39299154, 1.39299154,\n",
       "        1.39299154, 1.39299154, 1.39299154, 1.39299154, 1.39299154,\n",
       "        1.39299154, 1.39299154, 1.39299154, 1.39299154, 1.39299154],\n",
       "       [0.94644833, 0.95568067, 1.02711964, 1.02711964, 1.02711964,\n",
       "        1.31497002, 1.31497002, 1.3691113 , 1.3691113 , 1.3691113 ,\n",
       "        1.3691113 , 1.3691113 , 1.37632024, 1.37632024, 1.37632024,\n",
       "        1.37632024, 1.37632024, 1.37632024, 1.37632024, 1.37632024,\n",
       "        1.37632024, 1.37632024, 1.37632024, 1.37632024, 1.37632024,\n",
       "        1.37956727, 1.37956727, 1.37956727, 1.37956727, 1.37956727],\n",
       "       [1.02837372, 1.02837372, 1.02837372, 1.29285336, 1.29285336,\n",
       "        1.29285336, 1.29285336, 1.29285336, 1.33748984, 1.33748984,\n",
       "        1.33748984, 1.33748984, 1.33748984, 1.38729811, 1.38729811,\n",
       "        1.38729811, 1.38729811, 1.38729811, 1.38729811, 1.38729811,\n",
       "        1.38729811, 1.38729811, 1.38729811, 1.38729811, 1.38729811,\n",
       "        1.38729811, 1.38729811, 1.38729811, 1.38729811, 1.38729811],\n",
       "       [1.34415221, 1.34415221, 1.34415221, 1.34415221, 1.34415221,\n",
       "        1.34415221, 1.34415221, 1.34415221, 1.34415221, 1.34415221,\n",
       "        1.34415221, 1.34415221, 1.34415221, 1.35407209, 1.35407209,\n",
       "        1.35407209, 1.35407209, 1.35407209, 1.35407209, 1.35407209,\n",
       "        1.35407209, 1.35407209, 1.35407209, 1.35407209, 1.35407209,\n",
       "        1.35407209, 1.35407209, 1.35407209, 1.35407209, 1.35407209]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c84f62-b4bb-4d20-a45c-49bd4c6167cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5b7e65b-8731-4c5e-848a-e6a49eb59040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有结果已保存到 实验数据钼铋铋xg 文件中。\n"
     ]
    }
   ],
   "source": [
    "results_list = [results1,results2,results3,results4]\n",
    "results_names = ['results1','results2','results3','results4']\n",
    "\n",
    "# 初始化一个空字典来存储展平后的数据\n",
    "flattened_results = {}\n",
    "\n",
    "# 遍历所有结果数组\n",
    "for i, results in enumerate(results_list):\n",
    "    if isinstance(results, torch.Tensor):\n",
    "        results_np = results.cpu().numpy()  # 转为 numpy 数组\n",
    "    else:\n",
    "        results_np = results  # 如果已经是 numpy 数组，直接使用\n",
    "    \n",
    "    # 获取数组的维度\n",
    "    shape_len = len(results_np.shape)\n",
    "    \n",
    "    if shape_len == 3:\n",
    "        # 3D 数组的形状 (num_experiments, num_samples, num_metrics)\n",
    "        num_experiments, num_samples, num_metrics = results_np.shape\n",
    "        # 展平为 2D 数组\n",
    "        flattened_array = results_np.reshape(num_experiments * num_samples, num_metrics)\n",
    "    elif shape_len == 2:\n",
    "        # 2D 数组的形状 (num_experiments, num_metrics)\n",
    "        flattened_array = results_np\n",
    "        num_experiments, num_metrics = flattened_array.shape\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected number of dimensions: {shape_len}\")\n",
    "    \n",
    "    # 将每个数组的列命名为 'results1_Metric_1', 'results1_Metric_2', ...\n",
    "    columns = [f\"{results_names[i]}_Metric_{j+1}\" for j in range(num_metrics)]\n",
    "    \n",
    "    # 将展平后的数组存入字典，方便后面转换为 DataFrame\n",
    "    flattened_results.update({col: flattened_array[:, j] for j, col in enumerate(columns)})\n",
    "\n",
    "# 创建 DataFrame\n",
    "df_results = pd.DataFrame(flattened_results)\n",
    "\n",
    "# 文件名\n",
    "csv_filename = '实验数据钼铋铋xg'\n",
    "\n",
    "# 检查 CSV 文件是否已经存在\n",
    "if os.path.exists(csv_filename):\n",
    "    # 如果文件存在，先读取现有文件\n",
    "    df_existing = pd.read_csv(csv_filename)\n",
    "    # 合并新结果到现有的 DataFrame 中\n",
    "    df_results = pd.concat([df_existing, df_results], ignore_index=True)\n",
    "\n",
    "# 保存或追加为 CSV 文件\n",
    "df_results.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"所有结果已保存到 {csv_filename} 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb9d0324-9e8f-4da7-ac78-3571d9d0bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_plot_individual_results(csv_files, confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    - csv_files: CSV 文件名的列表。\n",
    "    - confidence_level: 置信水平，默认值为 0.95。\n",
    "    \"\"\"\n",
    "    # 计算置信区间的 Z 值\n",
    "    z_value = stats.norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "    \n",
    "    # 准备线条颜色和标签\n",
    "    line_colors = ['blue', 'red', 'green', 'orange', 'black', 'grey']\n",
    "    line_styles = ['-', '--', ':', '-.', '-', '--']  # 为每一条线添加样式\n",
    "    labels = ['Ackley 10D', 'Ackley 5D', 'branin', 'Hartmann']\n",
    "\n",
    "    # 创建一个包含 2x2 网格的图形\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    for idx, csv_filename in enumerate(csv_files):\n",
    "        # 检查 CSV 文件是否存在\n",
    "        if not os.path.exists(csv_filename):\n",
    "            raise FileNotFoundError(f\"File {csv_filename} does not exist.\")\n",
    "\n",
    "        # 从 CSV 文件中读取数据\n",
    "        df_results = pd.read_csv(csv_filename)\n",
    "\n",
    "\n",
    "        means_bayes1 = df_results.filter(like='results1_Metric_').mean(axis=0)\n",
    "        standard_errors1 = df_results.filter(like='results1_Metric_').sem(axis=0)\n",
    "        ci_bayes1 = z_value * standard_errors1\n",
    "\n",
    "        means_random = df_results.filter(like='results2_Metric_').mean(axis=0)\n",
    "        standard_errors2 = df_results.filter(like='results2_Metric_').sem(axis=0)\n",
    "        ci_random = z_value * standard_errors2\n",
    "\n",
    "        means_shiyan = df_results.filter(like='results3_Metric_').mean(axis=0)\n",
    "        standard_errors3 = df_results.filter(like='results3_Metric_').sem(axis=0)\n",
    "        ci_shiyan = z_value * standard_errors3\n",
    "\n",
    "        means_orthogonal = df_results.filter(like='results4_Metric_').mean(axis=0)\n",
    "        standard_errors4 = df_results.filter(like='results4_Metric_').sem(axis=0)\n",
    "        ci_orthogonal = z_value * standard_errors4\n",
    "\n",
    "\n",
    "        \n",
    "        # x轴的索引\n",
    "        x = np.arange(len(means_bayes1))\n",
    "\n",
    "        # 找到对应的子图位置\n",
    "        ax = axs[idx // 2, idx % 2]\n",
    "\n",
    "        # 使用不同颜色绘制带有误差条的均值图\n",
    "        ax.errorbar(x, means_bayes1, yerr=ci_bayes1, fmt='o', label='STGP+qlogEI', \n",
    "                    color=line_colors[0], linestyle=line_styles[0], ecolor=line_colors[0], capsize=5)\n",
    "\n",
    "        ax.errorbar(x, means_random, yerr=ci_random, fmt='o', label='random', \n",
    "                    color=line_colors[1], linestyle=line_styles[1], ecolor=line_colors[1], capsize=5)\n",
    "        ax.errorbar(x, means_shiyan, yerr=ci_shiyan, fmt='o', label='等分', \n",
    "                    color=line_colors[2], linestyle=line_styles[2], ecolor=line_colors[2], capsize=5)\n",
    "        ax.errorbar(x, means_orthogonal, yerr=ci_orthogonal, fmt='o', label='orthogonal', \n",
    "                    color=line_colors[3], linestyle=line_styles[3], ecolor=line_colors[3], capsize=5)\n",
    "    \n",
    "        # 设置子图的标题和标签\n",
    "        ax.set_title(f'Optimal values and confidence intervals ({labels[idx]})')\n",
    "        ax.set_xlabel('Number of Iterations')\n",
    "        ax.set_ylabel('The optimal value')\n",
    "\n",
    "        # 添加图例\n",
    "        ax.legend()\n",
    "\n",
    "    # 调整布局\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # 保存图像\n",
    "    plt.savefig('Ackley_Cos_Hartmann_Individual_Plots_Colored_Lines.png', dpi=300)\n",
    "    # 显示图形\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa4f752f-2347-44d0-b784-eb6df8d8cc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 定义文件名列表\n",
    "csv_files = [ '实验数据钼铋铋xg']\n",
    "\n",
    "# 调用函数并绘图\n",
    "load_and_plot_individual_results(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd444ef-c332-405c-8199-915dfae9c354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
